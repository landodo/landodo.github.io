<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
<meta name="robots" content="index, follow">
<title>CIFAR-10ã€PyTorch å’Œ AlexNet | Landodo&#39;s NoteBook</title>
<meta name="keywords" content="è®ºæ–‡é˜…è¯», AlexNet, PyTorch" />
<meta name="description" content="CIFAR-10ã€PyTorch å’Œ AlexNet å…ˆåœ¨è‡ªå·±çš„ç”µè„‘ä¸Šèµ°ä¸€éï¼Œä¿è¯è¯­æ³•å’Œé€»è¾‘ä¸ä¼šé”™ã€‚å†æ”¾åˆ°è¿œç¨‹é…ç½®é«˜çš„ç”µè„‘ä¸Šè·‘ã€‚ è¿™äº›ç»å…¸çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œè¦ç†Ÿæ‚‰">
<meta name="author" content="">
<link rel="canonical" href="http://landodo.github.io/posts/20201109-alexnet-code/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css" integrity="sha256-yIlj/i15RiAA/Q&#43;xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js" integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://landodo.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://landodo.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://landodo.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://landodo.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="http://landodo.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="CIFAR-10ã€PyTorch å’Œ AlexNet" />
<meta property="og:description" content="CIFAR-10ã€PyTorch å’Œ AlexNet å…ˆåœ¨è‡ªå·±çš„ç”µè„‘ä¸Šèµ°ä¸€éï¼Œä¿è¯è¯­æ³•å’Œé€»è¾‘ä¸ä¼šé”™ã€‚å†æ”¾åˆ°è¿œç¨‹é…ç½®é«˜çš„ç”µè„‘ä¸Šè·‘ã€‚ è¿™äº›ç»å…¸çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œè¦ç†Ÿæ‚‰" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://landodo.github.io/posts/20201109-alexnet-code/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-09T10:17:29&#43;08:00" />
<meta property="article:modified_time" content="2020-11-09T10:17:29&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="CIFAR-10ã€PyTorch å’Œ AlexNet"/>
<meta name="twitter:description" content="CIFAR-10ã€PyTorch å’Œ AlexNet å…ˆåœ¨è‡ªå·±çš„ç”µè„‘ä¸Šèµ°ä¸€éï¼Œä¿è¯è¯­æ³•å’Œé€»è¾‘ä¸ä¼šé”™ã€‚å†æ”¾åˆ°è¿œç¨‹é…ç½®é«˜çš„ç”µè„‘ä¸Šè·‘ã€‚ è¿™äº›ç»å…¸çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œè¦ç†Ÿæ‚‰"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://landodo.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "CIFAR-10ã€PyTorch å’Œ AlexNet",
      "item": "http://landodo.github.io/posts/20201109-alexnet-code/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "CIFAR-10ã€PyTorch å’Œ AlexNet",
  "name": "CIFAR-10ã€PyTorch å’Œ AlexNet",
  "description": "CIFAR-10ã€PyTorch å’Œ AlexNet å…ˆåœ¨è‡ªå·±çš„ç”µè„‘ä¸Šèµ°ä¸€éï¼Œä¿è¯è¯­æ³•å’Œé€»è¾‘ä¸ä¼šé”™ã€‚å†æ”¾åˆ°è¿œç¨‹é…ç½®é«˜çš„ç”µè„‘ä¸Šè·‘ã€‚ è¿™äº›ç»å…¸çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œè¦ç†Ÿæ‚‰",
  "keywords": [
    "è®ºæ–‡é˜…è¯»", "AlexNet", "PyTorch"
  ],
  "articleBody": "CIFAR-10ã€PyTorch å’Œ AlexNet å…ˆåœ¨è‡ªå·±çš„ç”µè„‘ä¸Šèµ°ä¸€éï¼Œä¿è¯è¯­æ³•å’Œé€»è¾‘ä¸ä¼šé”™ã€‚å†æ”¾åˆ°è¿œç¨‹é…ç½®é«˜çš„ç”µè„‘ä¸Šè·‘ã€‚\nè¿™äº›ç»å…¸çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œè¦ç†Ÿæ‚‰åˆ°èƒ½ç™½æ¿ç¼–ç¨‹çš„æŠ€èƒ½ã€‚\næœ€è¿‘çœ‹åˆ°æœ‰å…³æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªæ¨ç‰¹ï¼Œè§‰å¾—å¾ˆæœ‰å¯å‘ã€‚\n What a lot of machine learning courses \u0026 books teach:\n Load clean data Train an MNIST-* classifier with 99% accuracy  What they should actually be teaching:\n Process, clean, load your own data Fail many experiments and research/find/understand ways to improve your ML model   å¾ˆå¤šæœºå™¨å­¦ä¹ è¯¾ç¨‹ä¸ä¹¦ç±æ‰€æ•™æˆçš„å†…å®¹ï¼š\n åŠ è½½å¹²å‡€çš„æ•°æ® è®­ç»ƒä¸€ä¸ªMNIST-* åˆ†ç±»å™¨ï¼Œå‡†ç¡®ç‡è¾¾ 99%ã€‚  ä»–ä»¬å…¶å®åº”è¯¥æ•™ä»€ä¹ˆã€‚\n å¤„ç†ã€æ¸…ç†ã€åŠ è½½è‡ªå·±çš„æ•°æ® å¤šæ¬¡å®éªŒå¤±è´¥ï¼Œç ”ç©¶/å‘ç°/äº†è§£æ”¹è¿›ä½ çš„ ML æ¨¡å‹çš„æ–¹æ³•ã€‚   ç¯å¢ƒå‡†å¤‡ ç¬¬ä¸€æ­¥ï¼šå¯åŠ¨è™šæ‹Ÿç¯å¢ƒ\nâœ source activate ldl-env ç¬¬äºŒæ­¥ï¼šå®‰è£… PyTorch\n(ldl-env) âœ workspace conda install pytorch torchvision torchaudio -c pytorch  è¦å¤šçœ‹ PyTorch çš„å®˜æ–¹æ–‡æ¡£ã€‚\n æ•°æ®é›† torchvision.datasets torchvision.datasets ä¸­åŒ…å«äº†è¾ƒå¤šçš„æ•°æ®é›†\n  MNISTï¼ˆ0-9 æ‰‹å†™æ•°å­—ï¼‰\n  COCOï¼ˆç”¨äºå›¾åƒæ ‡æ³¨å’Œç›®æ ‡æ£€æµ‹ï¼‰\n  LSUNï¼ˆåŒ…å«æ•°ç™¾ä¸‡ä¸ªåœºæ™¯å’Œå¯¹è±¡çš„å½©è‰²å›¾åƒï¼‰\n  CIFAR-10\n  CIFAR-10 dataset (Canadian Institute For Advanced Research) ï¼šhttps://www.cs.toronto.edu/~kriz/cifar.html\nCIFAR-10 å’Œ CIFAR-100 æ˜¯ä¸€ä¸ªåŒ…å« 8000 ä¸‡å¼ å¾®å°å›¾åƒçš„æ•°æ®é›†ï¼Œç”± Alex Krizhevskyã€Vinod Nair å’Œ Geoffrey Hinton æ”¶é›†ã€‚\nCIFAR-10 æ•°æ®é›†åŒ…å« 10 ä¸ªç±»åˆ«ï¼Œæ€»å…± 60000 å¼  $$32\\times32$$ å½©è‰²å›¾åƒã€‚\næ¯ä¸ªç±»åˆ« 6000 å¼ å›¾åƒã€‚\næœ‰ 50000 å¼ è®­ç»ƒå›¾åƒï¼ˆtrain setï¼‰å’Œ 10000 å¼ æµ‹è¯•å›¾åƒï¼ˆtest setï¼‰ã€‚\næ•°æ®é›†åˆ†ä¸º 5 ä¸ªè®­ç»ƒ Batch å’Œ 1 ä¸ªæµ‹è¯• Batchã€‚æ¯ä¸ªTrain Batch æœ‰ 10000 å¼ å›¾åƒï¼ŒTest Batch æ­£å¥½åŒ…å« 1000 å¼ ä»æ¯ä¸ªç±»ä¸­éšæœºé€‰å–çš„å›¾åƒã€‚ Train Batch æŒ‰éšæœºé¡ºåºåŒ…å«å‰©ä½™çš„å›¾åƒï¼Œä½†ä¸€äº› Train Batch å¯èƒ½åŒ…å«æ¥è‡ªä¸€ä¸ªç±»çš„å›¾åƒæ¯”å¦ä¸€ä¸ªç±»æ›´å¤šã€‚åœ¨å®ƒä»¬ä¹‹é—´ï¼ŒTrain batch æ­£å¥½åŒ…å«æ¥è‡ªæ¯ä¸ªç±»çš„ 5000 å¼ å›¾åƒã€‚\n Fashion-MNIST  GitHub: https://github.com/zalandoresearch/fashion-mnist\næ¯ä¸ªè®­ç»ƒå’Œæµ‹è¯•æ ·æœ¬éƒ½æŒ‰ç…§ä»¥ä¸‹ç±»åˆ«è¿›è¡Œäº†æ ‡æ³¨ï¼š\n   æ ‡æ³¨ç¼–å· æè¿°     0 T-shirt/topï¼ˆTæ¤ï¼‰   1 Trouserï¼ˆè£¤å­ï¼‰   2 Pulloverï¼ˆå¥—è¡«ï¼‰   3 Dressï¼ˆè£™å­ï¼‰   4 Coatï¼ˆå¤–å¥—ï¼‰   5 Sandalï¼ˆå‡‰é‹ï¼‰   6 Shirtï¼ˆæ±—è¡«ï¼‰   7 Sneakerï¼ˆè¿åŠ¨é‹ï¼‰   8 Bagï¼ˆåŒ…ï¼‰   9 Ankle bootï¼ˆè¸é´ï¼‰    æ‰¾åˆ°äº†ä¸€ä¸ªå¯ä¾›å‚è€ƒçš„å°é¡¹ç›®ï¼Œæ•°æ®é›†æ˜¯ CIFAR-10ã€‚\nAlexNet GitHubï¼špytorch-cifar10 è¾“å…¥å›¾ç‰‡çš„å¤§å°ä¸º $$32\\times32\\times3$$\nclass AlexNet(nn.Module):  def __init__(self, num_classes=NUM_CLASSES):  super(AlexNet, self).__init__()  self.features = nn.Sequential(  nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  nn.ReLU(inplace=True),  nn.MaxPool2d(kernel_size=2),  nn.Conv2d(64, 192, kernel_size=3, padding=1),  nn.ReLU(inplace=True),  nn.MaxPool2d(kernel_size=2),  nn.Conv2d(192, 384, kernel_size=3, padding=1),  nn.ReLU(inplace=True),  nn.Conv2d(384, 256, kernel_size=3, padding=1),  nn.ReLU(inplace=True),  nn.Conv2d(256, 256, kernel_size=3, padding=1),  nn.ReLU(inplace=True),  nn.MaxPool2d(kernel_size=2),  )  self.classifier = nn.Sequential(  nn.Dropout(),  nn.Linear(256 * 2 * 2, 4096),  nn.ReLU(inplace=True),  nn.Dropout(),  nn.Linear(4096, 4096),  nn.ReLU(inplace=True),  nn.Linear(4096, num_classes),  )   def forward(self, x):  x = self.features(x)  x = x.view(x.size(0), 256 * 2 * 2)  x = self.classifier(x)  return x æˆ‘æŒ‰ç…§å´æ©è¾¾è€å¸ˆçš„è§†é¢‘æ•™ç¨‹ï¼Œç»˜åˆ¶äº†ä¸€ä¸ªå›¾ï¼Œå¦‚ä¸‹ã€‚\nPapers with Code è¿™é‡Œçš„å›¾ç‰‡è¾“å…¥åº”è¯¥æ˜¯ $$227\\times227\\times3$$ï¼Œæ‰€ä»¥ç½‘ç»œçš„å†…éƒ¨ kernel_size å’Œ stride ä¼šæœ‰ä¸åŒã€‚\nclass AlexNet(nn.Module):  \"\"\" Neural network model consisting of layers propsed by AlexNet paper. \"\"\"  def __init__(self, num_classes=1000):  \"\"\" Define and allocate layers for this neural net. Args: num_classes (int): number of classes to predict with this model \"\"\"  super().__init__()  # input size should be : (b x 3 x 227 x 227)  # The image in the original paper states that width and height are 224 pixels, but  # the dimensions after first convolution layer do not lead to 55 x 55.  self.net = nn.Sequential(  nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4), # (b x 96 x 55 x 55)  nn.ReLU(),  nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2), # section 3.3  nn.MaxPool2d(kernel_size=3, stride=2), # (b x 96 x 27 x 27)  nn.Conv2d(96, 256, 5, padding=2), # (b x 256 x 27 x 27)  nn.ReLU(),  nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  nn.MaxPool2d(kernel_size=3, stride=2), # (b x 256 x 13 x 13)  nn.Conv2d(256, 384, 3, padding=1), # (b x 384 x 13 x 13)  nn.ReLU(),  nn.Conv2d(384, 384, 3, padding=1), # (b x 384 x 13 x 13)  nn.ReLU(),  nn.Conv2d(384, 256, 3, padding=1), # (b x 256 x 13 x 13)  nn.ReLU(),  nn.MaxPool2d(kernel_size=3, stride=2), # (b x 256 x 6 x 6)  )  # classifier is just a name for linear layers  self.classifier = nn.Sequential(  nn.Dropout(p=0.5, inplace=True),  nn.Linear(in_features=(256 * 6 * 6), out_features=4096),  nn.ReLU(),  nn.Dropout(p=0.5, inplace=True),  nn.Linear(in_features=4096, out_features=4096),  nn.ReLU(),  nn.Linear(in_features=4096, out_features=num_classes),  )  self.init_bias() # initialize bias   def init_bias(self):  for layer in self.net:  if isinstance(layer, nn.Conv2d):  nn.init.normal_(layer.weight, mean=0, std=0.01)  nn.init.constant_(layer.bias, 0)  # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers  nn.init.constant_(self.net[4].bias, 1)  nn.init.constant_(self.net[10].bias, 1)  nn.init.constant_(self.net[12].bias, 1)   def forward(self, x):  \"\"\" Pass the input through the net. Args: x (Tensor): input tensor Returns: output (Tensor): output tensor \"\"\"  x = self.net(x)  x = x.view(-1, 256 * 6 * 6) # reduce the dimensions for linear layer input  return self.classifier(x) Zhihu çŸ¥ä¹ https://zhuanlan.zhihu.com/p/29786939\nç»™å‡ºäº†å±€éƒ¨å“åº”å½’ä¸€åŒ–çš„å®ç°ã€‚\nimport torch.nn as nn from torch.nn import functional as F from torch.autograd import Variable  class LRN(nn.Module):  def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):  super(LRN, self).__init__()  self.ACROSS_CHANNELS = ACROSS_CHANNELS  if self.ACROSS_CHANNELS:  self.average=nn.AvgPool3d(kernel_size=(local_size, 1, 1), #0.2.0_4ä¼šæŠ¥é”™ï¼Œéœ€è¦åœ¨æœ€æ–°çš„åˆ†æ”¯ä¸ŠAvgPool3dæ‰æœ‰paddingå‚æ•°  stride=1,  padding=(int((local_size-1.0)/2), 0, 0))  else:  self.average=nn.AvgPool2d(kernel_size=local_size,  stride=1,  padding=int((local_size-1.0)/2))  self.alpha = alpha  self.beta = beta    def forward(self, x):  if self.ACROSS_CHANNELS:  div = x.pow(2).unsqueeze(1)  div = self.average(div).squeeze(1)  div = div.mul(self.alpha).add(1.0).pow(self.beta)#è¿™é‡Œçš„1.0å³ä¸ºbias  else:  div = x.pow(2)  div = self.average(div)  div = div.mul(self.alpha).add(1.0).pow(self.beta)  x = x.div(div)  return x è¿™ä¸ªä¸“é—¨åˆ†äº† layer1ï¼Œ layer2ï¼Œ layer3 ï¼Œæ›´åŠ çš„å¥½ç†è§£äº†ã€‚\nfrom torch import nn from torch.nn import functional as F from torch.autograd import Variable  import torch class AlexNet(nn.Module):  def __init__(self, num_classes = 1000):#imagenetæ•°é‡  super().__init__()  self.layer1 = nn.Sequential(  nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4),  nn.ReLU(inplace=True),  nn.MaxPool2d(kernel_size=3, stride=2),  LRN(local_size=5, alpha=1e-4, beta=0.75, ACROSS_CHANNELS=True)  )   self.layer2 = nn.Sequential(  nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, groups=2, padding=2),  nn.ReLU(inplace=True),  nn.MaxPool2d(kernel_size=3, stride=2),  LRN(local_size=5, alpha=1e-4, beta=0.75, ACROSS_CHANNELS=True)  )   self.layer3 = nn.Sequential(  nn.Conv2d(in_channels=256, out_channels=384, padding=1, kernel_size=3),  nn.ReLU(inplace=True)  )  self.layer4 = nn.Sequential(  nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1),  nn.ReLU(inplace=True)  )   self.layer5 = nn.Sequential(  nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),  nn.ReLU(inplace=True),  nn.MaxPool2d(kernel_size=3, stride=2)  )   #éœ€è¦é’ˆå¯¹ä¸Šä¸€å±‚æ”¹å˜view  self.layer6 = nn.Sequential(  nn.Linear(in_features=6*6*256, out_features=4096),  nn.ReLU(inplace=True),  nn.Dropout()  )  self.layer7 = nn.Sequential(  nn.Linear(in_features=4096, out_features=4096),  nn.ReLU(inplace=True),  nn.Dropout()  )   self.layer8 = nn.Linear(in_features=4096, out_features=num_classes)   def forward(self, x):  x = self.layer5(self.layer4(self.layer3(self.layer2(self.layer1(x)))))  x = x.view(-1, 6*6*256)  x = self.layer8(self.layer7(self.layer6(x)))   return x æ€è€ƒ æˆ‘æœ‰å‡ ä¸ªç–‘é—®ï¼Ÿ\n  AlexNet è®ºæ–‡é‡Œé¢çš„æ•°æ®é›†ä½¿ç”¨çš„æ˜¯ $$256\\times256\\times3$$ï¼Œé‡‡ç”¨æ•°æ®å¢å¼ºåçœŸæ­£è¾“å…¥åˆ°ç½‘ç»œçš„å›¾åƒ size ä¸º $$224\\times224\\times3$$ï¼Œä½†æ˜¯ç¼–ç¨‹å®ç°çš„æ—¶å€™ï¼Œè¾“å…¥çš„å¤§å¤šæ˜¯ $$227\\times227\\times3$$ è¿™ä¸ª 227 æ˜¯æ€ä¹ˆç®—å‡ºæ¥çš„ï¼Ÿ\n   2021.02.05ï¼š224 åº”è¯¥æ˜¯ä½œè€…çš„ä¸€ä¸ªå¤±è¯¯ï¼Œå…¶å®æ²¡å…³ç³»çš„ã€‚å°† 224 ä»£å…¥ç½‘ç»œï¼Œå°±ä¼šå‘ç° 224 å­˜åœ¨çš„é—®é¢˜ï¼Œ227 æ˜¯ä¸€ä¸ªæ›´å¥½çš„å–å€¼ã€‚\n     æˆ‘æ„Ÿè§‰æœ‰äººç”¨ 224ï¼Œæœ‰äººç”¨ 227ï¼Œæœ‰ä»€ä¹ˆåŒºåˆ«å—ï¼Ÿ\n   2021.02.05ï¼šç”¨ 227ï¼Œä¸è¦ç”¨ 224ã€‚ä»£å…¥ç½‘ç»œæ¨ä¸€éå°±çŸ¥é“ä¸ºä»€ä¹ˆäº†ï¼\n     ä¸Šæ–‡æˆ‘è®°å½•çš„ç¬¬ä¸€ä¸ªç¨‹åº pytorch-cifar10ï¼Œæ¯å¼ å›¾åƒçš„è¾“å…¥æ˜¯ $$32\\times32\\times3$$ã€‚è¿™ç§æƒ…å†µä¸‹ä¸€ç§å¤„ç†æ–¹å¼æ˜¯ resize æˆ 224ï¼›å¦ä¸€ç§æ˜¯æ›´æ”¹ç½‘ç»œçš„ kernel_sizeã€paddingã€strideï¼Œä¿®æ”¹è¿‡ä¹‹åçš„ç½‘ç»œè¿˜èƒ½å«åšæ˜¯ AlexNet å—ï¼Ÿ\n   2021.02.05ï¼šæˆ‘è®¤ä¸ºä¿®æ”¹åçš„ç½‘ç»œå°±ä¸èƒ½å«åš AlexNet äº†ã€‚\nAlexNet ä¸­çš„å·ç§¯æ ¸å¤§å°ã€æ­¥é•¿ã€å¡«å……éƒ½æ˜¯ä½œè€…ä¸º ImageNet æ•°æ®é›†ç²¾å¿ƒè®¾è®¡çš„ã€‚\n     ",
  "wordCount" : "2091",
  "inLanguage": "en",
  "datePublished": "2020-11-09T10:17:29+08:00",
  "dateModified": "2020-11-09T10:17:29+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://landodo.github.io/posts/20201109-alexnet-code/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Landodo's NoteBook",
    "logo": {
      "@type": "ImageObject",
      "url": "http://landodo.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://landodo.github.io/" accesskey="h" title="Landodo&#39;s NoteBook (Alt + H)">Landodo&#39;s NoteBook</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="http://landodo.github.io/search" title="ğŸ”Search (Alt &#43; /)" accesskey=/>
                    <span>ğŸ”Search</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/tags" title="Tag">
                    <span>Tag</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/cs-zoo" title="CS ZOO">
                    <span>CS ZOO</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://landodo.github.io/">Home</a>&nbsp;Â»&nbsp;<a href="http://landodo.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      CIFAR-10ã€PyTorch å’Œ AlexNet
    </h1>
    <div class="post-meta"><span title='2020-11-09 10:17:29 +0800 CST'>November 9, 2020</span>&nbsp;Â·&nbsp;5 min&nbsp;Â·&nbsp;2091 words

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#cifar-10pytorch-%e5%92%8c-alexnet" aria-label="CIFAR-10ã€PyTorch å’Œ AlexNet">CIFAR-10ã€PyTorch å’Œ AlexNet</a></li>
                <li>
                    <a href="#%e7%8e%af%e5%a2%83%e5%87%86%e5%a4%87" aria-label="ç¯å¢ƒå‡†å¤‡">ç¯å¢ƒå‡†å¤‡</a></li>
                <li>
                    <a href="#%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="æ•°æ®é›†">æ•°æ®é›†</a><ul>
                        
                <li>
                    <a href="#torchvisiondatasets" aria-label="torchvision.datasets">torchvision.datasets</a></li></ul>
                </li>
                <li>
                    <a href="#alexnet" aria-label="AlexNet">AlexNet</a><ul>
                        
                <li>
                    <a href="#githubpytorch-cifar10" aria-label="GitHubï¼špytorch-cifar10">GitHubï¼špytorch-cifar10</a></li>
                <li>
                    <a href="#papers-with-code" aria-label="Papers with Code">Papers with Code</a></li>
                <li>
                    <a href="#zhihu-%e7%9f%a5%e4%b9%8e" aria-label="Zhihu çŸ¥ä¹">Zhihu çŸ¥ä¹</a></li></ul>
                </li>
                <li>
                    <a href="#%e6%80%9d%e8%80%83" aria-label="æ€è€ƒ">æ€è€ƒ</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="cifar-10pytorch-å’Œ-alexnet">CIFAR-10ã€PyTorch å’Œ AlexNet<a hidden class="anchor" aria-hidden="true" href="#cifar-10pytorch-å’Œ-alexnet">#</a></h2>
<p>å…ˆåœ¨è‡ªå·±çš„ç”µè„‘ä¸Šèµ°ä¸€éï¼Œä¿è¯è¯­æ³•å’Œé€»è¾‘ä¸ä¼šé”™ã€‚å†æ”¾åˆ°è¿œç¨‹é…ç½®é«˜çš„ç”µè„‘ä¸Šè·‘ã€‚</p>
<p>è¿™äº›ç»å…¸çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œè¦ç†Ÿæ‚‰åˆ°èƒ½ç™½æ¿ç¼–ç¨‹çš„æŠ€èƒ½ã€‚</p>
<p>æœ€è¿‘çœ‹åˆ°æœ‰å…³æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªæ¨ç‰¹ï¼Œè§‰å¾—å¾ˆæœ‰å¯å‘ã€‚</p>
<blockquote>
<p>What a lot of machine learning courses &amp; books teach:</p>
<ul>
<li>Load clean data</li>
<li>Train an MNIST-* classifier with 99% accuracy</li>
</ul>
<p>What they should actually be teaching:</p>
<ul>
<li>Process, clean, load your own data</li>
<li>Fail many experiments and research/find/understand ways to improve your ML model</li>
</ul>
<hr>
<p>å¾ˆå¤šæœºå™¨å­¦ä¹ è¯¾ç¨‹ä¸ä¹¦ç±æ‰€æ•™æˆçš„å†…å®¹ï¼š</p>
<ul>
<li>åŠ è½½å¹²å‡€çš„æ•°æ®</li>
<li>è®­ç»ƒä¸€ä¸ªMNIST-* åˆ†ç±»å™¨ï¼Œå‡†ç¡®ç‡è¾¾ 99%ã€‚</li>
</ul>
<p>ä»–ä»¬å…¶å®åº”è¯¥æ•™ä»€ä¹ˆã€‚</p>
<ul>
<li>å¤„ç†ã€æ¸…ç†ã€åŠ è½½è‡ªå·±çš„æ•°æ®</li>
<li>å¤šæ¬¡å®éªŒå¤±è´¥ï¼Œç ”ç©¶/å‘ç°/äº†è§£æ”¹è¿›ä½ çš„ ML æ¨¡å‹çš„æ–¹æ³•ã€‚</li>
</ul>
</blockquote>
<p><img loading="lazy" src="./20201109/tips.png" alt=""  />
</p>
<h2 id="ç¯å¢ƒå‡†å¤‡">ç¯å¢ƒå‡†å¤‡<a hidden class="anchor" aria-hidden="true" href="#ç¯å¢ƒå‡†å¤‡">#</a></h2>
<p>ç¬¬ä¸€æ­¥ï¼šå¯åŠ¨è™šæ‹Ÿç¯å¢ƒ</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>âœ source activate ldl-env
</span></span></code></pre></div><p>ç¬¬äºŒæ­¥ï¼šå®‰è£… PyTorch</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span><span style="color:#f92672">(</span>ldl-env<span style="color:#f92672">)</span> âœ  workspace conda install pytorch torchvision torchaudio -c pytorch
</span></span></code></pre></div><p><img loading="lazy" src="./20201109/1.PNG" alt=""  />
</p>
<blockquote>
<p>è¦å¤šçœ‹ PyTorch çš„å®˜æ–¹æ–‡æ¡£ã€‚</p>
</blockquote>
<h2 id="æ•°æ®é›†">æ•°æ®é›†<a hidden class="anchor" aria-hidden="true" href="#æ•°æ®é›†">#</a></h2>
<h3 id="torchvisiondatasets">torchvision.datasets<a hidden class="anchor" aria-hidden="true" href="#torchvisiondatasets">#</a></h3>
<p><code>torchvision.datasets </code>ä¸­åŒ…å«äº†è¾ƒå¤šçš„<a href="https://pytorch.org/docs/stable/torchvision/datasets.html">æ•°æ®é›†</a></p>
<ul>
<li>
<p>MNISTï¼ˆ0-9 æ‰‹å†™æ•°å­—ï¼‰</p>
</li>
<li>
<p>COCOï¼ˆç”¨äºå›¾åƒæ ‡æ³¨å’Œç›®æ ‡æ£€æµ‹ï¼‰</p>
</li>
<li>
<p>LSUNï¼ˆåŒ…å«æ•°ç™¾ä¸‡ä¸ªåœºæ™¯å’Œå¯¹è±¡çš„å½©è‰²å›¾åƒï¼‰</p>
</li>
<li>
<p><strong>CIFAR-10</strong></p>
</li>
</ul>
<p><img loading="lazy" src="./20201109/3.png" alt=""  />
</p>
<p>CIFAR-10 dataset (Canadian Institute For Advanced Research) ï¼š<a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a></p>
<p>CIFAR-10 å’Œ CIFAR-100 æ˜¯ä¸€ä¸ªåŒ…å« 8000 ä¸‡å¼ å¾®å°å›¾åƒçš„æ•°æ®é›†ï¼Œç”± Alex Krizhevskyã€Vinod Nair å’Œ Geoffrey Hinton æ”¶é›†ã€‚</p>
<p><strong>CIFAR-10</strong> æ•°æ®é›†åŒ…å« 10 ä¸ªç±»åˆ«ï¼Œæ€»å…± 60000 å¼  $$32\times32$$ å½©è‰²å›¾åƒã€‚</p>
<p>æ¯ä¸ªç±»åˆ« 6000 å¼ å›¾åƒã€‚</p>
<p>æœ‰ 50000 å¼ è®­ç»ƒå›¾åƒï¼ˆtrain setï¼‰å’Œ 10000 å¼ æµ‹è¯•å›¾åƒï¼ˆtest setï¼‰ã€‚</p>
<p>æ•°æ®é›†åˆ†ä¸º 5 ä¸ªè®­ç»ƒ Batch å’Œ 1 ä¸ªæµ‹è¯• Batchã€‚æ¯ä¸ªTrain Batch æœ‰ 10000 å¼ å›¾åƒï¼ŒTest Batch æ­£å¥½åŒ…å« 1000 å¼ ä»æ¯ä¸ªç±»ä¸­éšæœºé€‰å–çš„å›¾åƒã€‚ Train Batch æŒ‰éšæœºé¡ºåºåŒ…å«å‰©ä½™çš„å›¾åƒï¼Œä½†ä¸€äº› Train Batch å¯èƒ½åŒ…å«æ¥è‡ªä¸€ä¸ªç±»çš„å›¾åƒæ¯”å¦ä¸€ä¸ªç±»æ›´å¤šã€‚åœ¨å®ƒä»¬ä¹‹é—´ï¼ŒTrain batch æ­£å¥½åŒ…å«æ¥è‡ªæ¯ä¸ªç±»çš„ 5000 å¼ å›¾åƒã€‚</p>
<p><img loading="lazy" src="./20201109/4.png" alt=""  />
</p>
<ul>
<li>Fashion-MNIST</li>
</ul>
<p>GitHub: <a href="https://github.com/zalandoresearch/fashion-mnist">https://github.com/zalandoresearch/fashion-mnist</a></p>
<p><img loading="lazy" src="./20201109/fashion-mnist-sprite.png" alt=""  />
</p>
<p>æ¯ä¸ªè®­ç»ƒå’Œæµ‹è¯•æ ·æœ¬éƒ½æŒ‰ç…§ä»¥ä¸‹ç±»åˆ«è¿›è¡Œäº†æ ‡æ³¨ï¼š</p>
<table>
<thead>
<tr>
<th>æ ‡æ³¨ç¼–å·</th>
<th>æè¿°</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>T-shirt/topï¼ˆTæ¤ï¼‰</td>
</tr>
<tr>
<td>1</td>
<td>Trouserï¼ˆè£¤å­ï¼‰</td>
</tr>
<tr>
<td>2</td>
<td>Pulloverï¼ˆå¥—è¡«ï¼‰</td>
</tr>
<tr>
<td>3</td>
<td>Dressï¼ˆè£™å­ï¼‰</td>
</tr>
<tr>
<td>4</td>
<td>Coatï¼ˆå¤–å¥—ï¼‰</td>
</tr>
<tr>
<td>5</td>
<td>Sandalï¼ˆå‡‰é‹ï¼‰</td>
</tr>
<tr>
<td>6</td>
<td>Shirtï¼ˆæ±—è¡«ï¼‰</td>
</tr>
<tr>
<td>7</td>
<td>Sneakerï¼ˆè¿åŠ¨é‹ï¼‰</td>
</tr>
<tr>
<td>8</td>
<td>Bagï¼ˆåŒ…ï¼‰</td>
</tr>
<tr>
<td>9</td>
<td>Ankle bootï¼ˆè¸é´ï¼‰</td>
</tr>
</tbody>
</table>
<p>æ‰¾åˆ°äº†ä¸€ä¸ªå¯ä¾›å‚è€ƒçš„å°é¡¹ç›®ï¼Œæ•°æ®é›†æ˜¯ CIFAR-10ã€‚</p>
<p><img loading="lazy" src="./20201109/6.png" alt=""  />
</p>
<h2 id="alexnet">AlexNet<a hidden class="anchor" aria-hidden="true" href="#alexnet">#</a></h2>
<h3 id="githubpytorch-cifar10">GitHubï¼špytorch-cifar10<a hidden class="anchor" aria-hidden="true" href="#githubpytorch-cifar10">#</a></h3>
<p>è¾“å…¥å›¾ç‰‡çš„å¤§å°ä¸º $$32\times32\times3$$</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">AlexNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_classes<span style="color:#f92672">=</span>NUM_CLASSES):
</span></span><span style="display:flex;"><span>        super(AlexNet, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>features <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">192</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">192</span>, <span style="color:#ae81ff">384</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>classifier <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Dropout(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">256</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4096</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Dropout(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4096</span>, <span style="color:#ae81ff">4096</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4096</span>, num_classes),
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>features(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(x<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>), <span style="color:#ae81ff">256</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>classifier(x)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span></code></pre></div><p>æˆ‘æŒ‰ç…§å´æ©è¾¾è€å¸ˆçš„è§†é¢‘æ•™ç¨‹ï¼Œç»˜åˆ¶äº†ä¸€ä¸ªå›¾ï¼Œå¦‚ä¸‹ã€‚</p>
<p><img loading="lazy" src="./20201109/5.jpg" alt=""  />
</p>
<h3 id="papers-with-code">Papers with Code<a hidden class="anchor" aria-hidden="true" href="#papers-with-code">#</a></h3>
<p>è¿™é‡Œçš„å›¾ç‰‡è¾“å…¥åº”è¯¥æ˜¯ $$227\times227\times3$$ï¼Œæ‰€ä»¥ç½‘ç»œçš„å†…éƒ¨ <code>kernel_size</code> å’Œ <code>stride</code> ä¼šæœ‰ä¸åŒã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">AlexNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Neural network model consisting of layers propsed by AlexNet paper.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Define and allocate layers for this neural net.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            num_classes (int): number of classes to predict with this model
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># input size should be : (b x 3 x 227 x 227)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># The image in the original paper states that width and height are 224 pixels, but</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># the dimensions after first convolution layer do not lead to 55 x 55.</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>net <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, out_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">96</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">11</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>),  <span style="color:#75715e"># (b x 96 x 55 x 55)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>LocalResponseNorm(size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>, beta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.75</span>, k<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># section 3.3</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># (b x 96 x 27 x 27)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">96</span>, <span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">5</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># (b x 256 x 27 x 27)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>LocalResponseNorm(size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>, beta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.75</span>, k<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># (b x 256 x 13 x 13)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),  <span style="color:#75715e"># (b x 384 x 13 x 13)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),  <span style="color:#75715e"># (b x 384 x 13 x 13)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),  <span style="color:#75715e"># (b x 256 x 13 x 13)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># (b x 256 x 6 x 6)</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># classifier is just a name for linear layers</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>classifier <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Dropout(p<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(in_features<span style="color:#f92672">=</span>(<span style="color:#ae81ff">256</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">6</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">6</span>), out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Dropout(p<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>, out_features<span style="color:#f92672">=</span>num_classes),
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>init_bias()  <span style="color:#75715e"># initialize bias</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">init_bias</span>(self):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> layer <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>net:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(layer, nn<span style="color:#f92672">.</span>Conv2d):
</span></span><span style="display:flex;"><span>                nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>normal_(layer<span style="color:#f92672">.</span>weight, mean<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>, std<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>)
</span></span><span style="display:flex;"><span>                nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(layer<span style="color:#f92672">.</span>bias, <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers</span>
</span></span><span style="display:flex;"><span>        nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(self<span style="color:#f92672">.</span>net[<span style="color:#ae81ff">4</span>]<span style="color:#f92672">.</span>bias, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(self<span style="color:#f92672">.</span>net[<span style="color:#ae81ff">10</span>]<span style="color:#f92672">.</span>bias, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>constant_(self<span style="color:#f92672">.</span>net[<span style="color:#ae81ff">12</span>]<span style="color:#f92672">.</span>bias, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Pass the input through the net.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            x (Tensor): input tensor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            output (Tensor): output tensor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>net(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">256</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">6</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">6</span>)  <span style="color:#75715e"># reduce the dimensions for linear layer input</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>classifier(x)
</span></span></code></pre></div><h3 id="zhihu-çŸ¥ä¹">Zhihu çŸ¥ä¹<a hidden class="anchor" aria-hidden="true" href="#zhihu-çŸ¥ä¹">#</a></h3>
<p><a href="https://zhuanlan.zhihu.com/p/29786939">https://zhuanlan.zhihu.com/p/29786939</a></p>
<p>ç»™å‡ºäº†å±€éƒ¨å“åº”å½’ä¸€åŒ–çš„å®ç°ã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.nn <span style="color:#f92672">import</span> functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.autograd <span style="color:#f92672">import</span> Variable
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">LRN</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, local_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>, beta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.75</span>, ACROSS_CHANNELS<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>):
</span></span><span style="display:flex;"><span>        super(LRN, self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>ACROSS_CHANNELS <span style="color:#f92672">=</span> ACROSS_CHANNELS
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>ACROSS_CHANNELS:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>average<span style="color:#f92672">=</span>nn<span style="color:#f92672">.</span>AvgPool3d(kernel_size<span style="color:#f92672">=</span>(local_size, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), <span style="color:#75715e">#0.2.0_4ä¼šæŠ¥é”™ï¼Œéœ€è¦åœ¨æœ€æ–°çš„åˆ†æ”¯ä¸ŠAvgPool3dæ‰æœ‰paddingå‚æ•°</span>
</span></span><span style="display:flex;"><span>                    stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>                    padding<span style="color:#f92672">=</span>(int((local_size<span style="color:#f92672">-</span><span style="color:#ae81ff">1.0</span>)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>), <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>)) 
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>average<span style="color:#f92672">=</span>nn<span style="color:#f92672">.</span>AvgPool2d(kernel_size<span style="color:#f92672">=</span>local_size,
</span></span><span style="display:flex;"><span>                    stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>                    padding<span style="color:#f92672">=</span>int((local_size<span style="color:#f92672">-</span><span style="color:#ae81ff">1.0</span>)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>alpha <span style="color:#f92672">=</span> alpha
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>beta <span style="color:#f92672">=</span> beta
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>ACROSS_CHANNELS:
</span></span><span style="display:flex;"><span>            div <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>pow(<span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            div <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>average(div)<span style="color:#f92672">.</span>squeeze(<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            div <span style="color:#f92672">=</span> div<span style="color:#f92672">.</span>mul(self<span style="color:#f92672">.</span>alpha)<span style="color:#f92672">.</span>add(<span style="color:#ae81ff">1.0</span>)<span style="color:#f92672">.</span>pow(self<span style="color:#f92672">.</span>beta)<span style="color:#75715e">#è¿™é‡Œçš„1.0å³ä¸ºbias</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            div <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>pow(<span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>            div <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>average(div)
</span></span><span style="display:flex;"><span>            div <span style="color:#f92672">=</span> div<span style="color:#f92672">.</span>mul(self<span style="color:#f92672">.</span>alpha)<span style="color:#f92672">.</span>add(<span style="color:#ae81ff">1.0</span>)<span style="color:#f92672">.</span>pow(self<span style="color:#f92672">.</span>beta)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>div(div)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span></code></pre></div><p>è¿™ä¸ªä¸“é—¨åˆ†äº† <code>layer1</code>ï¼Œ <code>layer2</code>ï¼Œ <code>layer3</code> ï¼Œæ›´åŠ çš„å¥½ç†è§£äº†ã€‚</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> torch <span style="color:#f92672">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.nn <span style="color:#f92672">import</span> functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.autograd <span style="color:#f92672">import</span> Variable
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">AlexNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_classes <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>):<span style="color:#75715e">#imagenetæ•°é‡</span>
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, out_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">96</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">11</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            LRN(local_size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-4</span>, beta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.75</span>, ACROSS_CHANNELS<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">96</span>, out_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, groups<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            LRN(local_size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-4</span>, beta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.75</span>, ACROSS_CHANNELS<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer3 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">256</span>, out_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">384</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer4 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">384</span>, out_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">384</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer5 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">384</span>, out_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>         <span style="color:#75715e">#éœ€è¦é’ˆå¯¹ä¸Šä¸€å±‚æ”¹å˜view</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer6 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">256</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Dropout()
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer7 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Dropout()
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer8 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>, out_features<span style="color:#f92672">=</span>num_classes)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer5(self<span style="color:#f92672">.</span>layer4(self<span style="color:#f92672">.</span>layer3(self<span style="color:#f92672">.</span>layer2(self<span style="color:#f92672">.</span>layer1(x)))))
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">256</span>)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer8(self<span style="color:#f92672">.</span>layer7(self<span style="color:#f92672">.</span>layer6(x)))
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span></code></pre></div><h2 id="æ€è€ƒ">æ€è€ƒ<a hidden class="anchor" aria-hidden="true" href="#æ€è€ƒ">#</a></h2>
<p>æˆ‘æœ‰å‡ ä¸ªç–‘é—®ï¼Ÿ</p>
<ul>
<li>
<p>AlexNet è®ºæ–‡é‡Œé¢çš„æ•°æ®é›†ä½¿ç”¨çš„æ˜¯ $$256\times256\times3$$ï¼Œé‡‡ç”¨æ•°æ®å¢å¼ºåçœŸæ­£è¾“å…¥åˆ°ç½‘ç»œçš„å›¾åƒ size ä¸º $$224\times224\times3$$ï¼Œä½†æ˜¯ç¼–ç¨‹å®ç°çš„æ—¶å€™ï¼Œè¾“å…¥çš„å¤§å¤šæ˜¯ $$227\times227\times3$$ è¿™ä¸ª 227 æ˜¯æ€ä¹ˆç®—å‡ºæ¥çš„ï¼Ÿ</p>
<ul>
<li>
<blockquote>
<p>2021.02.05ï¼š224 åº”è¯¥æ˜¯ä½œè€…çš„ä¸€ä¸ªå¤±è¯¯ï¼Œå…¶å®æ²¡å…³ç³»çš„ã€‚å°† 224 ä»£å…¥ç½‘ç»œï¼Œå°±ä¼šå‘ç° 224 å­˜åœ¨çš„é—®é¢˜ï¼Œ227 æ˜¯ä¸€ä¸ªæ›´å¥½çš„å–å€¼ã€‚</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>æˆ‘æ„Ÿè§‰æœ‰äººç”¨ 224ï¼Œæœ‰äººç”¨ 227ï¼Œæœ‰ä»€ä¹ˆåŒºåˆ«å—ï¼Ÿ</p>
<ul>
<li>
<blockquote>
<p>2021.02.05ï¼šç”¨ 227ï¼Œä¸è¦ç”¨ 224ã€‚ä»£å…¥ç½‘ç»œæ¨ä¸€éå°±çŸ¥é“ä¸ºä»€ä¹ˆäº†ï¼</p>
</blockquote>
</li>
</ul>
</li>
<li>
<p>ä¸Šæ–‡æˆ‘è®°å½•çš„ç¬¬ä¸€ä¸ªç¨‹åº <code>pytorch-cifar10</code>ï¼Œæ¯å¼ å›¾åƒçš„è¾“å…¥æ˜¯ $$32\times32\times3$$ã€‚è¿™ç§æƒ…å†µä¸‹ä¸€ç§å¤„ç†æ–¹å¼æ˜¯ <code>resize</code> æˆ 224ï¼›å¦ä¸€ç§æ˜¯æ›´æ”¹ç½‘ç»œçš„ kernel_sizeã€paddingã€strideï¼Œä¿®æ”¹è¿‡ä¹‹åçš„ç½‘ç»œè¿˜èƒ½å«åšæ˜¯ AlexNet å—ï¼Ÿ</p>
<ul>
<li>
<blockquote>
<p>2021.02.05ï¼šæˆ‘è®¤ä¸ºä¿®æ”¹åçš„ç½‘ç»œå°±ä¸èƒ½å«åš AlexNet äº†ã€‚</p>
<p>AlexNet ä¸­çš„å·ç§¯æ ¸å¤§å°ã€æ­¥é•¿ã€å¡«å……éƒ½æ˜¯ä½œè€…ä¸º ImageNet æ•°æ®é›†ç²¾å¿ƒè®¾è®¡çš„ã€‚</p>
</blockquote>
</li>
</ul>
</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://landodo.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">è®ºæ–‡é˜…è¯»</a></li>
      <li><a href="http://landodo.github.io/tags/alexnet/">AlexNet</a></li>
      <li><a href="http://landodo.github.io/tags/pytorch/">PyTorch</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://landodo.github.io/posts/20201113-http/">
    <span class="title">Â« Prev Page</span>
    <br>
    <span>ä½¿ç”¨ C è¯­è¨€å®ç°ä¸€ä¸ª HTTP æœåŠ¡å™¨ï¼ˆ2ï¼‰</span>
  </a>
  <a class="next" href="http://landodo.github.io/posts/20201215-network-in-network/">
    <span class="title">Next Page Â»</span>
    <br>
    <span>Network In Network</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>Landon</span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
