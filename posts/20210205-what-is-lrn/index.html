<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
<meta name="robots" content="index, follow">
<title>AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ | Landodo&#39;s NoteBook</title>
<meta name="keywords" content="æ·±åº¦å­¦ä¹ , CNN, è®ºæ–‡é˜…è¯»" />
<meta name="description" content="AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ å¯¹æˆ‘è€Œè¨€ï¼ŒLRN æ˜¯ AleNet è®ºæ–‡ä¸­çš„ä¸€ä¸ªéš¾ç‚¹ï¼Œä»Šå¤©å°±æ¥æ›´åŠ ç»†è‡´çš„ç†è§£ä¸€ä¸‹ã€‚ LRN æ“ä½œåœ¨å“ªä¸€æ­¥">
<meta name="author" content="">
<link rel="canonical" href="http://landodo.github.io/posts/20210205-what-is-lrn/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css" integrity="sha256-yIlj/i15RiAA/Q&#43;xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js" integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://landodo.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://landodo.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://landodo.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://landodo.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="http://landodo.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ" />
<meta property="og:description" content="AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ å¯¹æˆ‘è€Œè¨€ï¼ŒLRN æ˜¯ AleNet è®ºæ–‡ä¸­çš„ä¸€ä¸ªéš¾ç‚¹ï¼Œä»Šå¤©å°±æ¥æ›´åŠ ç»†è‡´çš„ç†è§£ä¸€ä¸‹ã€‚ LRN æ“ä½œåœ¨å“ªä¸€æ­¥" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://landodo.github.io/posts/20210205-what-is-lrn/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-02-15T10:17:29&#43;08:00" />
<meta property="article:modified_time" content="2021-02-15T10:17:29&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ"/>
<meta name="twitter:description" content="AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ å¯¹æˆ‘è€Œè¨€ï¼ŒLRN æ˜¯ AleNet è®ºæ–‡ä¸­çš„ä¸€ä¸ªéš¾ç‚¹ï¼Œä»Šå¤©å°±æ¥æ›´åŠ ç»†è‡´çš„ç†è§£ä¸€ä¸‹ã€‚ LRN æ“ä½œåœ¨å“ªä¸€æ­¥"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://landodo.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ",
      "item": "http://landodo.github.io/posts/20210205-what-is-lrn/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ",
  "name": "AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ",
  "description": "AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ å¯¹æˆ‘è€Œè¨€ï¼ŒLRN æ˜¯ AleNet è®ºæ–‡ä¸­çš„ä¸€ä¸ªéš¾ç‚¹ï¼Œä»Šå¤©å°±æ¥æ›´åŠ ç»†è‡´çš„ç†è§£ä¸€ä¸‹ã€‚ LRN æ“ä½œåœ¨å“ªä¸€æ­¥",
  "keywords": [
    "æ·±åº¦å­¦ä¹ ", "CNN", "è®ºæ–‡é˜…è¯»"
  ],
  "articleBody": "AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ å¯¹æˆ‘è€Œè¨€ï¼ŒLRN æ˜¯ AleNet è®ºæ–‡ä¸­çš„ä¸€ä¸ªéš¾ç‚¹ï¼Œä»Šå¤©å°±æ¥æ›´åŠ ç»†è‡´çš„ç†è§£ä¸€ä¸‹ã€‚\n LRN æ“ä½œåœ¨å“ªä¸€æ­¥ï¼Ÿ  ç­”ï¼šReLU ä¹‹åã€‚    AlexNet çš„ PyTorch å®˜æ–¹å®ç° ï¼ˆ1ï¼‰PyTorch\nhttps://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py\nPyTorch æŠŠ LRN ç»™ç§»é™¤äº†ã€‚\nï¼ˆ2ï¼‰Paper with Code\nä¸‹é¢çš„ä¸€ä¸ªæœ‰ LRN çš„ç‰ˆæœ¬ï¼Œæ¥è‡ª Paper with Codeã€‚æˆ‘è§‰å¾—æ˜¯å†™å¾—æœ€æ¸…æ™°çš„ã€‚\nhttps://github.com/dansuh17/alexnet-pytorch/blob/d0c1b1c52296ffcbecfbf5b17e1d1685b4ca6744/model.py#L40\nclass AlexNet(nn.Module):  \"\"\" Neural network model consisting of layers propsed by AlexNet paper. \"\"\"  def __init__(self, num_classes=1000):  \"\"\" Define and allocate layers for this neural net. Args: num_classes (int): number of classes to predict with this model \"\"\"  super().__init__()  # input size should be : (b x 3 x 227 x 227)  # The image in the original paper states that width and height are 224 pixels, but  # the dimensions after first convolution layer do not lead to 55 x 55.  self.net = nn.Sequential(  nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4), # (b x 96 x 55 x 55)  nn.ReLU(),  nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2), # section 3.3  nn.MaxPool2d(kernel_size=3, stride=2), # (b x 96 x 27 x 27)  nn.Conv2d(96, 256, 5, padding=2), # (b x 256 x 27 x 27)  nn.ReLU(),  nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  nn.MaxPool2d(kernel_size=3, stride=2), # (b x 256 x 13 x 13)  nn.Conv2d(256, 384, 3, padding=1), # (b x 384 x 13 x 13)  nn.ReLU(),  nn.Conv2d(384, 384, 3, padding=1), # (b x 384 x 13 x 13)  nn.ReLU(),  nn.Conv2d(384, 256, 3, padding=1), # (b x 256 x 13 x 13)  nn.ReLU(),  nn.MaxPool2d(kernel_size=3, stride=2), # (b x 256 x 6 x 6)  )  # classifier is just a name for linear layers  self.classifier = nn.Sequential(  nn.Dropout(p=0.5, inplace=True),  nn.Linear(in_features=(256 * 6 * 6), out_features=4096),  nn.ReLU(),  nn.Dropout(p=0.5, inplace=True),  nn.Linear(in_features=4096, out_features=4096),  nn.ReLU(),  nn.Linear(in_features=4096, out_features=num_classes),  )   def forward(self, x):  \"\"\" Pass the input through the net. Args: x (Tensor): input tensor Returns: output (Tensor): output tensor \"\"\"  x = self.net(x)  x = x.view(-1, 256 * 6 * 6) # reduce the dimensions for linear layer input  return self.classifier(x) éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒLRN å‘ç”Ÿåœ¨ ReLU æ¿€æ´»å‡½æ•°ä¹‹åã€‚\næ¥ä¸‹æ¥çœ‹çœ‹è®ºæ–‡æ˜¯å¦‚ä½•æè¿° LRN çš„ã€‚\nLocal Response Normalization ReLU ä¸éœ€è¦è¾“å…¥å½’ä¸€åŒ–æ¥é˜²æ­¢é¥±å’Œï¼ˆSaturationï¼‰ï¼Œè¿™æ˜¯ ReLU çš„ä¸€ä¸ªç†æƒ³æ€§è´¨ã€‚å¦‚æœè‡³å°‘æœ‰ä¸€äº›è®­ç»ƒä¾‹å­å¯¹ ReLU äº§ç”Ÿæ­£å‘è¾“å…¥ï¼Œå­¦ä¹ å°±ä¼šåœ¨è¯¥ç¥ç»å…ƒä¸­å‘ç”Ÿã€‚\nå›¾ç‰‡æ¥æºï¼šhttps://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7\nä½œè€…å‘ç°ä»¥ä¸‹å±€éƒ¨å½’ä¸€åŒ–æ–¹æ¡ˆæœ‰åŠ©äºæ³›åŒ–ã€‚å“åº”å½’ä¸€åŒ– $b_{x,y}^{i}$ ç”±å¦‚ä¸‹è¡¨è¾¾å¼å¾—åˆ°ã€‚\n $a_{x,y}^{i}$ è¡¨ç¤ºåœ¨ä½ç½® $(x,y)$ å¤„åº”ç”¨æ ¸ $i$ å·ç§¯è®¡ç®—åï¼Œå†è¿ç”¨æ¿€æ´»å‡½æ•° ReLU åçš„è¾“å‡ºã€‚ï¼ˆå³ ReLU åè¿›è¡Œ LRNï¼‰   å¦‚ä¸‹æ˜¯ LRN æ˜¯æ•´ä½“ç¤ºæ„å›¾ã€‚\n   å“åº”å½’ä¸€åŒ–å®ç°äº†ä¸€ç§å—çœŸå®ç¥ç»å…ƒç±»å‹å¯å‘çš„æ¨ªå‘æŠ‘åˆ¶å½¢å¼ï¼Œåœ¨ä½¿ç”¨ä¸åŒå†…æ ¸è®¡ç®—çš„ç¥ç»å…ƒè¾“å‡ºä¸­åˆ›é€ äº†å¤§æ´»åŠ¨çš„ç«äº‰ã€‚å¸¸é‡ kï¼Œnï¼ŒÎ± å’Œ Î² æ˜¯è¶…å‚æ•°ï¼Œå…¶å€¼æ˜¯ä½¿ç”¨éªŒè¯é›†ç¡®å®šçš„ï¼Œä½¿ç”¨ k = 2ï¼Œn = 5ï¼ŒÎ± = 10e-4ï¼ŒÎ² = 0.75ã€‚åœ¨æŸäº›å±‚ä¸­åº”ç”¨ ReLU éçº¿æ€§ååº”ç”¨äº†è¿™ç§å½’ä¸€åŒ–ã€‚\nè¿™ä¸ªæ–¹æ¡ˆæ›´æ­£ç¡®çš„è¯´æ³•æ˜¯â€äº®åº¦å½’ä¸€åŒ–â€œï¼Œå› ä¸ºæ²¡æœ‰å‡å»å¹³å‡æ´»æ€§ã€‚å“åº”å½’ä¸€åŒ–ä½¿ top-1 å’Œ top-5 é”™è¯¯ç‡åˆ†åˆ«é™ä½äº† 1.4% å’Œ 1.2%ã€‚\nåœ¨ CIFAR-10 æ•°æ®é›†ä¸Šï¼šä¸€ä¸ªå››å±‚ CNN åœ¨æ²¡æœ‰å½’ä¸€åŒ–çš„æƒ…å†µä¸‹å®ç°äº† 13% çš„æµ‹è¯•é”™è¯¯ç‡ï¼Œè€Œåœ¨å½’ä¸€åŒ–çš„æƒ…å†µä¸‹å®ç°äº† 11% çš„é”™è¯¯ç‡ã€‚\nLRN ç»†èŠ‚ æ¥ä¸‹æ¥æ·±å…¥åˆ° LRN çš„ç»†èŠ‚ï¼Œçœ‹çœ‹ LRN ç©¶ç«Ÿå®ç°äº†ä»€ä¹ˆæ ·çš„æ•ˆæœã€‚\nï¼ˆ1ï¼‰å…¬å¼çš„è§£é‡Š\n a è¡¨ç¤ºå·ç§¯å±‚ï¼ˆåŒ…æ‹¬å·ç§¯æ“ä½œå’Œæ¿€æ´»æ“ä½œï¼‰åçš„è¾“å‡ºç»“æœã€‚è¿™ä¸ªè¾“å‡ºçš„ç»“æœæ˜¯ä¸€ä¸ªå››ç»´æ•°ç»„ [batch,height,width,channel]ã€‚è¿™ä¸ªè¾“å‡ºç»“æ„ä¸­çš„ä¸€ä¸ªä½ç½® [a,b,c,d]ï¼Œå¯ä»¥ç†è§£æˆåœ¨æŸä¸€å¼ ç‰¹å¾å›¾ä¸­çš„æŸä¸€ä¸ªé€šé“ä¸‹çš„æŸä¸ªé«˜åº¦å’ŒæŸä¸ªå®½åº¦ä½ç½®çš„ç‚¹ï¼Œå³ç¬¬ a å¼ ç‰¹å¾å›¾çš„ç¬¬ d ä¸ªé€šé“ä¸‹çš„é«˜åº¦ä¸º b å®½åº¦ä¸º c çš„ç‚¹ã€‚ $a_{x,y}^{i}$ è¡¨ç¤ºç¬¬ i ç‰‡ç‰¹å¾å›¾åœ¨ä½ç½®ï¼ˆx,yï¼‰è¿ç”¨æ¿€æ´»å‡½æ•° ReLU åçš„è¾“å‡ºã€‚n æ˜¯åŒä¸€ä½ç½®ä¸Šä¸´è¿‘çš„ feature map çš„æ•°ç›®ï¼ŒN æ˜¯ç‰¹å¾å›¾çš„æ€»æ•°ã€‚   å‚æ•° $k, n, \\alphaï¼Œ\\beta$ éƒ½æ˜¯è¶…å‚æ•°ã€‚k=2ï¼Œn=5ï¼ŒÎ±=10-4ï¼ŒÎ²=0.75ã€‚  ä¸¾ä¸€ä¸ªä¾‹å­ï¼š\ni = 10, N = 96 æ—¶ï¼Œç¬¬ i=10 ä¸ªå·ç§¯æ ¸åœ¨ä½ç½®ï¼ˆx,yï¼‰å¤„çš„å–å€¼ä¸º $a_{x,y}^{i}$ï¼Œå®ƒçš„å±€éƒ¨å“åº”å½’ä¸€åŒ–è¿‡ç¨‹å¦‚ä¸‹ï¼šç”¨ $a_{x,y}^{i}$ é™¤ä»¥ç¬¬ 8ã€9ã€10ã€11ã€12 ç‰‡ç‰¹å¾å›¾ä½ç½®ï¼ˆx,yï¼‰å¤„çš„å–å€¼æ±‚å’Œã€‚\nä¹Ÿå°±æ˜¯è·¨é€šé“çš„ä¸€ä¸ª Normalization æ“ä½œã€‚\ntorch.nn.LocalResponseNorm() $$b_{c} = a_{c}\\left(k + \\frac{\\alpha}{n} â€‹ \\sum_{câ€™=\\max(0, c-n/2)}^{\\min(N-1,c+n/2)}a_{câ€™}^2\\right)^{-\\beta}$$\nInit signature: nn.LocalResponseNorm(  size:int,  alpha:float=0.0001,  beta:float=0.75,  k:float=1.0, ) - None  Docstring: Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension. Applies normalization across channels.  Args:  size: amount of neighbouring channels used for normalization  alpha: multiplicative factor. Default: 0.0001  beta: exponent. Default: 0.75  k: additive factor. Default: 1  Shape:  - Input: :math:`(N, C, *)`  - Output: :math:`(N, C, *)` (same shape as input)  Examples::    lrn = nn.LocalResponseNorm(2)   signal_2d = torch.randn(32, 5, 24, 24)   signal_4d = torch.randn(16, 5, 7, 7, 7, 7)   output_2d = lrn(signal_2d)   output_4d = lrn(signal_4d) ä½¿ç”¨ï¼š\nimport torch import torch.nn as nn  torch.__version__ # '1.7.0' lrn = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2) signal_2d = torch.randn(32, 96, 55, 55) # batch_size=32, feature_map=96Ã—55Ã—55 output_2d = lrn(signal_2d) signal_2d.shape # torch.Size([32, 96, 55, 55]) output_2d.shape # torch.Size([32, 96, 55, 55]) æ‰‹ç®—æ£€éªŒ import torch torch.__version__ '1.7.0' import torch.nn as nn lrn = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2) torch.manual_seed(666) signal_2d = torch.randn(2, 3, 2, 2) # batch_size=2, feature_map=3Ã—2Ã—2 output_2d = lrn(signal_2d) output_2d.shape torch.Size([2, 3, 2, 2]) signal_2d.shape torch.Size([2, 3, 2, 2]) signal_2d tensor([[[[-0.7747, 0.7926], [-0.0062, -0.4377]], [[ 0.4657, -0.1880], [-0.8975, 0.4169]], [[-0.3479, -0.4007], [ 0.8059, -0.1021]]], [[[-0.3055, -1.7611], [-0.6461, 0.3470]], [[ 0.9144, 1.6259], [-0.6535, -0.0865]], [[ 0.2100, 0.4811], [ 0.4506, 0.0600]]]]) output_2d tensor([[[[-0.4607, 0.4713], [-0.0037, -0.2603]], [[ 0.2769, -0.1118], [-0.5336, 0.2479]], [[-0.2069, -0.2383], [ 0.4792, -0.0607]]], [[[-0.1816, -1.0471], [-0.3842, 0.2063]], [[ 0.5437, 0.9667], [-0.3886, -0.0514]], [[ 0.1249, 0.2860], [ 0.2680, 0.0357]]]]) åˆ†æï¼š\nè¿™ä¸ª batch é‡Œé¢çš„ç¬¬ä¸€å¼ ç‰¹å¾å›¾ã€ç¬¬ä¸€ä¸ªé€šé“ã€(0,0) ä½ç½®çš„å–å€¼ä¸º -0.7747ã€‚æ¥ä¸‹æ¥åˆ†æå…¶ LRN å½’ä¸€åŒ–åçš„å€¼ã€‚\nLRN çš„è¶…å‚æ•°ï¼šsize=5, alpha=0.0001, beta=0.75, k=2ã€‚\n$$b_{c} = a_{c}\\left(k + \\frac{\\alpha}{n} â€‹ \\sum_{câ€™=\\max(0, c-n/2)}^{\\min(N-1,c+n/2)}a_{câ€™}^2\\right)^{-\\beta}$$\n$$\\frac{-0.7747}{(2 + \\frac{0.0001}{5} (0.7747^2 + 0.4657^2 + 0.3479^2))^{0.75}} = -0.4607$$\n  è·¨é€šé“æ±‚å’Œçš„ä¸‹é™ï¼šmax(0, 0 - 5/2) = 0\n  ä¸Šé™ï¼šmin(2, 0 + 5/2) = 2    LRN å½’ä¸€åŒ–å…¬å¼å†…éƒ¨çš„ç»†èŠ‚ç†è§£å°±å…ˆè¿™æ ·äº†ï¼Œè‡³äºå®ƒæ›´æ·±å±‚çš„ä½œç”¨ï¼Œä»¥åŠå®ƒä¸ºä»€ä¹ˆä¼šè¢«èˆå¼ƒï¼Œç•™åˆ°åé¢ã€‚\n",
  "wordCount" : "1768",
  "inLanguage": "en",
  "datePublished": "2021-02-15T10:17:29+08:00",
  "dateModified": "2021-02-15T10:17:29+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://landodo.github.io/posts/20210205-what-is-lrn/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Landodo's NoteBook",
    "logo": {
      "@type": "ImageObject",
      "url": "http://landodo.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://landodo.github.io/" accesskey="h" title="Landodo&#39;s NoteBook (Alt + H)">Landodo&#39;s NoteBook</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="http://landodo.github.io/search" title="ğŸ”Search (Alt &#43; /)" accesskey=/>
                    <span>ğŸ”Search</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/tags" title="Tag">
                    <span>Tag</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/cs-zoo" title="CS ZOO">
                    <span>CS ZOO</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://landodo.github.io/">Home</a>&nbsp;Â»&nbsp;<a href="http://landodo.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ
    </h1>
    <div class="post-meta"><span title='2021-02-15 10:17:29 +0800 CST'>February 15, 2021</span>&nbsp;Â·&nbsp;4 min&nbsp;Â·&nbsp;1768 words

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#alexnet-%e4%b8%ad%e7%9a%84-lrnlocal-response-normalization-%e6%98%af%e4%bb%80%e4%b9%88" aria-label="AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ">AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ</a><ul>
                        
                <li>
                    <a href="#alexnet-%e7%9a%84-pytorch-%e5%ae%98%e6%96%b9%e5%ae%9e%e7%8e%b0" aria-label="AlexNet çš„ PyTorch å®˜æ–¹å®ç°">AlexNet çš„ PyTorch å®˜æ–¹å®ç°</a></li>
                <li>
                    <a href="#local-response-normalization" aria-label="Local Response Normalization">Local Response Normalization</a></li>
                <li>
                    <a href="#lrn-%e7%bb%86%e8%8a%82" aria-label="LRN ç»†èŠ‚">LRN ç»†èŠ‚</a></li>
                <li>
                    <a href="#torchnnlocalresponsenorm" aria-label="torch.nn.LocalResponseNorm()">torch.nn.LocalResponseNorm()</a></li>
                <li>
                    <a href="#%e6%89%8b%e7%ae%97%e6%a3%80%e9%aa%8c" aria-label="æ‰‹ç®—æ£€éªŒ">æ‰‹ç®—æ£€éªŒ</a></li>
                <li>
                    <a href="#%e4%b8%8a%e9%99%90min2-0--52--2" aria-label="ä¸Šé™ï¼šmin(2, 0 &#43; 5/2) = 2">ä¸Šé™ï¼šmin(2, 0 + 5/2) = 2</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="alexnet-ä¸­çš„-lrnlocal-response-normalization-æ˜¯ä»€ä¹ˆ">AlexNet ä¸­çš„ LRNï¼ˆLocal Response Normalizationï¼‰ æ˜¯ä»€ä¹ˆ<a hidden class="anchor" aria-hidden="true" href="#alexnet-ä¸­çš„-lrnlocal-response-normalization-æ˜¯ä»€ä¹ˆ">#</a></h1>
<p>å¯¹æˆ‘è€Œè¨€ï¼ŒLRN æ˜¯ AleNet è®ºæ–‡ä¸­çš„ä¸€ä¸ªéš¾ç‚¹ï¼Œä»Šå¤©å°±æ¥æ›´åŠ ç»†è‡´çš„ç†è§£ä¸€ä¸‹ã€‚</p>
<ul>
<li>LRN æ“ä½œåœ¨å“ªä¸€æ­¥ï¼Ÿ
<ul>
<li>ç­”ï¼šReLU ä¹‹åã€‚</li>
</ul>
</li>
</ul>
<h2 id="alexnet-çš„-pytorch-å®˜æ–¹å®ç°">AlexNet çš„ PyTorch å®˜æ–¹å®ç°<a hidden class="anchor" aria-hidden="true" href="#alexnet-çš„-pytorch-å®˜æ–¹å®ç°">#</a></h2>
<p>ï¼ˆ1ï¼‰PyTorch</p>
<p><a href="https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py">https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py</a></p>
<p>PyTorch æŠŠ LRN ç»™ç§»é™¤äº†ã€‚</p>
<p>ï¼ˆ2ï¼‰Paper with Code</p>
<p>ä¸‹é¢çš„ä¸€ä¸ªæœ‰ LRN çš„ç‰ˆæœ¬ï¼Œæ¥è‡ª Paper with Codeã€‚æˆ‘è§‰å¾—æ˜¯å†™å¾—æœ€æ¸…æ™°çš„ã€‚</p>
<p><a href="https://github.com/dansuh17/alexnet-pytorch/blob/d0c1b1c52296ffcbecfbf5b17e1d1685b4ca6744/model.py#L40">https://github.com/dansuh17/alexnet-pytorch/blob/d0c1b1c52296ffcbecfbf5b17e1d1685b4ca6744/model.py#L40</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">AlexNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Neural network model consisting of layers propsed by AlexNet paper.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, num_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Define and allocate layers for this neural net.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            num_classes (int): number of classes to predict with this model
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># input size should be : (b x 3 x 227 x 227)</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># The image in the original paper states that width and height are 224 pixels, but</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># the dimensions after first convolution layer do not lead to 55 x 55.</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>net <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, out_channels<span style="color:#f92672">=</span><span style="color:#ae81ff">96</span>, kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">11</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>),  <span style="color:#75715e"># (b x 96 x 55 x 55)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>LocalResponseNorm(size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>, beta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.75</span>, k<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># section 3.3</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># (b x 96 x 27 x 27)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">96</span>, <span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">5</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># (b x 256 x 27 x 27)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>LocalResponseNorm(size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>, beta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.75</span>, k<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># (b x 256 x 13 x 13)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),  <span style="color:#75715e"># (b x 384 x 13 x 13)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),  <span style="color:#75715e"># (b x 384 x 13 x 13)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">384</span>, <span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">3</span>, padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),  <span style="color:#75715e"># (b x 256 x 13 x 13)</span>
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>),  <span style="color:#75715e"># (b x 256 x 6 x 6)</span>
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># classifier is just a name for linear layers</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>classifier <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Dropout(p<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(in_features<span style="color:#f92672">=</span>(<span style="color:#ae81ff">256</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">6</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">6</span>), out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Dropout(p<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>, out_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>ReLU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(in_features<span style="color:#f92672">=</span><span style="color:#ae81ff">4096</span>, out_features<span style="color:#f92672">=</span>num_classes),
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Pass the input through the net.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            x (Tensor): input tensor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            output (Tensor): output tensor
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>net(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">256</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">6</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">6</span>)  <span style="color:#75715e"># reduce the dimensions for linear layer input</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>classifier(x)
</span></span></code></pre></div><p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ<strong>LRN å‘ç”Ÿåœ¨ ReLU æ¿€æ´»å‡½æ•°ä¹‹åã€‚</strong></p>
<p>æ¥ä¸‹æ¥çœ‹çœ‹è®ºæ–‡æ˜¯å¦‚ä½•æè¿° LRN çš„ã€‚</p>
<h2 id="local-response-normalization">Local Response Normalization<a hidden class="anchor" aria-hidden="true" href="#local-response-normalization">#</a></h2>
<p>ReLU ä¸éœ€è¦è¾“å…¥å½’ä¸€åŒ–æ¥é˜²æ­¢é¥±å’Œï¼ˆSaturationï¼‰ï¼Œè¿™æ˜¯ ReLU çš„ä¸€ä¸ªç†æƒ³æ€§è´¨ã€‚å¦‚æœè‡³å°‘æœ‰ä¸€äº›è®­ç»ƒä¾‹å­å¯¹ ReLU äº§ç”Ÿæ­£å‘è¾“å…¥ï¼Œå­¦ä¹ å°±ä¼šåœ¨è¯¥ç¥ç»å…ƒä¸­å‘ç”Ÿã€‚</p>
<p>å›¾ç‰‡æ¥æºï¼š<a href="https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7">https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7</a></p>
<p><img loading="lazy" src="./20210205/1.png" alt=""  />
</p>
<p>ä½œè€…å‘ç°ä»¥ä¸‹å±€éƒ¨å½’ä¸€åŒ–æ–¹æ¡ˆæœ‰åŠ©äºæ³›åŒ–ã€‚å“åº”å½’ä¸€åŒ– $b_{x,y}^{i}$ ç”±å¦‚ä¸‹è¡¨è¾¾å¼å¾—åˆ°ã€‚</p>
<ul>
<li>$a_{x,y}^{i}$ è¡¨ç¤ºåœ¨ä½ç½® $(x,y)$ å¤„åº”ç”¨æ ¸ $i$ å·ç§¯è®¡ç®—åï¼Œå†è¿ç”¨æ¿€æ´»å‡½æ•° ReLU åçš„è¾“å‡ºã€‚ï¼ˆå³ ReLU åè¿›è¡Œ LRNï¼‰</li>
</ul>
<p><img loading="lazy" src="./20210205/2.png" alt=""  />
</p>
<blockquote>
<p>å¦‚ä¸‹æ˜¯ LRN æ˜¯æ•´ä½“ç¤ºæ„å›¾ã€‚</p>
</blockquote>
<blockquote>
<p><img loading="lazy" src="./20210205/3.png" alt=""  />
</p>
</blockquote>
<p>å“åº”å½’ä¸€åŒ–å®ç°äº†ä¸€ç§å—çœŸå®ç¥ç»å…ƒç±»å‹å¯å‘çš„æ¨ªå‘æŠ‘åˆ¶å½¢å¼ï¼Œåœ¨ä½¿ç”¨ä¸åŒå†…æ ¸è®¡ç®—çš„ç¥ç»å…ƒè¾“å‡ºä¸­åˆ›é€ äº†å¤§æ´»åŠ¨çš„ç«äº‰ã€‚å¸¸é‡ kï¼Œnï¼ŒÎ± å’Œ Î² æ˜¯è¶…å‚æ•°ï¼Œå…¶å€¼æ˜¯ä½¿ç”¨éªŒè¯é›†ç¡®å®šçš„ï¼Œä½¿ç”¨ k = 2ï¼Œn = 5ï¼ŒÎ± = 10e-4ï¼ŒÎ² = 0.75ã€‚åœ¨æŸäº›å±‚ä¸­åº”ç”¨ ReLU éçº¿æ€§ååº”ç”¨äº†è¿™ç§å½’ä¸€åŒ–ã€‚</p>
<p>è¿™ä¸ªæ–¹æ¡ˆæ›´æ­£ç¡®çš„è¯´æ³•æ˜¯â€äº®åº¦å½’ä¸€åŒ–â€œï¼Œå› ä¸ºæ²¡æœ‰å‡å»å¹³å‡æ´»æ€§ã€‚å“åº”å½’ä¸€åŒ–ä½¿ top-1 å’Œ top-5 é”™è¯¯ç‡åˆ†åˆ«é™ä½äº† 1.4% å’Œ 1.2%ã€‚</p>
<p>åœ¨ CIFAR-10 æ•°æ®é›†ä¸Šï¼šä¸€ä¸ªå››å±‚ CNN åœ¨æ²¡æœ‰å½’ä¸€åŒ–çš„æƒ…å†µä¸‹å®ç°äº† 13% çš„æµ‹è¯•é”™è¯¯ç‡ï¼Œè€Œåœ¨å½’ä¸€åŒ–çš„æƒ…å†µä¸‹å®ç°äº† 11% çš„é”™è¯¯ç‡ã€‚</p>
<h2 id="lrn-ç»†èŠ‚">LRN ç»†èŠ‚<a hidden class="anchor" aria-hidden="true" href="#lrn-ç»†èŠ‚">#</a></h2>
<p>æ¥ä¸‹æ¥æ·±å…¥åˆ° LRN çš„ç»†èŠ‚ï¼Œçœ‹çœ‹ LRN ç©¶ç«Ÿå®ç°äº†ä»€ä¹ˆæ ·çš„æ•ˆæœã€‚</p>
<p>ï¼ˆ1ï¼‰å…¬å¼çš„è§£é‡Š</p>
<p><img loading="lazy" src="./20210205/2.png" alt=""  />
</p>
<ul>
<li>a è¡¨ç¤º<strong>å·ç§¯å±‚ï¼ˆåŒ…æ‹¬å·ç§¯æ“ä½œå’Œæ¿€æ´»æ“ä½œï¼‰åçš„è¾“å‡ºç»“æœ</strong>ã€‚è¿™ä¸ªè¾“å‡ºçš„ç»“æœæ˜¯ä¸€ä¸ªå››ç»´æ•°ç»„ [batch,height,width,channel]ã€‚è¿™ä¸ªè¾“å‡ºç»“æ„ä¸­çš„ä¸€ä¸ªä½ç½® [a,b,c,d]ï¼Œå¯ä»¥ç†è§£æˆåœ¨æŸä¸€å¼ ç‰¹å¾å›¾ä¸­çš„æŸä¸€ä¸ªé€šé“ä¸‹çš„æŸä¸ªé«˜åº¦å’ŒæŸä¸ªå®½åº¦ä½ç½®çš„ç‚¹ï¼Œå³<strong>ç¬¬ a å¼ ç‰¹å¾å›¾çš„ç¬¬ d ä¸ªé€šé“ä¸‹çš„é«˜åº¦ä¸º b å®½åº¦ä¸º c çš„ç‚¹ã€‚</strong></li>
<li>$a_{x,y}^{i}$ è¡¨ç¤ºç¬¬ i ç‰‡ç‰¹å¾å›¾åœ¨ä½ç½®ï¼ˆx,yï¼‰è¿ç”¨æ¿€æ´»å‡½æ•° ReLU åçš„è¾“å‡ºã€‚n æ˜¯åŒä¸€ä½ç½®ä¸Šä¸´è¿‘çš„ feature map çš„æ•°ç›®ï¼ŒN æ˜¯ç‰¹å¾å›¾çš„æ€»æ•°ã€‚</li>
</ul>
<p><img loading="lazy" src="./20210205/4.png" alt=""  />
</p>
<ul>
<li>å‚æ•° $k, n, \alphaï¼Œ\beta$ éƒ½æ˜¯è¶…å‚æ•°ã€‚k=2ï¼Œn=5ï¼ŒÎ±=10-4ï¼ŒÎ²=0.75ã€‚</li>
</ul>
<p>ä¸¾ä¸€ä¸ªä¾‹å­ï¼š</p>
<p>i = 10, N = 96 æ—¶ï¼Œç¬¬ i=10 ä¸ªå·ç§¯æ ¸åœ¨ä½ç½®ï¼ˆx,yï¼‰å¤„çš„å–å€¼ä¸º $a_{x,y}^{i}$ï¼Œå®ƒçš„å±€éƒ¨å“åº”å½’ä¸€åŒ–è¿‡ç¨‹å¦‚ä¸‹ï¼šç”¨ $a_{x,y}^{i}$ é™¤ä»¥ç¬¬ 8ã€9ã€10ã€11ã€12 ç‰‡ç‰¹å¾å›¾ä½ç½®ï¼ˆx,yï¼‰å¤„çš„å–å€¼æ±‚å’Œã€‚</p>
<p>ä¹Ÿå°±æ˜¯è·¨é€šé“çš„ä¸€ä¸ª Normalization æ“ä½œã€‚</p>
<h2 id="torchnnlocalresponsenorm">torch.nn.LocalResponseNorm()<a hidden class="anchor" aria-hidden="true" href="#torchnnlocalresponsenorm">#</a></h2>
<p>$$b_{c} = a_{c}\left(k + \frac{\alpha}{n}
â€‹    \sum_{c&rsquo;=\max(0, c-n/2)}^{\min(N-1,c+n/2)}a_{c&rsquo;}^2\right)^{-\beta}$$</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-shell" data-lang="shell"><span style="display:flex;"><span>Init signature:
</span></span><span style="display:flex;"><span>nn.LocalResponseNorm<span style="color:#f92672">(</span>
</span></span><span style="display:flex;"><span>    size:int,
</span></span><span style="display:flex;"><span>    alpha:float<span style="color:#f92672">=</span>0.0001,
</span></span><span style="display:flex;"><span>    beta:float<span style="color:#f92672">=</span>0.75,
</span></span><span style="display:flex;"><span>    k:float<span style="color:#f92672">=</span>1.0,
</span></span><span style="display:flex;"><span><span style="color:#f92672">)</span> -&gt; None
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Docstring:     
</span></span><span style="display:flex;"><span>Applies local response normalization over an input signal composed
</span></span><span style="display:flex;"><span>of several input planes, where channels occupy the second dimension.
</span></span><span style="display:flex;"><span>Applies normalization across channels.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Args:
</span></span><span style="display:flex;"><span>    size: amount of neighbouring channels used <span style="color:#66d9ef">for</span> normalization
</span></span><span style="display:flex;"><span>    alpha: multiplicative factor. Default: 0.0001
</span></span><span style="display:flex;"><span>    beta: exponent. Default: 0.75
</span></span><span style="display:flex;"><span>    k: additive factor. Default: <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Shape:
</span></span><span style="display:flex;"><span>    - Input: :math:<span style="color:#e6db74">`</span><span style="color:#f92672">(</span>N, C, *<span style="color:#f92672">)</span><span style="color:#e6db74">`</span>
</span></span><span style="display:flex;"><span>    - Output: :math:<span style="color:#e6db74">`</span><span style="color:#f92672">(</span>N, C, *<span style="color:#f92672">)</span><span style="color:#e6db74">`</span> <span style="color:#f92672">(</span>same shape as input<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Examples::
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    &gt;&gt;&gt; lrn <span style="color:#f92672">=</span> nn.LocalResponseNorm<span style="color:#f92672">(</span>2<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    &gt;&gt;&gt; signal_2d <span style="color:#f92672">=</span> torch.randn<span style="color:#f92672">(</span>32, 5, 24, 24<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    &gt;&gt;&gt; signal_4d <span style="color:#f92672">=</span> torch.randn<span style="color:#f92672">(</span>16, 5, 7, 7, 7, 7<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    &gt;&gt;&gt; output_2d <span style="color:#f92672">=</span> lrn<span style="color:#f92672">(</span>signal_2d<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>    &gt;&gt;&gt; output_4d <span style="color:#f92672">=</span> lrn<span style="color:#f92672">(</span>signal_4d<span style="color:#f92672">)</span>
</span></span></code></pre></div><p>ä½¿ç”¨ï¼š</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>__version__
</span></span><span style="display:flex;"><span><span style="color:#75715e"># &#39;1.7.0&#39;</span>
</span></span><span style="display:flex;"><span>lrn <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LocalResponseNorm(size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>, beta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.75</span>, k<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>signal_2d <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">96</span>, <span style="color:#ae81ff">55</span>, <span style="color:#ae81ff">55</span>) <span style="color:#75715e"># batch_size=32, feature_map=96Ã—55Ã—55</span>
</span></span><span style="display:flex;"><span>output_2d <span style="color:#f92672">=</span> lrn(signal_2d)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>signal_2d<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span><span style="color:#75715e"># torch.Size([32, 96, 55, 55])</span>
</span></span><span style="display:flex;"><span>output_2d<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span><span style="color:#75715e"># torch.Size([32, 96, 55, 55])</span>
</span></span></code></pre></div><h2 id="æ‰‹ç®—æ£€éªŒ">æ‰‹ç®—æ£€éªŒ<a hidden class="anchor" aria-hidden="true" href="#æ‰‹ç®—æ£€éªŒ">#</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>__version__
</span></span></code></pre></div><pre tabindex="0"><code>&#39;1.7.0&#39;
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>lrn <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LocalResponseNorm(size<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>, beta<span style="color:#f92672">=</span><span style="color:#ae81ff">0.75</span>, k<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>torch<span style="color:#f92672">.</span>manual_seed(<span style="color:#ae81ff">666</span>)
</span></span></code></pre></div><pre tabindex="0"><code>&lt;torch._C.Generator at 0x7ffd61652d38&gt;
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>signal_2d <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randn(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>) <span style="color:#75715e"># batch_size=2, feature_map=3Ã—2Ã—2</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>output_2d <span style="color:#f92672">=</span> lrn(signal_2d)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>output_2d<span style="color:#f92672">.</span>shape
</span></span></code></pre></div><pre tabindex="0"><code>torch.Size([2, 3, 2, 2])
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>signal_2d<span style="color:#f92672">.</span>shape
</span></span></code></pre></div><pre tabindex="0"><code>torch.Size([2, 3, 2, 2])
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>signal_2d
</span></span></code></pre></div><pre tabindex="0"><code>tensor([[[[-0.7747,  0.7926],
          [-0.0062, -0.4377]],

         [[ 0.4657, -0.1880],
          [-0.8975,  0.4169]],

         [[-0.3479, -0.4007],
          [ 0.8059, -0.1021]]],
         
        [[[-0.3055, -1.7611],
          [-0.6461,  0.3470]],

         [[ 0.9144,  1.6259],
          [-0.6535, -0.0865]],

         [[ 0.2100,  0.4811],
          [ 0.4506,  0.0600]]]])
</code></pre><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>output_2d
</span></span></code></pre></div><pre tabindex="0"><code>tensor([[[[-0.4607,  0.4713],
          [-0.0037, -0.2603]],

         [[ 0.2769, -0.1118],
          [-0.5336,  0.2479]],

         [[-0.2069, -0.2383],
          [ 0.4792, -0.0607]]],
         
         
        [[[-0.1816, -1.0471],
          [-0.3842,  0.2063]],

         [[ 0.5437,  0.9667],
          [-0.3886, -0.0514]],

         [[ 0.1249,  0.2860],
          [ 0.2680,  0.0357]]]])
</code></pre><p>åˆ†æï¼š</p>
<p>è¿™ä¸ª batch é‡Œé¢çš„ç¬¬ä¸€å¼ ç‰¹å¾å›¾ã€ç¬¬ä¸€ä¸ªé€šé“ã€(0,0) ä½ç½®çš„å–å€¼ä¸º -0.7747ã€‚æ¥ä¸‹æ¥åˆ†æå…¶ LRN å½’ä¸€åŒ–åçš„å€¼ã€‚</p>
<p>LRN çš„è¶…å‚æ•°ï¼š<code>size=5, alpha=0.0001, beta=0.75, k=2</code>ã€‚</p>
<p>$$b_{c} = a_{c}\left(k + \frac{\alpha}{n}
â€‹    \sum_{c&rsquo;=\max(0, c-n/2)}^{\min(N-1,c+n/2)}a_{c&rsquo;}^2\right)^{-\beta}$$</p>
<p>$$\frac{-0.7747}{(2 + \frac{0.0001}{5} (0.7747^2 + 0.4657^2 + 0.3479^2))^{0.75}} = -0.4607$$</p>
<ul>
<li>
<p>è·¨é€šé“æ±‚å’Œçš„ä¸‹é™ï¼šmax(0, 0 - 5/2) = 0</p>
</li>
<li>
<h2 id="ä¸Šé™min2-0--52--2">ä¸Šé™ï¼šmin(2, 0 + 5/2) = 2<a hidden class="anchor" aria-hidden="true" href="#ä¸Šé™min2-0--52--2">#</a></h2>
</li>
</ul>
<p><img loading="lazy" src="./20210205/5.png" alt=""  />
</p>
<hr>
<p>LRN å½’ä¸€åŒ–å…¬å¼å†…éƒ¨çš„ç»†èŠ‚ç†è§£å°±å…ˆè¿™æ ·äº†ï¼Œè‡³äºå®ƒæ›´æ·±å±‚çš„ä½œç”¨ï¼Œä»¥åŠå®ƒä¸ºä»€ä¹ˆä¼šè¢«èˆå¼ƒï¼Œç•™åˆ°åé¢ã€‚</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://landodo.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">æ·±åº¦å­¦ä¹ </a></li>
      <li><a href="http://landodo.github.io/tags/cnn/">CNN</a></li>
      <li><a href="http://landodo.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">è®ºæ–‡é˜…è¯»</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://landodo.github.io/posts/20210301-attention-mechanism/">
    <span class="title">Â« Prev Page</span>
    <br>
    <span>Attention mechanism: SENet &amp; SKNet</span>
  </a>
  <a class="next" href="http://landodo.github.io/posts/20210130-pytorch-paper-reading-1/">
    <span class="title">Next Page Â»</span>
    <br>
    <span>PyTorch: An Imperative Style, High-Performance Deep Learning Library</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>Landon</span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
