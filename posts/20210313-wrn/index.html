<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
<meta name="robots" content="index, follow">
<title>Wide Residual Networks | Landodo&#39;s NoteBook</title>
<meta name="keywords" content="CNN, è®ºæ–‡é˜…è¯»" />
<meta name="description" content="Wide Residual Networks arXiv: 1605.07146v4 æ³•å›½ Abstract æ·±åº¦æ®‹å·®ç½‘ç»œè¢«è¯æ˜èƒ½å¤Ÿæ‰©å±•åˆ°æ•°åƒå±‚ï¼Œä¸æ–­çš„æé«˜æ€§èƒ½ã€‚ ä½†æ˜¯ï¼Œç²¾åº¦æé«˜çš„æ¯ä¸€å°éƒ¨åˆ†éƒ½è¦å¢åŠ è¿‘ä¸€å€çš„å±‚æ•°ï¼Œè€Œè®­ç»ƒå¾ˆæ·±çš„æ®‹å·®ç½‘ç»œæœ‰ä¸€">
<meta name="author" content="">
<link rel="canonical" href="http://landodo.github.io/posts/20210313-wrn/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css" integrity="sha256-yIlj/i15RiAA/Q&#43;xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js" integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://landodo.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://landodo.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://landodo.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://landodo.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="http://landodo.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Wide Residual Networks" />
<meta property="og:description" content="Wide Residual Networks arXiv: 1605.07146v4 æ³•å›½ Abstract æ·±åº¦æ®‹å·®ç½‘ç»œè¢«è¯æ˜èƒ½å¤Ÿæ‰©å±•åˆ°æ•°åƒå±‚ï¼Œä¸æ–­çš„æé«˜æ€§èƒ½ã€‚ ä½†æ˜¯ï¼Œç²¾åº¦æé«˜çš„æ¯ä¸€å°éƒ¨åˆ†éƒ½è¦å¢åŠ è¿‘ä¸€å€çš„å±‚æ•°ï¼Œè€Œè®­ç»ƒå¾ˆæ·±çš„æ®‹å·®ç½‘ç»œæœ‰ä¸€" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://landodo.github.io/posts/20210313-wrn/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-03-13T10:17:29&#43;08:00" />
<meta property="article:modified_time" content="2021-03-13T10:17:29&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Wide Residual Networks"/>
<meta name="twitter:description" content="Wide Residual Networks arXiv: 1605.07146v4 æ³•å›½ Abstract æ·±åº¦æ®‹å·®ç½‘ç»œè¢«è¯æ˜èƒ½å¤Ÿæ‰©å±•åˆ°æ•°åƒå±‚ï¼Œä¸æ–­çš„æé«˜æ€§èƒ½ã€‚ ä½†æ˜¯ï¼Œç²¾åº¦æé«˜çš„æ¯ä¸€å°éƒ¨åˆ†éƒ½è¦å¢åŠ è¿‘ä¸€å€çš„å±‚æ•°ï¼Œè€Œè®­ç»ƒå¾ˆæ·±çš„æ®‹å·®ç½‘ç»œæœ‰ä¸€"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://landodo.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Wide Residual Networks",
      "item": "http://landodo.github.io/posts/20210313-wrn/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Wide Residual Networks",
  "name": "Wide Residual Networks",
  "description": "Wide Residual Networks arXiv: 1605.07146v4 æ³•å›½ Abstract æ·±åº¦æ®‹å·®ç½‘ç»œè¢«è¯æ˜èƒ½å¤Ÿæ‰©å±•åˆ°æ•°åƒå±‚ï¼Œä¸æ–­çš„æé«˜æ€§èƒ½ã€‚ ä½†æ˜¯ï¼Œç²¾åº¦æé«˜çš„æ¯ä¸€å°éƒ¨åˆ†éƒ½è¦å¢åŠ è¿‘ä¸€å€çš„å±‚æ•°ï¼Œè€Œè®­ç»ƒå¾ˆæ·±çš„æ®‹å·®ç½‘ç»œæœ‰ä¸€",
  "keywords": [
    "CNN", "è®ºæ–‡é˜…è¯»"
  ],
  "articleBody": "Wide Residual Networks arXiv: 1605.07146v4\næ³•å›½\nAbstract æ·±åº¦æ®‹å·®ç½‘ç»œè¢«è¯æ˜èƒ½å¤Ÿæ‰©å±•åˆ°æ•°åƒå±‚ï¼Œä¸æ–­çš„æé«˜æ€§èƒ½ã€‚\nä½†æ˜¯ï¼Œç²¾åº¦æé«˜çš„æ¯ä¸€å°éƒ¨åˆ†éƒ½è¦å¢åŠ è¿‘ä¸€å€çš„å±‚æ•°ï¼Œè€Œè®­ç»ƒå¾ˆæ·±çš„æ®‹å·®ç½‘ç»œæœ‰ä¸€ä¸ªç‰¹å¾é‡ç”¨é€’å‡ï¼ˆdiminishing feature reuseï¼‰çš„é—®é¢˜ï¼Œè¿™ä½¿å¾—è¿™äº›ç½‘ç»œçš„è®­ç»ƒé€Ÿåº¦éå¸¸æ…¢ã€‚\nä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡å¯¹ ResNet block çš„æ¶æ„è¿›è¡Œäº†è¯¦ç»†çš„å®éªŒç ”ç©¶ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„æ¶æ„ï¼Œå³å‡å°‘æ·±åº¦ï¼Œå¢åŠ æ®‹å·®ç½‘ç»œçš„å®½åº¦ï¼ˆ decrease depth and increase width of residual networks. ï¼‰ã€‚\næœ¬ç¯‡è®ºæ–‡æå‡ºçš„ç½‘ç»œè¢«ç§°ä¸º wide residual networks (WRNs)ï¼Œå®éªŒè¯æ˜ï¼Œä¸€ä¸ªç®€å•çš„ 16 å±‚æ·±çš„ WRNï¼Œç²¾åº¦å’Œæ•ˆç‡ä¸Šä¼˜äºä»¥å‰æ‰€æœ‰çš„æ·±æ®‹å·®ç½‘ç»œï¼ŒåŒ…æ‹¬åƒå±‚æ·±ç½‘ç»œã€‚\nWRN åœ¨ CIFARã€SVHNã€COCO æ•°æ®é›†ä¸Šå–å¾— SOTAã€‚\n1 Introduction å·ç§¯ç¥ç»ç½‘ç»œåœ¨è¿‡å»å‡ å¹´ä¸­ï¼Œå±‚æ•°é€æ¸å¢åŠ ï¼šAlexNetï¼ŒVGGï¼ŒInceptionï¼ŒResNetã€‚\nè®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œå­˜åœ¨å‡ ä¸ªå›°éš¾ï¼ŒåŒ…æ‹¬æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±å’Œç½‘ç»œé€€åŒ–ï¼ˆexploding/vanishing gradients and degradation.ï¼‰ã€‚è®­ç»ƒæ·±å±‚çš„ç¥ç»ç½‘ç»œæœ‰å¦‚ä¸‹æŠ€å·§ï¼š\n well-designed initialization strategies better optimizers skip connections knowledge transfer layer-wise training  æœ€è¿‘çš„ ResNet åœ¨ ImageNetã€CIFARã€PASCAL VOCã€MS COCO ä¸Šå–å¾—äº† SOTAã€‚ä¸ Inception æ¶æ„ç›¸æ¯”ï¼ŒResNet è¡¨ç°å‡ºäº†æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¿™æ„å‘³ç€ç‰¹å¾å¯ä»¥åœ¨è¿ç§»å­¦ä¹ ä¸­è¢«åˆ©ç”¨ï¼Œæ•ˆç‡æ›´é«˜ã€‚\nç ”ç©¶è¡¨æ˜ï¼Œæ®‹å·®è¿æ¥åŠ å¿«äº†ç½‘ç»œçš„æ”¶æ•›ã€‚\nHighway Network åœ¨ ResNet ä¹‹å‰è¢«æå‡ºï¼ŒHighway Network ä¸­çš„æ®‹å·®é“¾è·¯æ˜¯é—¨æ§çš„ï¼Œè¿™äº›é—¨çš„æƒé‡æ˜¯å¯å­¦ä¹ çš„ã€‚\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œå¯¹æ®‹å·®ç½‘ç»œçš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ ResNet å—å†…çš„æ¿€æ´»é¡ºåºå’Œæ®‹å·®ç½‘ç»œçš„æ·±åº¦ä¸Šã€‚æœ¬ç¯‡è®ºæ–‡çš„çš„å·¥ä½œæ˜¯æ¢ç´¢ä¸€å¥—æ›´ä¸°å¯Œçš„ ResNet å—çš„ç½‘ç»œæ¶æ„ï¼Œå¹¶å½»åº•ç ”ç©¶é™¤äº†æ¿€æ´»é¡ºåºä¹‹å¤–çš„å…¶ä»–å‡ ä¸ªä¸åŒæ–¹é¢å¦‚ä½•å½±å“æ€§èƒ½ã€‚\nWidth vs depth in residual networks.ï¼ˆæ®‹å·®ç½‘ç»œçš„å®½åº¦ä¸æ·±åº¦ï¼‰\næ®‹å·®ç½‘ç»œçš„ä½œè€…è¯•å›¾å°†ç½‘ç»œå°½å¯èƒ½åœ°åšå¾—æ›´è–„ï¼Œè€Œå€¾å‘äºå¢åŠ å…¶æ·±åº¦å’Œæ›´å°‘çš„å‚æ•°ï¼Œç”šè‡³å¼•å…¥äº†ä¸€ä¸ªâ€ç“¶é¢ˆâ€œå—ï¼ˆÂ«bottleneckÂ» blockï¼‰ï¼Œä½¿å¾— ResNet å—æ›´è–„ã€‚\nä½œè€…ä»¬æ³¨æ„åˆ°ï¼Œå¸¦æœ‰æ’ç­‰æ˜ å°„ï¼ˆidentity mappingï¼‰çš„æ®‹å·®å—å¯ä»¥è®­ç»ƒéå¸¸æ·±çš„ç½‘ç»œï¼Œè¿™è¿™æ˜¯æ®‹å·®ç½‘ç»œçš„ä¼˜ç‚¹ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸€ä¸ªå¼±ç‚¹ã€‚ç”±äºæ¢¯åº¦æµç»ç½‘ç»œæ—¶ï¼Œæ²¡æœ‰ä»€ä¹ˆä¸œè¥¿å¯ä»¥å¼ºè¿«å®ƒé€šè¿‡æ®‹å·®å—æƒé‡ï¼Œå®ƒå¯ä»¥é¿å…åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ ä»»ä½•ä¸œè¥¿ï¼Œæ‰€ä»¥æœ‰å¯èƒ½åªæœ‰å°‘æ•°å‡ ä¸ªå—å¯ä»¥å­¦ä¹ åˆ°æœ‰ç”¨çš„è¡¨å¾ï¼Œæˆ–è€…å¾ˆå¤šå—å…±äº«çš„ä¿¡æ¯éå¸¸å°‘ï¼Œå¯¹æœ€ç»ˆç›®æ ‡çš„è´¡çŒ®å¾ˆå°ã€‚è¿™ä¸ªé—®é¢˜è¢«ç§°ä¸ºé€’å‡ç‰¹å¾é‡ç”¨ï¼ˆdiminishing feature reuseï¼‰ï¼Œï¼ˆDeep networks with stochastic depthï¼‰è¯•å›¾ç”¨åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºç¦ç”¨æ®‹å·®å—çš„æƒ³æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚\nè¿™ç¯‡è®ºæ–‡å»ºç«‹åœ¨ â€œIdentity mappings in deep residual networksâ€ ä¹‹ä¸Šï¼Œè¯•å›¾å›ç­”æ·±åº¦æ®‹å·®ç½‘ç»œåº”è¯¥æœ‰å¤šå®½çš„é—®é¢˜ï¼Œå¹¶è§£å†³è®­ç»ƒä¸­å­˜åœ¨çš„é—®é¢˜ã€‚\nå®éªŒè¡¨æ˜ï¼Œä¸å¢åŠ æ®‹å·®ç½‘ç»œçš„æ·±åº¦ç›¸æ¯”ï¼Œæ‹“å®½ ResNet å—æä¾›äº†ä¸€ç§æ›´æœ‰æ•ˆçš„æ–¹æ³•æ¥æé«˜æ®‹å·®ç½‘ç»œçš„æ€§èƒ½ã€‚wider deep residual networks æ¯” ResNet æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå±‚æ•°å‡å°‘äº† 50 å€ï¼Œé€Ÿåº¦å¿«äº† 2 å€ä»¥ä¸Šã€‚\nwide 16-layer deep network ä¸ 1000-layer thin deep network çš„ç²¾åº¦ç›¸åŒï¼Œå‚æ•°æ•°é‡ä¹Ÿç›¸å½“ï¼Œä¸è¿‡å‰è€…è®­ç»ƒé€Ÿåº¦è¦å¿«å‡ å€ã€‚è¿™æš—ç¤ºäº†æ·±åº¦æ®‹å·®ç½‘ç»œçš„ä¸»è¦åŠ›é‡åœ¨æ®‹å·®å—ï¼Œæ·±åº¦çš„å½±å“æ˜¯è¾…åŠ©æ€§çš„ã€‚\n**Use of dropout in ResNet blocks. **\nDropout è¾ƒå¤šåº”ç”¨äºå‚æ•°è¾ƒå¤šçš„é¡¶å±‚ï¼Œä»¥é˜²æ­¢ç‰¹å¾å…±é€‚åº”å’Œè¿‡æ‹Ÿåˆã€‚\nåæ¥ï¼Œdropout è¢« Batch normalization ä»£æ›¿ï¼ŒBN çš„ç½‘ç»œæ¯”æœ‰ dropout çš„ç½‘ç»œèƒ½è¾¾åˆ°æ›´å¥½çš„ç²¾åº¦ã€‚ï¼ˆBatch normalization: Accelerating deep network training by reducing internal covariate shift.ï¼‰\nkaiming He ç ”ç©¶è¡¨æ˜ï¼Œåœ¨ ResNet ä¸­å¼•å…¥ dropout ä¼šäº§ç”Ÿè´Ÿé¢çš„ä½œç”¨ã€‚åœ¨å®½æ®‹å·®ç½‘ç»œï¼ˆWRNï¼‰ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œå¼•å…¥ dropout åï¼Œåœ¨ä¸€äº›æ•°æ®é›†ä¸Šå–å¾—äº† SOTAã€‚\næœ¬ç¯‡è®ºæ–‡çš„è´¡çŒ®æ€»ç»“å¦‚ä¸‹ï¼š\n å¯¹æ®‹å·®ç½‘ç»œæ¶æ„è¿›è¡Œäº†è¯¦ç»†çš„å®éªŒç ”ç©¶ï¼Œå½»åº•ç ”ç©¶äº† ResNet å—ç»“æ„çš„å‡ ä¸ªé‡è¦æ–¹é¢ã€‚ æå‡ºäº†ä¸€ç§ widened architecture for ResNet blocksï¼Œä½¿æ®‹ä½™ç½‘ç»œçš„æ€§èƒ½å¾—åˆ°æ˜¾è‘—æé«˜ã€‚ æå‡ºäº†ä¸€ç§åœ¨æ·±åº¦æ®‹å·®ç½‘ç»œä¸­åˆ©ç”¨ dropout çš„æ–°æ–¹æ³•ã€‚ WRN åœ¨å‡ ä¸ªæ•°æ®é›†ä¸Šå–å¾— SOTAã€‚  2 Wide residual networks æ’ç­‰æ˜ å°„çš„æ®‹å·®å—è¡¨ç¤ºå¦‚ä¸‹ï¼š\n å…¶ä¸­ $x_{l+1}$ å’Œ $x_l$ ä¸ºç½‘ç»œä¸­ç¬¬ $l$ ä¸ªå•å…ƒçš„è¾“å…¥å’Œè¾“å‡ºï¼Œ$F$ ä¸ºæ®‹å·®å‡½æ•°ï¼Œ$W_l$ ä¸ºå—çš„å‚æ•°ã€‚æ®‹å·®ç½‘ç»œç”±ä¾æ¬¡å åŠ çš„æ®‹å·®å—ç»„æˆã€‚  æ®‹å·®ç½‘ç»œç”±ä¸¤ç§ç±»å‹çš„å—ç»„æˆï¼š\nï¼ˆ1ï¼‰basicï¼šç”¨ä¸¤ä¸ªè¿ç»­çš„ 3Ã—3 å·ç§¯ä¸æ‰¹é‡å½’ä¸€åŒ–ã€ReLU å‰é¢çš„å·ç§¯ï¼šconv3Ã—3-conv3Ã—3 å›¾ 1(a)\nï¼ˆ2ï¼‰bottleneckï¼šæœ‰ä¸€ä¸ª 3Ã—3 å·ç§¯ï¼Œå‰åæœ‰é™ç»´å’Œæ‰©å±•çš„ 1Ã—1 å·ç§¯å±‚ï¼šconv1Ã—1-conv3Ã—3-conv1Ã—1 å›¾1(b)\nä¸åŸæ¶æ„ï¼ˆDeep residual learning for image recognitionï¼‰ç›¸æ¯”ï¼Œåœ¨ï¼ˆIdentity mappings in deep residual networksï¼‰ä¸­ï¼Œå°† batch normalizationã€activationã€convolution çš„é¡ºåºç”± conv-BN-ReLU æ”¹ä¸º BN-ReLU- convã€‚åè€…è¢«è¯æ˜è®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå–å¾—äº†æ›´å¥½çš„æ•ˆæœã€‚\næ‰€è°“çš„ â€bottleneck blockâ€œ æœ€åˆæ˜¯ç”¨æ¥ä½¿ block çš„è®¡ç®—æˆæœ¬é™ä½ï¼Œä»¥å¢åŠ å±‚æ•°ã€‚ç”±äºæœ¬ç¯‡è®ºæ–‡è¦ç ”ç©¶åŠ å®½çš„æ•ˆæœï¼Œè€Œ â€bottleneck blockâ€œ æ˜¯ç”¨æ¥è®©ç½‘ç»œå˜è–„çš„ï¼Œæ‰€ä»¥ä¸è€ƒè™‘å®ƒï¼Œè€Œæ˜¯å…³æ³¨ â€basic blockâ€œ çš„æ®‹å·®æ¶æ„ã€‚\næœ‰ä¸‰ç§ç®€å•çš„æ–¹æ³•å¯ä»¥æé«˜æ®‹å·®å—çš„è¡¨ç¤ºåŠ›ã€‚\n to add more convolutional layers per block âœ… to widen the convolutional layers by adding more feature planes to increase filter sizes in convolutional layers  å¼•å…¥ä¸¤ä¸ªå‚æ•°ï¼š\n deepening factor lï¼šl è¡¨ç¤ºä¸€ä¸ªåŒºå—ä¸­çš„å·ç§¯æ•°ã€‚ widening factor kï¼šk å€çš„ç‰¹å¾æ•°é‡ï¼ˆç‰¹å¾å›¾çš„ç‰‡æ•°ï¼Œå³å·ç§¯æ ¸çš„ä¸ªæ•°ï¼‰  å› æ­¤ï¼ŒResNet baseline ä¸­çš„ â€basic blockâ€œ å¯¹åº”çš„æ˜¯ lï¼2ï¼Œkï¼1ã€‚å›¾ 1(a) å’Œå›¾ 1(c) åˆ†åˆ«æ˜¾ç¤ºäº† Â«basicÂ» å’Œ Â«basic-wideÂ» blocksã€‚\nWRN ç»“æ„å¦‚ Table 1 æ‰€ç¤ºï¼š\nå®ƒç”±ä¸€ä¸ªåˆå§‹å·ç§¯å±‚ conv1 ç»„æˆï¼Œä¹‹åæ˜¯ 3 ç»„ï¼ˆæ¯ç»„å¤§å°ä¸º Nï¼‰æ®‹å·®å— conv2ã€conv3 å’Œ conv4ï¼Œç„¶åæ˜¯å¹³å‡æ± å’Œæœ€ç»ˆåˆ†ç±»å±‚ã€‚\nåœ¨æ‰€æœ‰çš„å®éªŒä¸­ï¼Œconv1 çš„å¤§å°éƒ½æ˜¯å›ºå®šçš„ï¼Œè€Œå¼•å…¥çš„åŠ å®½å› å­ k åˆ™å¯¹ 3 ç»„ conv2-4 ä¸­çš„æ®‹å·®å—çš„å®½åº¦è¿›è¡Œäº†ç¼©æ”¾ï¼ˆä¾‹å¦‚ï¼ŒåŸæ¥çš„ â€basicâ€œ æ¶æ„ç›¸å½“äº k=1ï¼‰ã€‚\n2.1 Type of convolutions in residual block è®© B(M) è¡¨ç¤ºæ®‹å·®å—ç»“æ„ï¼Œå…¶ä¸­ M æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­æœ‰å—ä¸­å·ç§¯å±‚çš„æ ¸å¤§å°ã€‚\nä¾‹å¦‚ï¼ŒB(3, 1) è¡¨ç¤ºå…·æœ‰ 3Ã—3 å’Œ 1Ã—1 å·ç§¯å±‚çš„æ®‹å·®å—ã€‚è¯·æ³¨æ„ï¼Œç”±äºæˆ‘ä»¬ä¸è€ƒè™‘å‰é¢è§£é‡Šçš„ â€œç“¶é¢ˆ â€œå—ï¼Œæ‰€ä»¥åœ¨æ•´ä¸ªå—ä¸­ï¼Œç‰¹å¾å¹³é¢çš„æ•°é‡å§‹ç»ˆä¿æŒä¸å˜ï¼ˆæ‰€æœ‰ block ä¸­ï¼Œä½¿ç”¨å·ç§¯æ ¸çš„æ•°é‡ç›¸åŒï¼‰ã€‚\nè®ºæ–‡æƒ³è¦ç ”ç©¶çš„æ˜¯ï¼Œâ€basic blockâ€œ æ®‹å·®æ¶æ„çš„ 3Ã—3 å·ç§¯å±‚ä¸­çš„æ¯ä¸€ä¸ªå±‚çš„é‡è¦ç¨‹åº¦ï¼Œæ˜¯å¦å¯ä»¥ç”¨è®¡ç®—æˆæœ¬è¾ƒä½çš„ 1Ã—1 å±‚ï¼Œç”šè‡³æ˜¯ 1Ã—1 å’Œ 3Ã—3 å·ç§¯å±‚çš„ç»„åˆæ¥ä»£æ›¿ã€‚ä¾‹å¦‚ï¼ŒB(1,3) æˆ– B(1,3)ã€‚è¿™å¯ä»¥å¢åŠ æˆ–å‡å°‘å—çš„è¡¨ç¤ºèƒ½åŠ›ã€‚\nå› æ­¤ï¼Œè¯•éªŒäº†ä»¥ä¸‹ç»„åˆï¼ˆæ³¨æ„ï¼Œæœ€åä¸€ä¸ªç»„åˆï¼Œå³ B(3,1,1) ä¸Network in Network æ¶æ„ç›¸ä¼¼ï¼‰ã€‚\n2.2 Number of convolutional layers per residual block è¿˜å¯¹åŒºå—åŠ æ·±å› å­ l è¿›è¡Œå®éªŒï¼Œçœ‹çœ‹å®ƒå¯¹æ€§èƒ½çš„å½±å“ã€‚æ¯”è¾ƒå¿…é¡»åœ¨å‚æ•°æ•°é‡ç›¸åŒçš„ç½‘ç»œä¸­è¿›è¡Œï¼Œæ‰€ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œéœ€è¦åœ¨ç¡®ä¿ç½‘ç»œå¤æ‚åº¦ä¿æŒå¤§è‡´ä¸å˜çš„æƒ…å†µä¸‹ï¼Œæ„å»ºä¸åŒ l å’Œ dï¼ˆå…¶ä¸­ d è¡¨ç¤ºå—çš„æ€»æ•°é‡ï¼‰çš„ç½‘ç»œã€‚ä¾‹å¦‚ï¼Œè¿™æ„å‘³ç€åªè¦ l å¢åŠ ï¼Œd å°±åº”è¯¥å‡å°‘ã€‚\n2.3 Width of residual blocks  While the number of parameters increases linearly with l (the deepening factor) and d (the number of ResNet blocks), number of parameters and computational complexity are quadratic in k.\n å‚æ•°é‡éšç€ lï¼ˆåŠ æ·±å› å­ï¼‰å’Œ dï¼ˆResNet å—æ•°ï¼‰çš„å¢åŠ è€Œçº¿æ€§å¢åŠ ï¼Œä½†å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦æ˜¯ k çš„å¹³æ–¹ã€‚\nå…³äºæ›´å®½çš„æ®‹å·®ç½‘ç»œçš„ä¸€ä¸ªè®ºç‚¹æ˜¯ï¼Œåœ¨æ®‹å·®ç½‘ç»œä¹‹å‰ï¼Œå‡ ä¹æ‰€æœ‰çš„æ¶æ„ï¼ŒåŒ…æ‹¬æœ€æˆåŠŸçš„ Inception å’Œ VGGï¼Œä¸ ResNet ç›¸æ¯”éƒ½è¦å®½å¾ˆå¤šã€‚ä¾‹å¦‚ï¼Œæ®‹å·®ç½‘ç»œ WRN-22-8 å’Œ WRN-16-10 åœ¨å®½åº¦ã€æ·±åº¦å’Œå‚æ•°æ•°é‡ä¸Šä¸ VGG æ¶æ„éå¸¸ç›¸ä¼¼ã€‚\n WRN-n-kï¼šn ä¸ºæ€»çš„å·ç§¯å±‚æ•°ï¼›k ä¸ºwidening factorã€‚\nfor example, network with 40 layers and k = 2 times wider than original would be denoted as WRN-40-2.\n 2.4 Dropout in residual blocks BN è™½ç„¶æœ‰æ­£åˆ™åŒ–çš„æ•ˆæœï¼Œä½†æ˜¯å…¶éœ€è¦å¤§é‡çš„æ•°æ®å¢å¼ºã€‚\nå›¾ 1(d) æ‰€ç¤ºï¼Œåœ¨æ¯ä¸ªæ®‹å·®å—ä¹‹é—´çš„å·ç§¯å’Œ ReLU ä¹‹åå¢åŠ ä¸€ä¸ª dropout å±‚ï¼Œä»¥æ‰°åŠ¨ä¸‹ä¸€ä¸ªæ®‹å·®å—ä¸­çš„æ‰¹å½’ä¸€åŒ–ï¼Œé˜²æ­¢å…¶è¿‡æ‹Ÿåˆã€‚åœ¨å¾ˆæ·±çš„æ®‹å·®ç½‘ç»œä¸­ï¼Œåº”è¯¥æœ‰åŠ©äºå¤„ç†åœ¨ä¸åŒæ®‹å·®å—ä¸­å¼ºåˆ¶å­¦ä¹ çš„é€’å‡ç‰¹å¾é‡ç”¨é—®é¢˜ã€‚\n3 Experimental results ï¼ˆ1ï¼‰Type of convolutions in a block\nB(3,3) æ˜¯æœ€å¥½çš„ï¼ŒB(3,1) å’Œ B(3,1,3) åœ¨ç²¾åº¦ä¸Šéå¸¸æ¥è¿‘ B(3,3)ï¼Œå› ä¸ºå‚æ•°å°‘ï¼Œå±‚æ•°å°‘ã€‚B(3,1,3) æ¯”å…¶ä»–çš„å¿«ä¸€ç‚¹ã€‚\nï¼ˆ2ï¼‰Number of convolutions per block\nB(3,3 )ç»“æœæœ€å¥½ï¼Œè€Œ B(3,3,3) å’Œ B(3,3,3,3) çš„æ€§èƒ½æœ€å·®ã€‚\nB(3,3) åœ¨æ¯ä¸ªå—çš„å·ç§¯æ•°æ–¹é¢æ˜¯æœ€ä¼˜çš„ï¼Œå› æ­¤ï¼Œåœ¨æ¥ä¸‹æ¥çš„å®éªŒä¸­ï¼Œåªè€ƒè™‘ B(3,3) ç±»å‹çš„å—çš„ WRNã€‚\nï¼ˆ3ï¼‰Width of residual blocks\nå½“è¯•å›¾å¢åŠ åŠ å®½å‚æ•° k æ—¶ï¼Œå°±å¿…é¡»å‡å°‘æ€»å±‚æ•°ã€‚ä¸ºäº†æ‰¾åˆ°ä¸€ä¸ªæœ€ä½³æ¯”ä¾‹ï¼Œåœ¨ k ä» 2~12ï¼Œæ·±åº¦ä» 16~40 çš„æƒ…å†µä¸‹è¿›è¡Œäº†è¯•éªŒã€‚ç»“æœå¦‚ Table 4 æ‰€ç¤ºã€‚\nK = 8 æ—¶ï¼Œdepth åˆ†åˆ«æ˜¯ 16ã€22ã€40ï¼Œé”™è¯¯ç‡ 4.56%ã€4.38%ã€4.66%ï¼Œæœ‰ä¸€ä¸ªå…ˆä¸‹é™ï¼Œå†ä¸Šå‡çš„è¿‡ç¨‹ã€‚\ncompare thin and wide residual networks.\nWRN-28-10 åœ¨ CIFAR-10 ä¸Šçš„è¡¨ç°æ¯” ResNet-1001 è¦å¥½ 0.92%ï¼Œåœ¨ CIFAR-100 ä¸Šçš„è¡¨ç°æ¯” ResNet-1001 è¦å¥½ 3.46%ï¼Œå±‚æ•°å°‘äº† 36 å€ã€‚\nWRN-28-10 å’Œ WRN-40-10 çš„å‚æ•°åˆ†åˆ«æ˜¯ ResNet-1001 çš„ 3.6 å€å’Œ 5 å€ï¼Œåˆ†ç±»é”™è¯¯ç‡æ˜æ˜¾ä½äº ResNet-1001ã€‚\nï¼ˆ4ï¼‰Dropout in residual blocks\nç•¥ï¼Œå®éªŒç»“æœç›´æ¥çœ‹è®ºæ–‡æ•ˆæœæ›´å¥½ã€‚\nç¬”è®°åªè®°å½•èƒŒæ™¯å’ŒåŸç†å°±å¥½ã€‚\n",
  "wordCount" : "3385",
  "inLanguage": "en",
  "datePublished": "2021-03-13T10:17:29+08:00",
  "dateModified": "2021-03-13T10:17:29+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://landodo.github.io/posts/20210313-wrn/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Landodo's NoteBook",
    "logo": {
      "@type": "ImageObject",
      "url": "http://landodo.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://landodo.github.io/" accesskey="h" title="Landodo&#39;s NoteBook (Alt + H)">Landodo&#39;s NoteBook</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="http://landodo.github.io/search" title="ğŸ”Search (Alt &#43; /)" accesskey=/>
                    <span>ğŸ”Search</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/tags" title="Tag">
                    <span>Tag</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/cs-zoo" title="CS ZOO">
                    <span>CS ZOO</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://landodo.github.io/">Home</a>&nbsp;Â»&nbsp;<a href="http://landodo.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      Wide Residual Networks
    </h1>
    <div class="post-meta"><span title='2021-03-13 10:17:29 +0800 CST'>March 13, 2021</span>&nbsp;Â·&nbsp;7 min&nbsp;Â·&nbsp;3385 words

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#wide-residual-networks" aria-label="Wide Residual Networks">Wide Residual Networks</a><ul>
                        
                <li>
                    <a href="#abstract" aria-label="Abstract">Abstract</a></li>
                <li>
                    <a href="#1-introduction" aria-label="1 Introduction">1 Introduction</a></li>
                <li>
                    <a href="#2-wide-residual-networks" aria-label="2 Wide residual networks">2 Wide residual networks</a><ul>
                        
                <li>
                    <a href="#21-type-of-convolutions-in-residual-block" aria-label="2.1 Type of convolutions in residual block">2.1 Type of convolutions in residual block</a></li>
                <li>
                    <a href="#22-number-of-convolutional-layers-per-residual-block" aria-label="2.2 Number of convolutional layers per residual block">2.2 Number of convolutional layers per residual block</a></li>
                <li>
                    <a href="#23-width-of-residual-blocks" aria-label="2.3 Width of residual blocks">2.3 Width of residual blocks</a></li>
                <li>
                    <a href="#24-dropout-in-residual-blocks" aria-label="2.4 Dropout in residual blocks">2.4 Dropout in residual blocks</a></li></ul>
                </li>
                <li>
                    <a href="#3-experimental-results" aria-label="3 Experimental results">3 Experimental results</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="wide-residual-networks">Wide Residual Networks<a hidden class="anchor" aria-hidden="true" href="#wide-residual-networks">#</a></h1>
<p>arXiv: 1605.07146v4</p>
<p>æ³•å›½</p>
<h2 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h2>
<p>æ·±åº¦æ®‹å·®ç½‘ç»œè¢«è¯æ˜èƒ½å¤Ÿæ‰©å±•åˆ°æ•°åƒå±‚ï¼Œä¸æ–­çš„æé«˜æ€§èƒ½ã€‚</p>
<p>ä½†æ˜¯ï¼Œç²¾åº¦æé«˜çš„æ¯ä¸€å°éƒ¨åˆ†éƒ½è¦å¢åŠ è¿‘ä¸€å€çš„å±‚æ•°ï¼Œè€Œè®­ç»ƒå¾ˆæ·±çš„æ®‹å·®ç½‘ç»œæœ‰ä¸€ä¸ªç‰¹å¾é‡ç”¨é€’å‡ï¼ˆdiminishing feature reuseï¼‰çš„é—®é¢˜ï¼Œè¿™ä½¿å¾—è¿™äº›ç½‘ç»œçš„è®­ç»ƒé€Ÿåº¦éå¸¸æ…¢ã€‚</p>
<p>ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡å¯¹ ResNet block çš„æ¶æ„è¿›è¡Œäº†è¯¦ç»†çš„å®éªŒç ”ç©¶ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„æ¶æ„ï¼Œå³<strong>å‡å°‘æ·±åº¦ï¼Œå¢åŠ æ®‹å·®ç½‘ç»œçš„å®½åº¦ï¼ˆ decrease depth and increase width of residual networks. ï¼‰ã€‚</strong></p>
<p>æœ¬ç¯‡è®ºæ–‡æå‡ºçš„ç½‘ç»œè¢«ç§°ä¸º wide residual networks (WRNs)ï¼Œå®éªŒè¯æ˜ï¼Œä¸€ä¸ªç®€å•çš„ 16 å±‚æ·±çš„ WRNï¼Œç²¾åº¦å’Œæ•ˆç‡ä¸Šä¼˜äºä»¥å‰æ‰€æœ‰çš„æ·±æ®‹å·®ç½‘ç»œï¼ŒåŒ…æ‹¬åƒå±‚æ·±ç½‘ç»œã€‚</p>
<p>WRN åœ¨ CIFARã€SVHNã€COCO æ•°æ®é›†ä¸Šå–å¾— SOTAã€‚</p>
<h2 id="1-introduction">1 Introduction<a hidden class="anchor" aria-hidden="true" href="#1-introduction">#</a></h2>
<p>å·ç§¯ç¥ç»ç½‘ç»œåœ¨è¿‡å»å‡ å¹´ä¸­ï¼Œå±‚æ•°é€æ¸å¢åŠ ï¼šAlexNetï¼ŒVGGï¼ŒInceptionï¼ŒResNetã€‚</p>
<p>è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œå­˜åœ¨å‡ ä¸ªå›°éš¾ï¼ŒåŒ…æ‹¬æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±å’Œç½‘ç»œé€€åŒ–ï¼ˆexploding/vanishing gradients and degradation.ï¼‰ã€‚è®­ç»ƒæ·±å±‚çš„ç¥ç»ç½‘ç»œæœ‰å¦‚ä¸‹æŠ€å·§ï¼š</p>
<ul>
<li>well-designed initialization strategies</li>
<li>better optimizers</li>
<li>skip connections</li>
<li>knowledge transfer</li>
<li>layer-wise training</li>
</ul>
<p>æœ€è¿‘çš„ ResNet åœ¨ ImageNetã€CIFARã€PASCAL VOCã€MS COCO ä¸Šå–å¾—äº† SOTAã€‚ä¸ Inception æ¶æ„ç›¸æ¯”ï¼ŒResNet è¡¨ç°å‡ºäº†æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¿™æ„å‘³ç€ç‰¹å¾å¯ä»¥åœ¨è¿ç§»å­¦ä¹ ä¸­è¢«åˆ©ç”¨ï¼Œæ•ˆç‡æ›´é«˜ã€‚</p>
<p>ç ”ç©¶è¡¨æ˜ï¼Œæ®‹å·®è¿æ¥åŠ å¿«äº†ç½‘ç»œçš„æ”¶æ•›ã€‚</p>
<p>Highway Network åœ¨ ResNet ä¹‹å‰è¢«æå‡ºï¼ŒHighway Network ä¸­çš„æ®‹å·®é“¾è·¯æ˜¯é—¨æ§çš„ï¼Œè¿™äº›é—¨çš„æƒé‡æ˜¯å¯å­¦ä¹ çš„ã€‚</p>
<p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œå¯¹æ®‹å·®ç½‘ç»œçš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨ ResNet å—å†…çš„æ¿€æ´»é¡ºåºå’Œæ®‹å·®ç½‘ç»œçš„æ·±åº¦ä¸Šã€‚æœ¬ç¯‡è®ºæ–‡çš„çš„å·¥ä½œæ˜¯æ¢ç´¢ä¸€å¥—æ›´ä¸°å¯Œçš„ ResNet å—çš„ç½‘ç»œæ¶æ„ï¼Œå¹¶å½»åº•ç ”ç©¶é™¤äº†æ¿€æ´»é¡ºåºä¹‹å¤–çš„å…¶ä»–å‡ ä¸ªä¸åŒæ–¹é¢å¦‚ä½•å½±å“æ€§èƒ½ã€‚</p>
<p><strong>Width vs depth in residual networks.</strong>ï¼ˆæ®‹å·®ç½‘ç»œçš„å®½åº¦ä¸æ·±åº¦ï¼‰</p>
<p>æ®‹å·®ç½‘ç»œçš„ä½œè€…è¯•å›¾å°†ç½‘ç»œå°½å¯èƒ½åœ°åšå¾—æ›´è–„ï¼Œè€Œå€¾å‘äºå¢åŠ å…¶æ·±åº¦å’Œæ›´å°‘çš„å‚æ•°ï¼Œç”šè‡³å¼•å…¥äº†ä¸€ä¸ªâ€ç“¶é¢ˆâ€œå—ï¼ˆÂ«bottleneckÂ» blockï¼‰ï¼Œä½¿å¾— ResNet å—æ›´è–„ã€‚</p>
<p>ä½œè€…ä»¬æ³¨æ„åˆ°ï¼Œå¸¦æœ‰æ’ç­‰æ˜ å°„ï¼ˆidentity mappingï¼‰çš„æ®‹å·®å—å¯ä»¥è®­ç»ƒéå¸¸æ·±çš„ç½‘ç»œï¼Œè¿™è¿™æ˜¯æ®‹å·®ç½‘ç»œçš„ä¼˜ç‚¹ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸€ä¸ªå¼±ç‚¹ã€‚ç”±äºæ¢¯åº¦æµç»ç½‘ç»œæ—¶ï¼Œæ²¡æœ‰ä»€ä¹ˆä¸œè¥¿å¯ä»¥å¼ºè¿«å®ƒé€šè¿‡æ®‹å·®å—æƒé‡ï¼Œå®ƒå¯ä»¥é¿å…åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ ä»»ä½•ä¸œè¥¿ï¼Œæ‰€ä»¥æœ‰å¯èƒ½åªæœ‰å°‘æ•°å‡ ä¸ªå—å¯ä»¥å­¦ä¹ åˆ°æœ‰ç”¨çš„è¡¨å¾ï¼Œæˆ–è€…å¾ˆå¤šå—å…±äº«çš„ä¿¡æ¯éå¸¸å°‘ï¼Œå¯¹æœ€ç»ˆç›®æ ‡çš„è´¡çŒ®å¾ˆå°ã€‚è¿™ä¸ªé—®é¢˜è¢«ç§°ä¸º<strong>é€’å‡ç‰¹å¾é‡ç”¨ï¼ˆdiminishing feature reuseï¼‰</strong>ï¼Œï¼ˆDeep networks with stochastic depthï¼‰è¯•å›¾ç”¨åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºç¦ç”¨æ®‹å·®å—çš„æƒ³æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</p>
<p>è¿™ç¯‡è®ºæ–‡å»ºç«‹åœ¨ â€œIdentity mappings in deep residual networksâ€ ä¹‹ä¸Šï¼Œè¯•å›¾å›ç­”æ·±åº¦æ®‹å·®ç½‘ç»œåº”è¯¥æœ‰å¤šå®½çš„é—®é¢˜ï¼Œå¹¶è§£å†³è®­ç»ƒä¸­å­˜åœ¨çš„é—®é¢˜ã€‚</p>
<p>å®éªŒè¡¨æ˜ï¼Œä¸å¢åŠ æ®‹å·®ç½‘ç»œçš„æ·±åº¦ç›¸æ¯”ï¼Œæ‹“å®½ ResNet å—æä¾›äº†ä¸€ç§æ›´æœ‰æ•ˆçš„æ–¹æ³•æ¥æé«˜æ®‹å·®ç½‘ç»œçš„æ€§èƒ½ã€‚wider deep residual networks æ¯” ResNet æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå±‚æ•°å‡å°‘äº† 50 å€ï¼Œé€Ÿåº¦å¿«äº† 2 å€ä»¥ä¸Šã€‚</p>
<p>wide 16-layer deep network ä¸ 1000-layer thin deep network çš„ç²¾åº¦ç›¸åŒï¼Œå‚æ•°æ•°é‡ä¹Ÿç›¸å½“ï¼Œä¸è¿‡å‰è€…è®­ç»ƒé€Ÿåº¦è¦å¿«å‡ å€ã€‚è¿™æš—ç¤ºäº†æ·±åº¦æ®‹å·®ç½‘ç»œçš„ä¸»è¦åŠ›é‡åœ¨æ®‹å·®å—ï¼Œæ·±åº¦çš„å½±å“æ˜¯è¾…åŠ©æ€§çš„ã€‚</p>
<p>**Use of dropout in ResNet blocks. **</p>
<p>Dropout è¾ƒå¤šåº”ç”¨äºå‚æ•°è¾ƒå¤šçš„é¡¶å±‚ï¼Œä»¥é˜²æ­¢ç‰¹å¾å…±é€‚åº”å’Œè¿‡æ‹Ÿåˆã€‚</p>
<p>åæ¥ï¼Œdropout è¢« Batch normalization ä»£æ›¿ï¼ŒBN çš„ç½‘ç»œæ¯”æœ‰ dropout çš„ç½‘ç»œèƒ½è¾¾åˆ°æ›´å¥½çš„ç²¾åº¦ã€‚ï¼ˆBatch normalization: Accelerating deep network training by reducing internal covariate shift.ï¼‰</p>
<p>kaiming He ç ”ç©¶è¡¨æ˜ï¼Œåœ¨ ResNet ä¸­å¼•å…¥ dropout ä¼šäº§ç”Ÿè´Ÿé¢çš„ä½œç”¨ã€‚åœ¨å®½æ®‹å·®ç½‘ç»œï¼ˆWRNï¼‰ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œå¼•å…¥ dropout åï¼Œåœ¨ä¸€äº›æ•°æ®é›†ä¸Šå–å¾—äº† SOTAã€‚</p>
<p>æœ¬ç¯‡è®ºæ–‡çš„è´¡çŒ®æ€»ç»“å¦‚ä¸‹ï¼š</p>
<ul>
<li>å¯¹æ®‹å·®ç½‘ç»œæ¶æ„è¿›è¡Œäº†è¯¦ç»†çš„å®éªŒç ”ç©¶ï¼Œå½»åº•ç ”ç©¶äº† ResNet å—ç»“æ„çš„å‡ ä¸ªé‡è¦æ–¹é¢ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ <em>widened</em> architecture for ResNet blocksï¼Œä½¿æ®‹ä½™ç½‘ç»œçš„æ€§èƒ½å¾—åˆ°æ˜¾è‘—æé«˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åœ¨æ·±åº¦æ®‹å·®ç½‘ç»œä¸­åˆ©ç”¨ dropout çš„æ–°æ–¹æ³•ã€‚</li>
<li>WRN åœ¨å‡ ä¸ªæ•°æ®é›†ä¸Šå–å¾— SOTAã€‚</li>
</ul>
<h2 id="2-wide-residual-networks">2 Wide residual networks<a hidden class="anchor" aria-hidden="true" href="#2-wide-residual-networks">#</a></h2>
<p>æ’ç­‰æ˜ å°„çš„æ®‹å·®å—è¡¨ç¤ºå¦‚ä¸‹ï¼š</p>
<p><img loading="lazy" src="./20210313/1.png" alt=""  />
</p>
<ul>
<li>å…¶ä¸­ $x_{l+1}$ å’Œ $x_l$ ä¸ºç½‘ç»œä¸­ç¬¬ $l$ ä¸ªå•å…ƒçš„è¾“å…¥å’Œè¾“å‡ºï¼Œ$F$ ä¸ºæ®‹å·®å‡½æ•°ï¼Œ$W_l$ ä¸ºå—çš„å‚æ•°ã€‚æ®‹å·®ç½‘ç»œç”±ä¾æ¬¡å åŠ çš„æ®‹å·®å—ç»„æˆã€‚</li>
</ul>
<p>æ®‹å·®ç½‘ç»œç”±ä¸¤ç§ç±»å‹çš„å—ç»„æˆï¼š</p>
<p>ï¼ˆ1ï¼‰basicï¼šç”¨ä¸¤ä¸ªè¿ç»­çš„ 3Ã—3 å·ç§¯ä¸æ‰¹é‡å½’ä¸€åŒ–ã€ReLU å‰é¢çš„å·ç§¯ï¼šconv3Ã—3-conv3Ã—3  å›¾ 1(a)</p>
<p>ï¼ˆ2ï¼‰bottleneckï¼šæœ‰ä¸€ä¸ª 3Ã—3 å·ç§¯ï¼Œå‰åæœ‰é™ç»´å’Œæ‰©å±•çš„ 1Ã—1 å·ç§¯å±‚ï¼šconv1Ã—1-conv3Ã—3-conv1Ã—1 å›¾1(b)</p>
<p><img loading="lazy" src="./20210313/2.png" alt=""  />
</p>
<p>ä¸åŸæ¶æ„ï¼ˆDeep residual learning for image recognitionï¼‰ç›¸æ¯”ï¼Œåœ¨ï¼ˆIdentity mappings in deep residual networksï¼‰ä¸­ï¼Œå°† batch normalizationã€activationã€convolution çš„é¡ºåºç”± conv-BN-ReLU æ”¹ä¸º BN-ReLU- convã€‚åè€…è¢«è¯æ˜è®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå–å¾—äº†æ›´å¥½çš„æ•ˆæœã€‚</p>
<p>æ‰€è°“çš„ â€bottleneck blockâ€œ æœ€åˆæ˜¯ç”¨æ¥ä½¿ block çš„è®¡ç®—æˆæœ¬é™ä½ï¼Œä»¥å¢åŠ å±‚æ•°ã€‚ç”±äºæœ¬ç¯‡è®ºæ–‡è¦ç ”ç©¶åŠ å®½çš„æ•ˆæœï¼Œè€Œ â€bottleneck blockâ€œ æ˜¯ç”¨æ¥è®©ç½‘ç»œå˜è–„çš„ï¼Œæ‰€ä»¥ä¸è€ƒè™‘å®ƒï¼Œè€Œæ˜¯å…³æ³¨ â€basic blockâ€œ çš„æ®‹å·®æ¶æ„ã€‚</p>
<p>æœ‰ä¸‰ç§ç®€å•çš„æ–¹æ³•å¯ä»¥æé«˜æ®‹å·®å—çš„è¡¨ç¤ºåŠ›ã€‚</p>
<ul>
<li>to add more convolutional layers per block</li>
<li>âœ… <strong>to widen the convolutional layers by adding more feature planes</strong></li>
<li>to increase filter sizes in convolutional layers</li>
</ul>
<p>å¼•å…¥ä¸¤ä¸ªå‚æ•°ï¼š</p>
<ul>
<li>deepening factor lï¼šl è¡¨ç¤ºä¸€ä¸ªåŒºå—ä¸­çš„å·ç§¯æ•°ã€‚</li>
<li>widening factor kï¼šk å€çš„ç‰¹å¾æ•°é‡ï¼ˆç‰¹å¾å›¾çš„ç‰‡æ•°ï¼Œå³å·ç§¯æ ¸çš„ä¸ªæ•°ï¼‰</li>
</ul>
<p>å› æ­¤ï¼ŒResNet baseline ä¸­çš„ â€basic blockâ€œ å¯¹åº”çš„æ˜¯ lï¼2ï¼Œkï¼1ã€‚å›¾ 1(a) å’Œå›¾ 1(c) åˆ†åˆ«æ˜¾ç¤ºäº† Â«basicÂ» å’Œ Â«basic-wideÂ» blocksã€‚</p>
<p><img loading="lazy" src="./20210313/3.png" alt=""  />
</p>
<p>WRN ç»“æ„å¦‚ Table 1 æ‰€ç¤ºï¼š</p>
<p><img loading="lazy" src="./20210313/4.png" alt=""  />
</p>
<p>å®ƒç”±ä¸€ä¸ªåˆå§‹å·ç§¯å±‚ conv1 ç»„æˆï¼Œä¹‹åæ˜¯ 3 ç»„ï¼ˆæ¯ç»„å¤§å°ä¸º Nï¼‰æ®‹å·®å— conv2ã€conv3 å’Œ conv4ï¼Œç„¶åæ˜¯å¹³å‡æ± å’Œæœ€ç»ˆåˆ†ç±»å±‚ã€‚</p>
<p>åœ¨æ‰€æœ‰çš„å®éªŒä¸­ï¼Œconv1 çš„å¤§å°éƒ½æ˜¯å›ºå®šçš„ï¼Œè€Œå¼•å…¥çš„åŠ å®½å› å­ k åˆ™å¯¹ 3 ç»„ conv2-4 ä¸­çš„æ®‹å·®å—çš„å®½åº¦è¿›è¡Œäº†ç¼©æ”¾ï¼ˆä¾‹å¦‚ï¼ŒåŸæ¥çš„ â€basicâ€œ æ¶æ„ç›¸å½“äº k=1ï¼‰ã€‚</p>
<h3 id="21-type-of-convolutions-in-residual-block">2.1 Type of convolutions in residual block<a hidden class="anchor" aria-hidden="true" href="#21-type-of-convolutions-in-residual-block">#</a></h3>
<p>è®© B(M) è¡¨ç¤ºæ®‹å·®å—ç»“æ„ï¼Œå…¶ä¸­ M æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­æœ‰å—ä¸­å·ç§¯å±‚çš„æ ¸å¤§å°ã€‚</p>
<p>ä¾‹å¦‚ï¼ŒB(3, 1) è¡¨ç¤ºå…·æœ‰ 3Ã—3 å’Œ 1Ã—1 å·ç§¯å±‚çš„æ®‹å·®å—ã€‚è¯·æ³¨æ„ï¼Œç”±äºæˆ‘ä»¬ä¸è€ƒè™‘å‰é¢è§£é‡Šçš„ &ldquo;ç“¶é¢ˆ &ldquo;å—ï¼Œæ‰€ä»¥åœ¨æ•´ä¸ªå—ä¸­ï¼Œç‰¹å¾å¹³é¢çš„æ•°é‡å§‹ç»ˆä¿æŒä¸å˜ï¼ˆæ‰€æœ‰ block ä¸­ï¼Œä½¿ç”¨å·ç§¯æ ¸çš„æ•°é‡ç›¸åŒï¼‰ã€‚</p>
<p>è®ºæ–‡æƒ³è¦ç ”ç©¶çš„æ˜¯ï¼Œâ€basic blockâ€œ æ®‹å·®æ¶æ„çš„ 3Ã—3 å·ç§¯å±‚ä¸­çš„æ¯ä¸€ä¸ªå±‚çš„é‡è¦ç¨‹åº¦ï¼Œæ˜¯å¦å¯ä»¥ç”¨è®¡ç®—æˆæœ¬è¾ƒä½çš„ 1Ã—1 å±‚ï¼Œç”šè‡³æ˜¯ 1Ã—1 å’Œ 3Ã—3 å·ç§¯å±‚çš„ç»„åˆæ¥ä»£æ›¿ã€‚ä¾‹å¦‚ï¼ŒB(1,3) æˆ– B(1,3)ã€‚è¿™å¯ä»¥å¢åŠ æˆ–å‡å°‘å—çš„è¡¨ç¤ºèƒ½åŠ›ã€‚</p>
<p>å› æ­¤ï¼Œè¯•éªŒäº†ä»¥ä¸‹ç»„åˆï¼ˆæ³¨æ„ï¼Œæœ€åä¸€ä¸ªç»„åˆï¼Œå³ B(3,1,1) ä¸Network in Network æ¶æ„ç›¸ä¼¼ï¼‰ã€‚</p>
<p><img loading="lazy" src="./20210313/5.png" alt=""  />
</p>
<h3 id="22-number-of-convolutional-layers-per-residual-block">2.2 Number of convolutional layers per residual block<a hidden class="anchor" aria-hidden="true" href="#22-number-of-convolutional-layers-per-residual-block">#</a></h3>
<p>è¿˜å¯¹åŒºå—åŠ æ·±å› å­ l è¿›è¡Œå®éªŒï¼Œçœ‹çœ‹å®ƒå¯¹æ€§èƒ½çš„å½±å“ã€‚æ¯”è¾ƒå¿…é¡»åœ¨å‚æ•°æ•°é‡ç›¸åŒçš„ç½‘ç»œä¸­è¿›è¡Œï¼Œæ‰€ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œéœ€è¦åœ¨ç¡®ä¿<strong>ç½‘ç»œå¤æ‚åº¦ä¿æŒå¤§è‡´ä¸å˜</strong>çš„æƒ…å†µä¸‹ï¼Œæ„å»ºä¸åŒ l å’Œ dï¼ˆå…¶ä¸­ d è¡¨ç¤ºå—çš„æ€»æ•°é‡ï¼‰çš„ç½‘ç»œã€‚ä¾‹å¦‚ï¼Œè¿™æ„å‘³ç€åªè¦ l å¢åŠ ï¼Œd å°±åº”è¯¥å‡å°‘ã€‚</p>
<h3 id="23-width-of-residual-blocks">2.3 Width of residual blocks<a hidden class="anchor" aria-hidden="true" href="#23-width-of-residual-blocks">#</a></h3>
<blockquote>
<p>While the number of parameters increases linearly with l (the deepening factor) and d
(the number of ResNet blocks), number of parameters and computational complexity are
quadratic in k.</p>
</blockquote>
<p>å‚æ•°é‡éšç€ lï¼ˆåŠ æ·±å› å­ï¼‰å’Œ dï¼ˆResNet å—æ•°ï¼‰çš„å¢åŠ è€Œçº¿æ€§å¢åŠ ï¼Œä½†å‚æ•°é‡å’Œè®¡ç®—å¤æ‚åº¦æ˜¯ k çš„å¹³æ–¹ã€‚</p>
<p>å…³äºæ›´å®½çš„æ®‹å·®ç½‘ç»œçš„ä¸€ä¸ªè®ºç‚¹æ˜¯ï¼Œåœ¨æ®‹å·®ç½‘ç»œä¹‹å‰ï¼Œå‡ ä¹æ‰€æœ‰çš„æ¶æ„ï¼ŒåŒ…æ‹¬æœ€æˆåŠŸçš„ Inception å’Œ VGGï¼Œä¸ ResNet ç›¸æ¯”éƒ½è¦å®½å¾ˆå¤šã€‚ä¾‹å¦‚ï¼Œæ®‹å·®ç½‘ç»œ WRN-22-8 å’Œ WRN-16-10 åœ¨å®½åº¦ã€æ·±åº¦å’Œå‚æ•°æ•°é‡ä¸Šä¸ VGG æ¶æ„éå¸¸ç›¸ä¼¼ã€‚</p>
<blockquote>
<p>WRN-n-kï¼šn ä¸ºæ€»çš„å·ç§¯å±‚æ•°ï¼›k ä¸ºwidening factorã€‚</p>
<p>for example, network with 40 layers and k = 2 times wider than original would be denoted as WRN-40-2.</p>
</blockquote>
<h3 id="24-dropout-in-residual-blocks">2.4 Dropout in residual blocks<a hidden class="anchor" aria-hidden="true" href="#24-dropout-in-residual-blocks">#</a></h3>
<p>BN è™½ç„¶æœ‰æ­£åˆ™åŒ–çš„æ•ˆæœï¼Œä½†æ˜¯å…¶éœ€è¦å¤§é‡çš„æ•°æ®å¢å¼ºã€‚</p>
<p>å›¾ 1(d) æ‰€ç¤ºï¼Œåœ¨æ¯ä¸ªæ®‹å·®å—ä¹‹é—´çš„å·ç§¯å’Œ ReLU ä¹‹åå¢åŠ ä¸€ä¸ª dropout å±‚ï¼Œä»¥æ‰°åŠ¨ä¸‹ä¸€ä¸ªæ®‹å·®å—ä¸­çš„æ‰¹å½’ä¸€åŒ–ï¼Œé˜²æ­¢å…¶è¿‡æ‹Ÿåˆã€‚åœ¨å¾ˆæ·±çš„æ®‹å·®ç½‘ç»œä¸­ï¼Œåº”è¯¥æœ‰åŠ©äºå¤„ç†åœ¨ä¸åŒæ®‹å·®å—ä¸­å¼ºåˆ¶å­¦ä¹ çš„é€’å‡ç‰¹å¾é‡ç”¨é—®é¢˜ã€‚</p>
<p><img loading="lazy" src="./20210313/6.png" alt=""  />
</p>
<h2 id="3-experimental-results">3 Experimental results<a hidden class="anchor" aria-hidden="true" href="#3-experimental-results">#</a></h2>
<p>ï¼ˆ1ï¼‰Type of convolutions in a block</p>
<p><img loading="lazy" src="./20210313/7.png" alt=""  />
</p>
<p>B(3,3) æ˜¯æœ€å¥½çš„ï¼ŒB(3,1) å’Œ B(3,1,3) åœ¨ç²¾åº¦ä¸Šéå¸¸æ¥è¿‘ B(3,3)ï¼Œå› ä¸ºå‚æ•°å°‘ï¼Œå±‚æ•°å°‘ã€‚B(3,1,3) æ¯”å…¶ä»–çš„å¿«ä¸€ç‚¹ã€‚</p>
<p><strong>ï¼ˆ2ï¼‰Number of convolutions per block</strong></p>
<p><img loading="lazy" src="./20210313/8.png" alt=""  />
</p>
<p>B(3,3 )ç»“æœæœ€å¥½ï¼Œè€Œ B(3,3,3) å’Œ B(3,3,3,3) çš„æ€§èƒ½æœ€å·®ã€‚</p>
<p>B(3,3) åœ¨æ¯ä¸ªå—çš„å·ç§¯æ•°æ–¹é¢æ˜¯æœ€ä¼˜çš„ï¼Œå› æ­¤ï¼Œåœ¨æ¥ä¸‹æ¥çš„å®éªŒä¸­ï¼Œåªè€ƒè™‘ B(3,3) ç±»å‹çš„å—çš„ WRNã€‚</p>
<p><strong>ï¼ˆ3ï¼‰Width of residual blocks</strong></p>
<p><img loading="lazy" src="./20210313/9.png" alt=""  />
</p>
<p>å½“è¯•å›¾å¢åŠ åŠ å®½å‚æ•° k æ—¶ï¼Œå°±å¿…é¡»å‡å°‘æ€»å±‚æ•°ã€‚ä¸ºäº†æ‰¾åˆ°ä¸€ä¸ªæœ€ä½³æ¯”ä¾‹ï¼Œåœ¨ k ä» 2~12ï¼Œæ·±åº¦ä» 16~40 çš„æƒ…å†µä¸‹è¿›è¡Œäº†è¯•éªŒã€‚ç»“æœå¦‚ Table 4 æ‰€ç¤ºã€‚</p>
<p>K = 8 æ—¶ï¼Œdepth åˆ†åˆ«æ˜¯ 16ã€22ã€40ï¼Œé”™è¯¯ç‡ 4.56%ã€4.38%ã€4.66%ï¼Œæœ‰ä¸€ä¸ªå…ˆä¸‹é™ï¼Œå†ä¸Šå‡çš„è¿‡ç¨‹ã€‚</p>
<p><strong>compare thin and wide residual networks.</strong></p>
<p><img loading="lazy" src="./20210313/10.png" alt=""  />
</p>
<p>WRN-28-10 åœ¨ CIFAR-10 ä¸Šçš„è¡¨ç°æ¯” ResNet-1001 è¦å¥½ 0.92%ï¼Œåœ¨ CIFAR-100 ä¸Šçš„è¡¨ç°æ¯” ResNet-1001 è¦å¥½ 3.46%ï¼Œå±‚æ•°å°‘äº† 36 å€ã€‚</p>
<p>WRN-28-10 å’Œ WRN-40-10 çš„å‚æ•°åˆ†åˆ«æ˜¯ ResNet-1001 çš„ 3.6 å€å’Œ 5 å€ï¼Œåˆ†ç±»é”™è¯¯ç‡æ˜æ˜¾ä½äº ResNet-1001ã€‚</p>
<p><img loading="lazy" src="./20210313/11.png" alt=""  />
</p>
<p><strong>ï¼ˆ4ï¼‰Dropout in residual blocks</strong></p>
<p><img loading="lazy" src="./20210313/12.png" alt=""  />
</p>
<p>ç•¥ï¼Œå®éªŒç»“æœç›´æ¥çœ‹è®ºæ–‡æ•ˆæœæ›´å¥½ã€‚</p>
<p>ç¬”è®°åªè®°å½•èƒŒæ™¯å’ŒåŸç†å°±å¥½ã€‚</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://landodo.github.io/tags/cnn/">CNN</a></li>
      <li><a href="http://landodo.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">è®ºæ–‡é˜…è¯»</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://landodo.github.io/posts/20210315-sknet-review/">
    <span class="title">Â« Prev Page</span>
    <br>
    <span>Selective Kernel Network è§£æ</span>
  </a>
  <a class="next" href="http://landodo.github.io/posts/20210311-dual-attention-network/">
    <span class="title">Next Page Â»</span>
    <br>
    <span>Dual Attention Network for Scene Segmentation</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>Landon</span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
