<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
<meta name="robots" content="index, follow">
<title>20211024 Latent Space Data Augmentation | Notes</title>
<meta name="keywords" content="数据增强, 论文阅读, 医学图像分割" />
<meta name="description" content="Cooperative Training and Latent Space Data Augmentation for Robust Medical Image Segmentation 论文题目：协同训练和隐空间数据增强的鲁棒性医学图像分割 https://arxiv.org/abs/2107.01079 会议：MICCAI 2021 作者：Chen CHEN 陈晨 https://sites.google.com/view/morningchen-site/home Research Assistant/PhD 伦敦帝国理工学">
<meta name="author" content="">
<link rel="canonical" href="http://landodo.github.io/posts/20211024-latent-space-data-augmentation/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css" integrity="sha256-yIlj/i15RiAA/Q&#43;xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as="style">
<link rel="preload" href="./logo.png" as="image">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js" integrity="sha256-uVus3DnjejMqn4g7Hni&#43;Srwf3KK8HyZB9V4809q9TWE="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://landodo.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://landodo.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://landodo.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://landodo.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="http://landodo.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="20211024 Latent Space Data Augmentation" />
<meta property="og:description" content="Cooperative Training and Latent Space Data Augmentation for Robust Medical Image Segmentation 论文题目：协同训练和隐空间数据增强的鲁棒性医学图像分割 https://arxiv.org/abs/2107.01079 会议：MICCAI 2021 作者：Chen CHEN 陈晨 https://sites.google.com/view/morningchen-site/home Research Assistant/PhD 伦敦帝国理工学" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://landodo.github.io/posts/20211024-latent-space-data-augmentation/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-10-24T09:08:38&#43;08:00" />
<meta property="article:modified_time" content="2021-10-24T09:08:38&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="20211024 Latent Space Data Augmentation"/>
<meta name="twitter:description" content="Cooperative Training and Latent Space Data Augmentation for Robust Medical Image Segmentation 论文题目：协同训练和隐空间数据增强的鲁棒性医学图像分割 https://arxiv.org/abs/2107.01079 会议：MICCAI 2021 作者：Chen CHEN 陈晨 https://sites.google.com/view/morningchen-site/home Research Assistant/PhD 伦敦帝国理工学"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://landodo.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "20211024 Latent Space Data Augmentation",
      "item": "http://landodo.github.io/posts/20211024-latent-space-data-augmentation/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "20211024 Latent Space Data Augmentation",
  "name": "20211024 Latent Space Data Augmentation",
  "description": "Cooperative Training and Latent Space Data Augmentation for Robust Medical Image Segmentation 论文题目：协同训练和隐空间数据增强的鲁棒性医学图像分割 https://arxiv.org/abs/2107.01079 会议：MICCAI 2021 作者：Chen CHEN 陈晨 https://sites.google.com/view/morningchen-site/home Research Assistant/PhD 伦敦帝国理工学",
  "keywords": [
    "数据增强", "论文阅读", "医学图像分割"
  ],
  "articleBody": "Cooperative Training and Latent Space Data Augmentation for Robust Medical Image Segmentation\n论文题目：协同训练和隐空间数据增强的鲁棒性医学图像分割\nhttps://arxiv.org/abs/2107.01079 会议：MICCAI 2021\n作者：Chen CHEN 陈晨\nhttps://sites.google.com/view/morningchen-site/home\nResearch Assistant/PhD 伦敦帝国理工学院 Research Assistant/PhD\n本科哈工大 物联网工程\n代码：https://github.com/cherise215/Cooperative_Training_and_Latent_Space_Data_Augmentation\nAbstract 基于深度学习的分割方法在部署过程中容易受到不可预见的数据分布（unforeseen data distribution）变化的影响，例如，不同扫描仪引起的图像外观或对比度的变化，伪影等。本篇论文提出了一个用于图像分割模型的协同训练框架和一个用于生成困难样本的隐空间数据增强方法，提升了模型的泛化性和有限数据的稳健性。\n协同训练框架由 fast-thinking network(FTN) 和 slow-thinking network(STN) 构成。FTN 学习解耦的图像特征和形状特征，用于图像重建和分割任务； STN 学习形状先验，用于分割校正和细化。 隐空间数据增强（latent space DA）是通过在通道和空间上遮盖解耦的隐空间，为训练生成具有挑战性的样本。 在公共心脏成像数据集进行了广泛的实验，证实了分割性能的提高，以及提高了对各种不可预见的成像伪影的稳健性。与标准的训练方法相比，具有隐空间数据增强的协同训练在平均 Dice 提高了15%。\n1 Introduction 将基于深度学习的方法部署到实际应用中的一个主要障碍是临床部署过程中的域转移（domain shift），其中包括不同医疗中心和扫描仪的图像外观和对比度的变化，以及各种成像伪影。在 Multi-domain datasets 上学习域不变的特征进行分割可以解决上面的问题，但是 Multi-domain 数据的获取成本较高，因此从 single-domain 和有限的数据中学习稳健的网络，对医学影像研究具有重要的实用价值。\n本篇论文提出了一个新的协同训练框架，用于从 single-domain 数据中学习到一个稳健的分割网络。主要贡献可以总结如下：\n（1）设计了一个由两个网络组成的协同训练框架\n这个框架启发自人类行为中的双系统模型：快速思维系统做出直觉判断，而慢速思维系统则通过逻辑推理进行纠正。\n对应到框架中，fast-thinking network (FTN) 旨在理解图像的上下文，并提取与任务相关的图像和形状特征进行初始分割；slow-thinking network (STN) 根据学习到的形状先验来完善初始分割。\n（2）提出了一种隐空间数据增强方法 latent space data augmentation (DA) method\n随机和有针对性的方式对从 FTN 中学习到的隐编码（latent code）进行通道和空间的遮盖（屏蔽），这样就会重建出一组多样化的挑战性图像和对应的分割图，以加强两个网络的训练。\n2 Methodology single domain dataset $D_{tr} = {(x_i, y_i)}^{n}_{i=1}$\nimage $x_i \\in \\mathbb{R}^{H \\times W}$\none-hot encoded C-class label maps $y_i \\in {0, 1}^{H \\times W \\times C}$ （ground truth）\n2.1 Framework 给定输入图像 x，FTN 提取特定任务的形状特征 $z_s$ 来执行分割任务，提取图像上下文特征 $z_i$ 来执行图像重建任务。共享 encoder $E_{\\theta}$，特征解耦器 $\\mathcal{H}$， 两个特定任务的解码器 $D_{\\phi_s}$、$D_{\\phi_i}$ 用于图像分割和重建任务。\n对 $z_i$ 应用特征解耦器 $\\mathcal{H}$，使与分割任务无关的信息（如图像纹理信息、亮度）在 $z_s$ 中被停用，稀疏的 $z_s$ 有益于模型的稳健性。\n$\\mathcal{H}$ 由两个卷积层堆叠，后接 ReLU 激活函数。图像重建需要低层次的信息，而图像分割则依赖于更集中的高层次信息。引入 $\\mathcal{H}$ 明确地定义了一个分层的特征结构，以提高模型的通用性；\nSTN 是一个去噪自动编码器网络 $C_{\\psi}$，学习形状先验来纠正 FTN 预测的分割。在推理时，FTN 进行对给定的图像 x 进行快速分割：$p = D_{\\phi_s}(\\mathcal{H}(E_{\\theta}(x)))$；STN 完善分割结果：$p’ = C_{\\psi}(p)$。\n2.2 Standard Training 用监督的多任务损失函数联合训练三个编码器-解码器对，损失包含：图像重建 $L_{rec}$、图像分割 $L_{seg}$、形状校正 $L_{shp}$。\n$L_{rec}$ 是 Mean Squared Error(MSE) $L_{seg}, L_{shp}$ 是 cross-entropy function $y’ = C_{\\psi}(y)$ 2.3 Latent Space Data Augmentation for Hard Example Generation 为了缓解过拟合，提出了 latent space DA method，使得 FTN 可以自动构建具有挑战性的样本。\n掩码生成器 $\\mathcal{G}$ 在 latent code $z$ 上产生一个掩码 m，之后 $\\hat{z} = z \\cdot m$ 输入到解码器重构出被破坏的图像 $\\hat{x} = D_{\\phi_i}(\\hat{z_i})$ 和其对应的分割图 $\\hat{p} = D_{\\phi_s}(\\hat{z_s})$。这就是 latent code masking 数据增强方法。\n通过动态屏蔽 latent code，所提出的方法可以生成具有广泛多样性的图像外观和分割的样本。如下介绍几种 latent-code masking 方案：\n（1）Random Masking with Dropout\nlatent-code 的整个通道在训练时以 p 的概率被掩盖为全零。\n被遮盖后第 i 个通道的结果为：$\\hat{z}^{(i)} = z^{(i)} \\cdot m^{(i)}$。$z \\in \\mathbb{R}^{c \\times h \\times w}$。\n（2）Target Masking\n提出了有针对性的 latent-code masking 方案，该方案以梯度为线索来识别要掩蔽的“突出”特征。 采取图像重建损失和图像分割损失，分别计算 $z_i$ 和 $z_s$ 的梯度 $g_{z_i}$和 $g_{z_s}$。\n对梯度值进行排序，可以确定出那些最具预测性的元素。作者假设，对损失函数反应较高的元素是导致在不可预见的域转移下性能下降的主要原因。因此，对这种元素进行有针对性的遮蔽，以模拟数据分布的转移（data distribution shifts）。可以在通道维度和空间维度遮蔽 latent-code $z$ 的特征。\n$z^{ch}_p, z^{sp}_p$ 阈值 a 是 (0, 0.5) 之间随机抽取的退火系数，创建 soft masks； Channel-wise masked code at i-th channel：\n$\\hat{z}^{(i)} = z^{(i)} \\cdot m^{(i)}$\nSpatial-wise masked code at (j, k) position：\n$\\hat{z}^{(j, k)} = z^{(j, k)} \\cdot m^{(j, k)}$\n2.4 协同训练 训练过程中，随机地将上面介绍的三种 mask generator 应用于 $z_i, z_s$，这个操作生成一组丰富的增强图像 $\\hat{x}$ 和分割图 $\\hat{p}$。这就得到 3 example pairs 用于训练：\ncorrupted images-clean images $(\\hat{x}, x)$ corrupted images-GT $(\\hat{x}, y)$ corrupted GT-GT $(\\hat{p}, y)$ 合作训练的最终损失定义为简单例子和困难例子上的损失的组合。\n3 Experiments and Results 应用与心脏图像分割任务，从 MR 图像中分割出左心室腔、左心室心肌和右心室。\n数据集：\nACDC：训练、intra-domain 测试\nM\u0026Ms：cross-domain 测试\nACDC-C (corrupted ACDC)：评估数据增强方法的鲁棒性\n（1）实验 1：Standard Training vs Cooperative Training\n两种方法在域内测试集上取得了相近的性能； 双网络（FTN+STN）的协同训练在域外测试集上取得了更高的性能； 隐空间数据增强方法数据上，协同训练也表现出了其优越性。 （2）实验 2: Latent Space DA vs Image Space DA\nTable 1 中 AdvBias 在 M\u0026Ms 数据集和 RandBias 上取得了最好的性能，但这种方法有一个副作用，使其对尖峰伪影更加敏感（Dice 得分 0.4901 vs 0.3840）。latent-space DA 在六个数据集上取得了最高的平均性能。\n图 3. 本篇论文的方法不仅可以生成扰动的图像，还可以生成不确定性增加的真实的损坏的分割。\n（3）实验 3：Ablation Study\n(a) the proposed targeted masking; b) latent code decoupler H; c) cooperative training.\n禁用 $\\mathcal{G}{ch}、\\mathcal{G}{sp}$ 后，平均 Dice 得分从 0.6901 降至 0.6584； 图像重建需要低层次的信息，而图像分割则依赖于更集中的高层次信息。引入 H明确地定义了一个分层的特征结构，以提高模型的通用性； 突出了合作训练策略加强基于学习的形状细化和修正； 4 Conclusion 提出了一个新的协同训练框架，以及一个 latent space masking-based 的数据增强方法； 实验验证了模型的通用性和对不可预见的领域转变的鲁棒性； latent-space DA 方法只需要很少的代价； 目前只在心脏图像分割上展示了其性能，该通用框架有可能扩展到广泛的数据驱动的应用。 ",
  "wordCount" : "2874",
  "inLanguage": "en",
  "datePublished": "2021-10-24T09:08:38+08:00",
  "dateModified": "2021-10-24T09:08:38+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://landodo.github.io/posts/20211024-latent-space-data-augmentation/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Notes",
    "logo": {
      "@type": "ImageObject",
      "url": "http://landodo.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://landodo.github.io/" accesskey="h" title="Notes (Alt + H)">
                <img src="http://landodo.github.io/logo.png" alt="logo" aria-label="logo"
                    height="30">Notes</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="http://landodo.github.io/search" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/tags" title="Tag">
                    <span>Tag</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/cs-zoo" title="CS ZOO">
                    <span>CS ZOO</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://landodo.github.io/">Home</a>&nbsp;»&nbsp;<a href="http://landodo.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      20211024 Latent Space Data Augmentation
    </h1>
    <div class="post-meta"><span title='2021-10-24 09:08:38 +0800 CST'>October 24, 2021</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;2874 words

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#abstract" aria-label="Abstract">Abstract</a></li>
                <li>
                    <a href="#1-introduction" aria-label="1 Introduction">1 Introduction</a></li>
                <li>
                    <a href="#2-methodology" aria-label="2 Methodology">2 Methodology</a><ul>
                        
                <li>
                    <a href="#21-framework" aria-label="2.1 Framework">2.1 Framework</a></li>
                <li>
                    <a href="#22-standard-training" aria-label="2.2 Standard Training">2.2 Standard Training</a></li>
                <li>
                    <a href="#23-latent-space-data-augmentation-for-hard-example-generation" aria-label="2.3 Latent Space Data Augmentation for Hard Example Generation">2.3 Latent Space Data Augmentation for Hard Example Generation</a></li>
                <li>
                    <a href="#24-%e5%8d%8f%e5%90%8c%e8%ae%ad%e7%bb%83" aria-label="2.4 协同训练">2.4 协同训练</a></li></ul>
                </li>
                <li>
                    <a href="#3-experiments-and-results" aria-label="3 Experiments and Results">3 Experiments and Results</a></li>
                <li>
                    <a href="#4-conclusion" aria-label="4 Conclusion">4 Conclusion</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Cooperative Training and Latent Space Data Augmentation for Robust Medical Image Segmentation</p>
<p><strong>论文题目</strong>：协同训练和隐空间数据增强的鲁棒性医学图像分割</p>
<ul>
<li><a href="https://arxiv.org/abs/2107.01079">https://arxiv.org/abs/2107.01079</a></li>
</ul>
<p><strong>会议</strong>：MICCAI 2021</p>
<p><strong>作者</strong>：Chen CHEN 陈晨</p>
<ul>
<li>
<p><a href="https://sites.google.com/view/morningchen-site/home">https://sites.google.com/view/morningchen-site/home</a></p>
</li>
<li>
<p>Research Assistant/PhD 伦敦帝国理工学院 Research Assistant/PhD</p>
</li>
<li>
<p>本科哈工大 物联网工程</p>
</li>
</ul>
<p><strong>代码</strong>：https://github.com/cherise215/Cooperative_Training_and_Latent_Space_Data_Augmentation</p>
<h2 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h2>
<p>基于深度学习的分割方法在部署过程中容易受到不可预见的数据分布（unforeseen data distribution）变化的影响，例如，不同扫描仪引起的图像外观或对比度的变化，伪影等。本篇论文提出了一个用于<strong>图像分割模型的协同训练框架</strong>和一个用于<strong>生成困难样本的隐空间数据增强方法</strong>，提升了模型的泛化性和有限数据的稳健性。</p>
<ul>
<li>协同训练框架由 fast-thinking network(FTN) 和 slow-thinking network(STN) 构成。FTN 学习解耦的图像特征和形状特征，用于图像重建和分割任务； STN 学习形状先验，用于分割校正和细化。</li>
<li>隐空间数据增强（latent space DA）是通过在通道和空间上遮盖解耦的隐空间，为训练生成具有挑战性的样本。</li>
</ul>
<p>在公共心脏成像数据集进行了广泛的实验，证实了分割性能的提高，以及提高了对各种不可预见的成像伪影的稳健性。与标准的训练方法相比，具有隐空间数据增强的协同训练在平均 Dice 提高了15%。</p>
<h2 id="1-introduction">1 Introduction<a hidden class="anchor" aria-hidden="true" href="#1-introduction">#</a></h2>
<p>将基于深度学习的方法部署到实际应用中的一个主要障碍是临床部署过程中的<strong>域转移（domain shift）</strong>，其中包括不同医疗中心和扫描仪的图像外观和对比度的变化，以及各种成像伪影。在  Multi-domain datasets 上学习域不变的特征进行分割可以解决上面的问题，但是 Multi-domain 数据的获取成本较高，因此从 <strong>single-domain</strong> 和有限的数据中学习稳健的网络，对医学影像研究具有重要的实用价值。</p>
<p>本篇论文提出了一个新的协同训练框架，用于从 single-domain 数据中学习到一个稳健的分割网络。主要贡献可以总结如下：</p>
<p><!-- raw HTML omitted -->（1）设计了一个由两个网络组成的协同训练框架<!-- raw HTML omitted --></p>
<p>这个框架启发自人类行为中的双系统模型：<strong>快速思维系统</strong>做出直觉判断，而<strong>慢速思维系统</strong>则通过逻辑推理进行纠正。</p>
<p>对应到框架中，fast-thinking network (FTN) 旨在理解图像的上下文，并提取与任务相关的图像和形状特征进行初始分割；slow-thinking network (STN) 根据学习到的形状先验来完善初始分割。</p>
<p><!-- raw HTML omitted -->（2）提出了一种隐空间数据增强方法 latent space data augmentation (DA) method<!-- raw HTML omitted --></p>
<p>随机和有针对性的方式对从 FTN 中学习到的隐编码（latent code）进行通道和空间的遮盖（屏蔽），这样就会重建出一组多样化的挑战性图像和对应的分割图，以加强两个网络的训练。</p>
<h2 id="2-methodology">2 Methodology<a hidden class="anchor" aria-hidden="true" href="#2-methodology">#</a></h2>
<p>single domain dataset $D_{tr} = {(x_i, y_i)}^{n}_{i=1}$</p>
<p>image $x_i \in \mathbb{R}^{H \times W}$</p>
<p>one-hot encoded C-class label maps $y_i \in {0, 1}^{H \times W \times C}$ （ground truth）</p>
<h3 id="21-framework">2.1 Framework<a hidden class="anchor" aria-hidden="true" href="#21-framework">#</a></h3>
<p><img loading="lazy" src="./20211024/1.png" alt=""  />
</p>
<p>给定输入图像 x，FTN 提取特定任务的形状特征 $z_s$ 来执行分割任务，提取图像上下文特征 $z_i$ 来执行图像重建任务。共享 encoder $E_{\theta}$，特征解耦器 $\mathcal{H}$， 两个特定任务的解码器 $D_{\phi_s}$、$D_{\phi_i}$ 用于图像分割和重建任务。</p>
<p>对 $z_i$ 应用特征解耦器 $\mathcal{H}$，使与分割任务无关的信息（如图像纹理信息、亮度）在 $z_s$ 中被停用，稀疏的 $z_s$ 有益于模型的稳健性。</p>
<p>$\mathcal{H}$ 由两个卷积层堆叠，后接 ReLU 激活函数。图像重建需要低层次的信息，而图像分割则依赖于更集中的高层次信息。引入 $\mathcal{H}$ 明确地定义了一个分层的特征结构，以提高模型的通用性；</p>
<p>STN 是一个去噪自动编码器网络 $C_{\psi}$，学习形状先验来纠正 FTN 预测的分割。在推理时，FTN 进行对给定的图像 x 进行快速分割：$p = D_{\phi_s}(\mathcal{H}(E_{\theta}(x)))$；STN 完善分割结果：$p&rsquo; = C_{\psi}(p)$。</p>
<h3 id="22-standard-training">2.2 Standard Training<a hidden class="anchor" aria-hidden="true" href="#22-standard-training">#</a></h3>
<p>用监督的多任务损失函数联合训练三个编码器-解码器对，损失包含：图像重建 $L_{rec}$、图像分割 $L_{seg}$、形状校正 $L_{shp}$。</p>
<p><img loading="lazy" src="./20211024/2.png" alt=""  />
</p>
<ul>
<li>$L_{rec}$ 是 Mean Squared Error(MSE)</li>
<li>$L_{seg}, L_{shp}$ 是 cross-entropy function</li>
<li>$y&rsquo; = C_{\psi}(y)$</li>
</ul>
<h3 id="23-latent-space-data-augmentation-for-hard-example-generation">2.3 Latent Space Data Augmentation for Hard Example Generation<a hidden class="anchor" aria-hidden="true" href="#23-latent-space-data-augmentation-for-hard-example-generation">#</a></h3>
<p>为了缓解过拟合，提出了 latent space DA method，使得 FTN 可以自动构建具有挑战性的样本。</p>
<p><img loading="lazy" src="./20211024/1.png" alt=""  />
</p>
<p>掩码生成器 $\mathcal{G}$  在 latent code $z$ 上产生一个掩码 m，之后 $\hat{z} = z \cdot m$ 输入到解码器重构出被破坏的图像 $\hat{x} = D_{\phi_i}(\hat{z_i})$ 和其对应的分割图 $\hat{p} = D_{\phi_s}(\hat{z_s})$。这就是  latent code masking 数据增强方法。</p>
<p>通过动态屏蔽 latent code，所提出的方法可以生成具有广泛多样性的图像外观和分割的样本。如下介绍几种 latent-code masking 方案：</p>
<p>（1）Random Masking with Dropout</p>
<p>latent-code 的整个通道在训练时以 p 的概率被掩盖为全零。</p>
<p><img loading="lazy" src="./20211024/3.png" alt=""  />
</p>
<p>被遮盖后第 i 个通道的结果为：$\hat{z}^{(i)} = z^{(i)} \cdot m^{(i)}$。$z \in \mathbb{R}^{c \times h \times w}$。</p>
<p>（2）Target Masking</p>
<p>提出了有针对性的 latent-code masking 方案，该方案以梯度为线索来识别要掩蔽的“突出”特征。 采取图像重建损失和图像分割损失，分别计算 $z_i$ 和 $z_s$ 的梯度 $g_{z_i}$和 $g_{z_s}$。</p>
<p><img loading="lazy" src="./20211024/4.png" alt=""  />
</p>
<p>对梯度值进行排序，可以确定出那些<strong>最具预测性</strong>的元素。作者假设，对损失函数反应较高的元素是导致在不可预见的域转移下性能下降的主要原因。因此，对这种元素进行有针对性的遮蔽，以<strong>模拟数据分布的转移（data distribution shifts）</strong>。可以在通道维度和空间维度遮蔽 latent-code $z$  的特征。</p>
<p><img loading="lazy" src="./20211024/5.png" alt=""  />
</p>
<ul>
<li>$z^{ch}_p, z^{sp}_p$ 阈值</li>
<li>a 是 (0, 0.5) 之间随机抽取的退火系数，创建 soft masks；</li>
</ul>
<p>Channel-wise masked code at i-th channel：</p>
<p>$\hat{z}^{(i)} = z^{(i)} \cdot m^{(i)}$</p>
<p>Spatial-wise masked code at (j, k) position：</p>
<p>$\hat{z}^{(j, k)} = z^{(j, k)} \cdot m^{(j, k)}$</p>
<h3 id="24-协同训练">2.4 协同训练<a hidden class="anchor" aria-hidden="true" href="#24-协同训练">#</a></h3>
<p>训练过程中，随机地将上面介绍的三种 mask generator 应用于 $z_i, z_s$，这个操作生成一组丰富的增强图像 $\hat{x}$ 和分割图 $\hat{p}$。这就得到 3 example pairs 用于训练：</p>
<ul>
<li>corrupted images-clean images $(\hat{x}, x)$</li>
<li>corrupted images-GT $(\hat{x}, y)$</li>
<li>corrupted GT-GT $(\hat{p}, y)$</li>
</ul>
<p>合作训练的最终损失定义为简单例子和困难例子上的损失的组合。</p>
<p><img loading="lazy" src="./20211024/6.png" alt=""  />
</p>
<h2 id="3-experiments-and-results">3 Experiments and Results<a hidden class="anchor" aria-hidden="true" href="#3-experiments-and-results">#</a></h2>
<p>应用与心脏图像分割任务，从 MR 图像中分割出左心室腔、左心室心肌和右心室。</p>
<p>数据集：</p>
<ul>
<li>
<p>ACDC：训练、intra-domain 测试</p>
</li>
<li>
<p>M&amp;Ms：cross-domain 测试</p>
</li>
<li>
<p>ACDC-C (corrupted ACDC)：评估数据增强方法的鲁棒性</p>
</li>
</ul>
<p>（1）实验 1：Standard Training vs Cooperative Training</p>
<p><img loading="lazy" src="./20211024/7.png" alt=""  />
</p>
<ul>
<li>两种方法在域内测试集上取得了相近的性能；</li>
<li>双网络（FTN+STN）的协同训练在域外测试集上取得了更高的性能；</li>
<li>隐空间数据增强方法数据上，协同训练也表现出了其优越性。</li>
</ul>
<p>（2）实验 2: Latent Space DA vs Image Space DA</p>
<p><img loading="lazy" src="./20211024/8.png" alt=""  />
</p>
<p><img loading="lazy" src="./20211024/9.png" alt=""  />
</p>
<p>Table 1 中 AdvBias 在 M&amp;Ms 数据集和 RandBias 上取得了最好的性能，但这种方法有一个副作用，使其对尖峰伪影更加敏感（Dice 得分 0.4901 vs 0.3840）。latent-space DA 在六个数据集上取得了最高的平均性能。</p>
<p>图 3. 本篇论文的方法不仅可以生成扰动的图像，还可以生成不确定性增加的真实的损坏的分割。</p>
<p>（3）实验 3：Ablation Study</p>
<p>(a) the proposed targeted masking; b) latent code decoupler <em>H</em>; c) cooperative training.</p>
<p><img loading="lazy" src="./20211024/10.png" alt=""  />
</p>
<ul>
<li>禁用 $\mathcal{G}<em>{ch}、\mathcal{G}</em>{sp}$ 后，平均 Dice 得分从 0.6901 降至 0.6584；</li>
<li>图像重建需要低层次的信息，而图像分割则依赖于更集中的高层次信息。引入 H明确地定义了一个分层的特征结构，以提高模型的通用性；</li>
<li>突出了合作训练策略加强基于学习的形状细化和修正；</li>
</ul>
<h2 id="4-conclusion">4 Conclusion<a hidden class="anchor" aria-hidden="true" href="#4-conclusion">#</a></h2>
<ul>
<li>提出了一个新的协同训练框架，以及一个 latent space masking-based 的数据增强方法；</li>
<li>实验验证了模型的通用性和对不可预见的领域转变的鲁棒性；</li>
<li>latent-space DA 方法只需要很少的代价；</li>
<li>目前只在心脏图像分割上展示了其性能，该通用框架有可能扩展到广泛的数据驱动的应用。</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://landodo.github.io/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/">数据增强</a></li>
      <li><a href="http://landodo.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></li>
      <li><a href="http://landodo.github.io/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/">医学图像分割</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://landodo.github.io/posts/20211105-2-5d-network/">
    <span class="title">« Prev Page</span>
    <br>
    <span>2.5D methods for Volumetric Medical Image Segmentation</span>
  </a>
  <a class="next" href="http://landodo.github.io/posts/20210924-3d-roi-aware-u-net/">
    <span class="title">Next Page »</span>
    <br>
    <span>3D RoI-aware U-Net for Accurate and Efficient Colorectal Tumor Segmentation</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>Landon</span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
