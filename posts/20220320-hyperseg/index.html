<<<<<<< HEAD
<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
<meta name="robots" content="index, follow">
<title>HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation | Landodo&#39;s NoteBook</title>
<meta name="keywords" content="论文阅读, CNN, 笔记" />
<meta name="description" content="HyperSeg Nirkin, Y., Wolf, L., &amp; Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4060-4069. 论文简介： CVPR 2021 https://arxiv.org/abs/2012.11582 💡亮点： 解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution(">
<meta name="author" content="">
<link rel="canonical" href="http://landodo.github.io/posts/20220320-hyperseg/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css" integrity="sha256-yIlj/i15RiAA/Q&#43;xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js" integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://landodo.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://landodo.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://landodo.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://landodo.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="http://landodo.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation" />
<meta property="og:description" content="HyperSeg Nirkin, Y., Wolf, L., &amp; Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4060-4069. 论文简介： CVPR 2021 https://arxiv.org/abs/2012.11582 💡亮点： 解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution(" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://landodo.github.io/posts/20220320-hyperseg/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-20T14:50:44&#43;08:00" />
<meta property="article:modified_time" content="2022-03-20T14:50:44&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation"/>
<meta name="twitter:description" content="HyperSeg Nirkin, Y., Wolf, L., &amp; Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4060-4069. 论文简介： CVPR 2021 https://arxiv.org/abs/2012.11582 💡亮点： 解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution("/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://landodo.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation",
      "item": "http://landodo.github.io/posts/20220320-hyperseg/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation",
  "name": "HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation",
  "description": "HyperSeg Nirkin, Y., Wolf, L., \u0026amp; Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4060-4069. 论文简介： CVPR 2021 https://arxiv.org/abs/2012.11582 💡亮点： 解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution(",
  "keywords": [
    "论文阅读", "CNN", "笔记"
  ],
  "articleBody": "HyperSeg  Nirkin, Y., Wolf, L., \u0026 Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4060-4069.\n 论文简介：\n CVPR 2021 https://arxiv.org/abs/2012.11582  💡亮点：\n 解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution(DPWConv)； Context head 也比较新颖。该模块的作用就是学习meta block所用的参数；即本论文的创新点：“Hypernetworks——使用一个网络为另一个网络生成权重”； 网络的整体结构视为类 U-Net 结构（嵌套的U-Net）；  Abstract 提出了一个新颖的、实时的、语义分割网络，其中编码器既编码又生成解码器的参数（权重）。 此外，为了允许最大的适应性，每个解码器块的权重在空间上都有变化。该网络由一个嵌套的 U-Net 组成，用于提取更高层次的上下文特征； 一个多头的权重生成模块；主网络由动态补丁式卷积（DPWConv）组成。\n在 PASCAL VOC 2012（val. set.）、Cityscapes、CamVid 实现了SOTA 准确性与运行时间的折衷。\n1 Introduction 本篇论文试图通过为网络提供额外的适应性的方式来提高性能。\n使用元学习技术来增加这种适应性，通常被称为动态网络或超网络（dynamic networks or hypernet\u0002works）。以前的方法所建议的超网络并不能完全捕捉到高分辨率图像的信号，因此很少用于生成 image-like maps。\n本篇论文提供了一种新颖的编码器-解码器方法，其中编码器的主干是基于该领域的最新进展。编码信号通过内部U-Net映射到动态网络权重，而解码器则由具有空间变化权重的动态块组成。\n采用了具有动态权重的局部连接层，方法非常的有效。运行时间/精度权衡见 Fig 1.\n本论文的贡献总结为：\n A new hypernetwork architecture that employs a UNet within a U-Net.（嵌套 U-Net） Novel dynamic patch-wise convolution with weights that vary both per input and per spatial location. SOTA accuracy vs. runtime trade-off on the major benchmarks of the field.  2 Related Work Hypernetworks\nHypernetwork 是为其他网络（通常被称为主网络）产生权重值的网络。我们发现，Hypernetworks 从未被用于语义分割领域。\nLocally connected layers.\n连接性遵循一种空间模式，类似于传统的卷积层，但没有权重共享。\n在语义分割的背景下，我们是第一个提出将局部连接层与 Hypernetworks 结合起来。\nSemantic segmentation.\nFCN， 条件随机场(CRF)、U-Net、SPP、ASPP、Attention。\nReal-time segmentation.\n其目标是在准确性和计算量之间实现最佳权衡，重点是保持实时性能。网络架构通常由基于高效主干的编码器和相对较小的解码器组成。\nSegNet，ENet，ICNet，GUNNet，SwiftNet。\n深度可分离卷积，inverted residual blocks，BiSeNet，BiSeNetV2，TDNet。\n3. Method 提出的模型涉及三个子网络：\n Backbone (b)：EfficientNet context head (h)：Figure 2 (c) for details primary network(Decoder)：multiple meta-block  三个网络的权重：θb、θh 和 θw，在推理过程中是固定的，并在训练过程中学习。而 θmi，即 decoder meta block mi 的权重，在推理时是动态预测的（不是常规的卷积，而是动态的、局部的卷积）。\nBackbone：将输入图像 $I \\in \\mathbb{R}^{3 \\times H \\times W}$ 映射到组 5 组分辨率不同的特征图。\nContext head：将最后一个特征图映射为一个信号 φ。信号输入w生成主网络元块的权重d。 请注意，这些权重在不同的空间位置是不同的（动态）。\n最后，给定输入图像和特征图，F1，……，Fn，其相应的相同分辨率的位置编码 P0，……Pn，以及权重 θd，解码器 d 输出分割预测，$S \\in \\mathbb{R}^{C×H×W}$，其中 C 是语义分割任务中的类别数量。\n整个网络是由以下一组方程定义：\n3.1. The encoder and the hypernetwork Backbone 提取不同分辨率特征图后，采用 1×1 卷积，为的是减少特征图的通道数量，以减小解码器的规模，\nContext head 输出的通道数为输入的一半。 最底层的特征图被平均池化以提取最高级别的上下文，然后使用近邻插值将其上采样到之前的分辨率。在 h 的上采样路径中，在每一级，将特征图与相应的上采样特征图连接起来，然后是一个全连接层。\n权重映射网络，w = [w0, … , wn]，是 Hypernetworks 的一个关键部分，将 w 分成若干部分，并将这些部分附加到 Primary Network 块上，是比较有效的（ Figure 2 (b)）。将权重映射网络的各层w0, . . , wn, 的权重映射网络被嵌入到d的每个元块中。每个wi是与通道组1×1的卷积，见 Figure 3 (a)。\n3.2 Decoder(Primary Network) Decoder 包含 n+1 个 Meta-Block（$m_0, …m_n$）。$m_0$ 对应输入图片，$m_i$ 对应特征图 $F_i$，每个块之后是双线性上采样并与下一个更高分辨率的特征图连接。\n解码器 d 的权重不仅取决于输入图像，而且会在图像的不同区域之间变化。d 受益于知道像素的位置信息。 出于这个原因，我们通过额外的位置编码来增强输入图像和编码器的特征图。\n每个 Meta-Block 基于 inverted resid\u0002ual block of MobileNetV2。Figure 3(a) 所示，包含一个点卷积 pw1，然后是深度卷积 dw，以及另一个没有激活函数的点卷积 pw2。\n3.3. Dynamic patch-wise convolution dynamic patchwise convolution (DPWConv):\n4. Experimental results 三个数据集： PASCAL VOC 2012, Cityscapes, 和 CamVid.\n评估指标：mIoU、FPS、GFLOP。\nBatch size = 1 模拟实时推理。\n$\\theta^b$ 在 ImageNet 上预训练得到 ，$\\theta^h, \\theta^w$ 取随机的正态分布。采用 Adam Optimizer，学习率采用 polynomial learning rate scheduling。\nConclusion 我们提出将自动编码器与超网络结合起来，以完成语义分割的任务。在我们的方案中，超网络是由三个网络组成的：语义分割编码器的主干b、内部U-Net形式的上下文头h、以及多个权重映射头wi。解码器是一个多块解码器，其中每个块，di，实现局部连接的层。其结果是一种新型的U-Net，能够动态地、局部地适应输入，从而有可能使分割过程更好地适应输入图像。正如我们的实验所显示的，在这个竞争激烈的领域，我们的方法在多个基准上都超过了SotA方法。\n",
  "wordCount" : "2243",
  "inLanguage": "en",
  "datePublished": "2022-03-20T14:50:44+08:00",
  "dateModified": "2022-03-20T14:50:44+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://landodo.github.io/posts/20220320-hyperseg/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Landodo's NoteBook",
    "logo": {
      "@type": "ImageObject",
      "url": "http://landodo.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://landodo.github.io/" accesskey="h" title="Landodo&#39;s NoteBook (Alt + H)">Landodo&#39;s NoteBook</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="http://landodo.github.io/search" title="🔍Search (Alt &#43; /)" accesskey=/>
                    <span>🔍Search</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/tags" title="Tag">
                    <span>Tag</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/cs-zoo" title="CS ZOO">
                    <span>CS ZOO</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://landodo.github.io/">Home</a>&nbsp;»&nbsp;<a href="http://landodo.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation
    </h1>
    <div class="post-meta"><span title='2022-03-20 14:50:44 +0800 CST'>March 20, 2022</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;2243 words

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#hyperseg" aria-label="HyperSeg">HyperSeg</a><ul>
                        
                <li>
                    <a href="#abstract" aria-label="Abstract">Abstract</a></li>
                <li>
                    <a href="#1-introduction" aria-label="1 Introduction">1 Introduction</a></li>
                <li>
                    <a href="#2-related-work" aria-label="2 Related Work">2 Related Work</a></li>
                <li>
                    <a href="#3-method" aria-label="3. Method">3. Method</a><ul>
                        
                <li>
                    <a href="#31-the-encoder-and-the-hypernetwork" aria-label="3.1. The encoder and the hypernetwork">3.1. The encoder and the hypernetwork</a></li>
                <li>
                    <a href="#32-decoderprimary-network" aria-label="3.2 Decoder(Primary Network)">3.2 Decoder(Primary Network)</a></li>
                <li>
                    <a href="#33-dynamic-patch-wise-convolution" aria-label="3.3. Dynamic patch-wise convolution">3.3. Dynamic patch-wise convolution</a></li></ul>
                </li>
                <li>
                    <a href="#4-experimental-results" aria-label="4. Experimental results">4. Experimental results</a></li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

=======
<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">


<meta name="robots" content="index, follow">
<title>HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation | Landodo&#39;s NoteBook</title>
<meta name="keywords" content="论文阅读, CNN, 笔记" />
<meta name="description" content="HyperSeg Nirkin, Y., Wolf, L., &amp; Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4060-4069. 论文简介： CVPR 2021 https://arxiv.org/abs/2012.11582 💡亮点： 解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution(">
<meta name="author" content="">
<link rel="canonical" href="http://landodo.github.io/posts/20220320-hyperseg/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css" integrity="sha256-yIlj/i15RiAA/Q&#43;xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js" integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://landodo.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://landodo.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://landodo.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://landodo.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="http://landodo.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation" />
<meta property="og:description" content="HyperSeg Nirkin, Y., Wolf, L., &amp; Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4060-4069. 论文简介： CVPR 2021 https://arxiv.org/abs/2012.11582 💡亮点： 解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution(" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://landodo.github.io/posts/20220320-hyperseg/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-20T14:50:44&#43;08:00" />
<meta property="article:modified_time" content="2022-03-20T14:50:44&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation"/>
<meta name="twitter:description" content="HyperSeg Nirkin, Y., Wolf, L., &amp; Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4060-4069. 论文简介： CVPR 2021 https://arxiv.org/abs/2012.11582 💡亮点： 解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution("/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://landodo.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation",
      "item": "http://landodo.github.io/posts/20220320-hyperseg/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation",
  "name": "HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation",
  "description": "HyperSeg Nirkin, Y., Wolf, L., \u0026amp; Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4060-4069. 论文简介： CVPR 2021 https://arxiv.org/abs/2012.11582 💡亮点： 解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution(",
  "keywords": [
    "论文阅读", "CNN", "笔记"
  ],
  "articleBody": "HyperSeg  Nirkin, Y., Wolf, L., \u0026 Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 4060-4069.\n 论文简介：\n CVPR 2021 https://arxiv.org/abs/2012.11582  💡亮点：\n 解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution(DPWConv)； Context head 也比较新颖。该模块的作用就是学习meta block所用的参数；即本论文的创新点：“Hypernetworks——使用一个网络为另一个网络生成权重”； 网络的整体结构视为类 U-Net 结构（嵌套的U-Net）；  Abstract 提出了一个新颖的、实时的、语义分割网络，其中编码器既编码又生成解码器的参数（权重）。 此外，为了允许最大的适应性，每个解码器块的权重在空间上都有变化。该网络由一个嵌套的 U-Net 组成，用于提取更高层次的上下文特征； 一个多头的权重生成模块；主网络由动态补丁式卷积（DPWConv）组成。\n在 PASCAL VOC 2012（val. set.）、Cityscapes、CamVid 实现了SOTA 准确性与运行时间的折衷。\n1 Introduction 本篇论文试图通过为网络提供额外的适应性的方式来提高性能。\n使用元学习技术来增加这种适应性，通常被称为动态网络或超网络（dynamic networks or hypernet\u0002works）。以前的方法所建议的超网络并不能完全捕捉到高分辨率图像的信号，因此很少用于生成 image-like maps。\n本篇论文提供了一种新颖的编码器-解码器方法，其中编码器的主干是基于该领域的最新进展。编码信号通过内部U-Net映射到动态网络权重，而解码器则由具有空间变化权重的动态块组成。\n采用了具有动态权重的局部连接层，方法非常的有效。运行时间/精度权衡见 Fig 1.\n本论文的贡献总结为：\n A new hypernetwork architecture that employs a UNet within a U-Net.（嵌套 U-Net） Novel dynamic patch-wise convolution with weights that vary both per input and per spatial location. SOTA accuracy vs. runtime trade-off on the major benchmarks of the field.  2 Related Work Hypernetworks\nHypernetwork 是为其他网络（通常被称为主网络）产生权重值的网络。我们发现，Hypernetworks 从未被用于语义分割领域。\nLocally connected layers.\n连接性遵循一种空间模式，类似于传统的卷积层，但没有权重共享。\n在语义分割的背景下，我们是第一个提出将局部连接层与 Hypernetworks 结合起来。\nSemantic segmentation.\nFCN， 条件随机场(CRF)、U-Net、SPP、ASPP、Attention。\nReal-time segmentation.\n其目标是在准确性和计算量之间实现最佳权衡，重点是保持实时性能。网络架构通常由基于高效主干的编码器和相对较小的解码器组成。\nSegNet，ENet，ICNet，GUNNet，SwiftNet。\n深度可分离卷积，inverted residual blocks，BiSeNet，BiSeNetV2，TDNet。\n3. Method 提出的模型涉及三个子网络：\n Backbone (b)：EfficientNet context head (h)：Figure 2 (c) for details primary network(Decoder)：multiple meta-block  三个网络的权重：θb、θh 和 θw，在推理过程中是固定的，并在训练过程中学习。而 θmi，即 decoder meta block mi 的权重，在推理时是动态预测的（不是常规的卷积，而是动态的、局部的卷积）。\nBackbone：将输入图像 $I \\in \\mathbb{R}^{3 \\times H \\times W}$ 映射到组 5 组分辨率不同的特征图。\nContext head：将最后一个特征图映射为一个信号 φ。信号输入w生成主网络元块的权重d。 请注意，这些权重在不同的空间位置是不同的（动态）。\n最后，给定输入图像和特征图，F1，……，Fn，其相应的相同分辨率的位置编码 P0，……Pn，以及权重 θd，解码器 d 输出分割预测，$S \\in \\mathbb{R}^{C×H×W}$，其中 C 是语义分割任务中的类别数量。\n整个网络是由以下一组方程定义：\n3.1. The encoder and the hypernetwork Backbone 提取不同分辨率特征图后，采用 1×1 卷积，为的是减少特征图的通道数量，以减小解码器的规模，\nContext head 输出的通道数为输入的一半。 最底层的特征图被平均池化以提取最高级别的上下文，然后使用近邻插值将其上采样到之前的分辨率。在 h 的上采样路径中，在每一级，将特征图与相应的上采样特征图连接起来，然后是一个全连接层。\n权重映射网络，w = [w0, … , wn]，是 Hypernetworks 的一个关键部分，将 w 分成若干部分，并将这些部分附加到 Primary Network 块上，是比较有效的（ Figure 2 (b)）。将权重映射网络的各层w0, . . , wn, 的权重映射网络被嵌入到d的每个元块中。每个wi是与通道组1×1的卷积，见 Figure 3 (a)。\n3.2 Decoder(Primary Network) Decoder 包含 n+1 个 Meta-Block（$m_0, …m_n$）。$m_0$ 对应输入图片，$m_i$ 对应特征图 $F_i$，每个块之后是双线性上采样并与下一个更高分辨率的特征图连接。\n解码器 d 的权重不仅取决于输入图像，而且会在图像的不同区域之间变化。d 受益于知道像素的位置信息。 出于这个原因，我们通过额外的位置编码来增强输入图像和编码器的特征图。\n每个 Meta-Block 基于 inverted resid\u0002ual block of MobileNetV2。Figure 3(a) 所示，包含一个点卷积 pw1，然后是深度卷积 dw，以及另一个没有激活函数的点卷积 pw2。\n3.3. Dynamic patch-wise convolution dynamic patchwise convolution (DPWConv):\n4. Experimental results 三个数据集： PASCAL VOC 2012, Cityscapes, 和 CamVid.\n评估指标：mIoU、FPS、GFLOP。\nBatch size = 1 模拟实时推理。\n$\\theta^b$ 在 ImageNet 上预训练得到 ，$\\theta^h, \\theta^w$ 取随机的正态分布。采用 Adam Optimizer，学习率采用 polynomial learning rate scheduling。\nConclusion 我们提出将自动编码器与超网络结合起来，以完成语义分割的任务。在我们的方案中，超网络是由三个网络组成的：语义分割编码器的主干b、内部U-Net形式的上下文头h、以及多个权重映射头wi。解码器是一个多块解码器，其中每个块，di，实现局部连接的层。其结果是一种新型的U-Net，能够动态地、局部地适应输入，从而有可能使分割过程更好地适应输入图像。正如我们的实验所显示的，在这个竞争激烈的领域，我们的方法在多个基准上都超过了SotA方法。\n",
  "wordCount" : "2243",
  "inLanguage": "en",
  "datePublished": "2022-03-20T14:50:44+08:00",
  "dateModified": "2022-03-20T14:50:44+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://landodo.github.io/posts/20220320-hyperseg/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Landodo's NoteBook",
    "logo": {
      "@type": "ImageObject",
      "url": "http://landodo.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://landodo.github.io/" accesskey="h" title="Landodo&#39;s NoteBook (Alt + H)">Landodo&#39;s NoteBook</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="http://landodo.github.io/search" title="🔍Search (Alt &#43; /)" accesskey=/>
                    <span>🔍Search</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/tags" title="Tag">
                    <span>Tag</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://landodo.github.io/cs-zoo" title="CS ZOO">
                    <span>CS ZOO</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://landodo.github.io/">Home</a>&nbsp;»&nbsp;<a href="http://landodo.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation
    </h1>
    <div class="post-meta"><span title='2022-03-20 14:50:44 +0800 CST'>March 20, 2022</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;2243 words

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#hyperseg" aria-label="HyperSeg">HyperSeg</a><ul>
                        
                <li>
                    <a href="#abstract" aria-label="Abstract">Abstract</a></li>
                <li>
                    <a href="#1-introduction" aria-label="1 Introduction">1 Introduction</a></li>
                <li>
                    <a href="#2-related-work" aria-label="2 Related Work">2 Related Work</a></li>
                <li>
                    <a href="#3-method" aria-label="3. Method">3. Method</a><ul>
                        
                <li>
                    <a href="#31-the-encoder-and-the-hypernetwork" aria-label="3.1. The encoder and the hypernetwork">3.1. The encoder and the hypernetwork</a></li>
                <li>
                    <a href="#32-decoderprimary-network" aria-label="3.2 Decoder(Primary Network)">3.2 Decoder(Primary Network)</a></li>
                <li>
                    <a href="#33-dynamic-patch-wise-convolution" aria-label="3.3. Dynamic patch-wise convolution">3.3. Dynamic patch-wise convolution</a></li></ul>
                </li>
                <li>
                    <a href="#4-experimental-results" aria-label="4. Experimental results">4. Experimental results</a></li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

>>>>>>> 351a415af31a0561991d5014415d6ee1364940fd
  <div class="post-content"><h1 id="hyperseg">HyperSeg<a hidden class="anchor" aria-hidden="true" href="#hyperseg">#</a></h1>
<blockquote>
<p>Nirkin, Y., Wolf, L., &amp; Hassner, T. (2021). HyperSeg: Patch-wise Hypernetwork for Real-time Semantic Segmentation. <em>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 4060-4069.</p>
</blockquote>
<p><strong>论文简介：</strong></p>
<ul>
<li>CVPR 2021</li>
<li><a href="https://arxiv.org/abs/2012.11582">https://arxiv.org/abs/2012.11582</a></li>
</ul>
<p><strong>💡亮点：</strong></p>
<ul>
<li>解码器中的 Meta block 模块，在模块中提出了 Dynamic Patch-wise Convolution(DPWConv)；</li>
<li>Context head 也比较新颖。该模块的作用就是学习meta block所用的参数；即本论文的创新点：“Hypernetworks——使用一个网络为另一个网络生成权重”；</li>
<li>网络的整体结构视为类 U-Net 结构（嵌套的U-Net）；</li>
</ul>
<h2 id="abstract">Abstract<a hidden class="anchor" aria-hidden="true" href="#abstract">#</a></h2>
<p>提出了一个新颖的、实时的、语义分割网络，其中编码器既编码又生成解码器的参数（权重）。 此外，为了允许最大的适应性，每个解码器块的权重在空间上都有变化。该网络由一个嵌套的 U-Net 组成，用于提取更高层次的上下文特征； 一个多头的权重生成模块；主网络由动态补丁式卷积（DPWConv）组成。</p>
<p>在 PASCAL VOC 2012（val. set.）、Cityscapes、CamVid 实现了SOTA 准确性与运行时间的折衷。</p>
<h2 id="1-introduction">1 Introduction<a hidden class="anchor" aria-hidden="true" href="#1-introduction">#</a></h2>
<p>本篇论文试图通过<strong>为网络提供额外的适应性</strong>的方式来提高性能。</p>
<p>使用元学习技术来增加这种适应性，通常被称为动态网络或超网络（<em>dynamic networks or hypernetworks</em>）。以前的方法所建议的超网络并不能完全捕捉到高分辨率图像的信号，因此很少用于生成 image-like maps。</p>
<p>本篇论文提供了一种新颖的编码器-解码器方法，其中编码器的主干是基于该领域的最新进展。编码信号通过内部U-Net映射到动态网络权重，而解码器则由具有空间变化权重的动态块组成。</p>
<p>采用了具有动态权重的局部连接层，方法非常的有效。运行时间/精度权衡见 Fig 1.</p>
<<<<<<< HEAD
<p><img loading="lazy" src="./20220320/1.png" alt=""  />
=======
<p><img loading="lazy" src="./20220320/1.png" alt=""  />
>>>>>>> 351a415af31a0561991d5014415d6ee1364940fd
</p>
<p>本论文的贡献总结为：</p>
<ul>
<li>A new hypernetwork architecture that employs a UNet within a U-Net.（嵌套 U-Net）</li>
<li>Novel <strong>dynamic patch-wise convolution</strong> with weights that vary both per input and per spatial location.</li>
<li>SOTA accuracy vs. runtime trade-off on the major benchmarks of the field.</li>
</ul>
<h2 id="2-related-work">2 Related Work<a hidden class="anchor" aria-hidden="true" href="#2-related-work">#</a></h2>
<p><strong>Hypernetworks</strong></p>
<p>Hypernetwork 是为其他网络（通常被称为主网络）产生权重值的网络。我们发现，Hypernetworks 从未被用于语义分割领域。</p>
<p><strong>Locally connected layers.</strong></p>
<p>连接性遵循一种空间模式，类似于传统的卷积层，但没有权重共享。</p>
<p>在语义分割的背景下，我们是第一个提出将局部连接层与 Hypernetworks 结合起来。</p>
<p><strong>Semantic segmentation.</strong></p>
<p>FCN， 条件随机场(CRF)、U-Net、SPP、ASPP、Attention。</p>
<p><strong>Real-time segmentation.</strong></p>
<p>其目标是在准确性和计算量之间实现最佳权衡，重点是保持实时性能。网络架构通常由基于高效主干的编码器和相对较小的解码器组成。</p>
<p>SegNet，ENet，ICNet，GUNNet，SwiftNet。</p>
<p>深度可分离卷积，inverted residual blocks，BiSeNet，BiSeNetV2，TDNet。</p>
<h2 id="3-method">3. Method<a hidden class="anchor" aria-hidden="true" href="#3-method">#</a></h2>
<<<<<<< HEAD
<p><img loading="lazy" src="./20220320/2.png" alt=""  />
=======
<p><img loading="lazy" src="./20220320/2.png" alt=""  />
>>>>>>> 351a415af31a0561991d5014415d6ee1364940fd
</p>
<p>提出的模型涉及三个子网络：</p>
<ul>
<li>Backbone (b)：EfficientNet</li>
<li>context head (h)：Figure 2 (c) for details</li>
<li>primary network(Decoder)：multiple meta-block</li>
</ul>
<p>三个网络的权重：θb、θh 和 θw，在推理过程中是固定的，并在训练过程中学习。而 θmi，即 decoder meta block mi 的权重，在推理时是动态预测的（不是常规的卷积，而是动态的、局部的卷积）。</p>
<p>Backbone：将输入图像 $I \in \mathbb{R}^{3 \times H \times W}$ 映射到组 5 组分辨率不同的特征图。</p>
<p>Context head：将最后一个特征图映射为一个信号 φ。<strong>信号输入w生成主网络元块的权重d</strong>。 请注意，这些权重在不同的空间位置是不同的（动态）。</p>
<p>最后，给定输入图像和特征图，F1，&hellip;&hellip;，Fn，其相应的相同分辨率的位置编码 P0，……Pn，以及权重 θd，解码器 d 输出分割预测，$S \in \mathbb{R}^{C×H×W}$，其中 C 是语义分割任务中的类别数量。</p>
<p>整个网络是由以下一组方程定义：</p>
<<<<<<< HEAD
<p><img loading="lazy" src="./20220320/3.png" alt=""  />
=======
<p><img loading="lazy" src="./20220320/3.png" alt=""  />
>>>>>>> 351a415af31a0561991d5014415d6ee1364940fd
</p>
<h3 id="31-the-encoder-and-the-hypernetwork">3.1. The encoder and the hypernetwork<a hidden class="anchor" aria-hidden="true" href="#31-the-encoder-and-the-hypernetwork">#</a></h3>
<p>Backbone 提取不同分辨率特征图后，采用 1×1 卷积，为的是减少特征图的通道数量，以减小解码器的规模，</p>
<p>Context head 输出的通道数为输入的一半。 最底层的特征图被平均池化以提取最高级别的上下文，然后使用近邻插值将其上采样到之前的分辨率。在 h 的上采样路径中，在每一级，将特征图与相应的上采样特征图连接起来，然后是一个全连接层。</p>
<p>权重映射网络，w = [w0, &hellip; , wn]，是 Hypernetworks 的一个关键部分，将  <strong>w 分成若干部分</strong>，并将这些部分附加到 Primary Network 块上，是比较有效的（ Figure 2 (b)）。将权重映射网络的各层w0, . . , wn, 的权重映射网络被嵌入到d的每个元块中。每个wi是与通道组1×1的卷积，见 Figure 3 (a)。</p>
<<<<<<< HEAD
<p><img loading="lazy" src="./20220320/4.png" alt=""  />
=======
<p><img loading="lazy" src="./20220320/4.png" alt=""  />
>>>>>>> 351a415af31a0561991d5014415d6ee1364940fd
</p>
<h3 id="32-decoderprimary-network">3.2 Decoder(Primary Network)<a hidden class="anchor" aria-hidden="true" href="#32-decoderprimary-network">#</a></h3>
<p>Decoder 包含 n+1 个 Meta-Block（$m_0, &hellip;m_n$）。$m_0$ 对应输入图片，$m_i$ 对应特征图 $F_i$，每个块之后是双线性上采样并与下一个更高分辨率的特征图连接。</p>
<p>解码器 d 的权重不仅取决于输入图像，而且会在图像的不同区域之间变化。d 受益于知道像素的位置信息。 出于这个原因，我们通过额外的<strong>位置编码</strong>来增强输入图像和编码器的特征图。</p>
<p>每个 Meta-Block  基于 inverted residual block of MobileNetV2。Figure 3(a) 所示，包含一个点卷积 pw1，然后是深度卷积 dw，以及另一个没有激活函数的点卷积 pw2。</p>
<h3 id="33-dynamic-patch-wise-convolution">3.3. Dynamic patch-wise convolution<a hidden class="anchor" aria-hidden="true" href="#33-dynamic-patch-wise-convolution">#</a></h3>
<p>dynamic patchwise convolution (DPWConv):</p>
<<<<<<< HEAD
<p><img loading="lazy" src="./20220320/4.png" alt=""  />
=======
<p><img loading="lazy" src="./20220320/4.png" alt=""  />
>>>>>>> 351a415af31a0561991d5014415d6ee1364940fd
</p>
<h2 id="4-experimental-results">4. Experimental results<a hidden class="anchor" aria-hidden="true" href="#4-experimental-results">#</a></h2>
<p>三个数据集： PASCAL VOC 2012, Cityscapes, 和 CamVid.</p>
<p>评估指标：mIoU、FPS、GFLOP。</p>
<p>Batch size = 1 模拟实时推理。</p>
<p>$\theta^b$ 在 ImageNet 上预训练得到 ，$\theta^h, \theta^w$ 取随机的正态分布。采用 Adam Optimizer，学习率采用 polynomial learning rate scheduling。</p>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>我们提出将自动编码器与超网络结合起来，以完成语义分割的任务。在我们的方案中，超网络是由三个网络组成的：语义分割编码器的主干b、内部U-Net形式的上下文头h、以及多个权重映射头wi。解码器是一个多块解码器，其中每个块，di，实现局部连接的层。其结果是一种新型的U-Net，能够动态地、局部地适应输入，从而有可能使分割过程更好地适应输入图像。正如我们的实验所显示的，在这个竞争激烈的领域，我们的方法在多个基准上都超过了SotA方法。</p>
<<<<<<< HEAD


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://landodo.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></li>
      <li><a href="http://landodo.github.io/tags/cnn/">CNN</a></li>
      <li><a href="http://landodo.github.io/tags/%E7%AC%94%E8%AE%B0/">笔记</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://landodo.github.io/posts/20190304-stl-notes/">
    <span class="title">« Prev Page</span>
    <br>
    <span>《STL 源码剖析》STL 学习笔记</span>
  </a>
  <a class="next" href="http://landodo.github.io/posts/20220304-python-qt-notes/">
    <span class="title">Next Page »</span>
    <br>
    <span>《Python Qt GUI 与数据可视化编程》阅读笔记</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>Landon</span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
=======


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://landodo.github.io/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></li>
      <li><a href="http://landodo.github.io/tags/cnn/">CNN</a></li>
      <li><a href="http://landodo.github.io/tags/%E7%AC%94%E8%AE%B0/">笔记</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="http://landodo.github.io/posts/20190304-stl-notes/">
    <span class="title">« Prev Page</span>
    <br>
    <span>《STL 源码剖析》STL 学习笔记</span>
  </a>
  <a class="next" href="http://landodo.github.io/posts/20220304-python-qt-notes/">
    <span class="title">Next Page »</span>
    <br>
    <span>《Python Qt GUI 与数据可视化编程》阅读笔记</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>Landon</span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
>>>>>>> 351a415af31a0561991d5014415d6ee1364940fd
